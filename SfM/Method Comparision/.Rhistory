anova(mod3,mod2,test="Chisq")
p3<-PlotANALYST(sub.seg,"GENUS_CODE","Ave.size","SSSS","Average Max Diameter",1.5,36,"NS")
#p1<-p1+geom_label(label="Significant", x=1,y=36,label.size = 0.35,color = "black", fill="#00BFC4")
p3
#Ave. od- can't transform
s<-subset(sub.seg,GENUS_CODE=="SSSS")
hist(sqrt(s$Ave.od+1))
s$sqAve.od<-sqrt(s$Ave.od)
m<-lmer(sqAve.od~METHOD*ANALYST + (1|SEC_NAME),data=s)
DPlots(m,s)
wilcox.test(Ave.od ~ METHOD, data=subset(s,ANALYST=="1"))
wilcox.test(Ave.od ~ METHOD, data=subset(s,ANALYST=="2"))
p4<-PlotANALYST(sub.seg,"GENUS_CODE","Ave.od","SSSS","Average % Old Dead",1,36,"NS")
#p1<-p1+geom_label(label="Significant", x=1,y=36,label.size = 0.35,color = "black", fill="#00BFC4")
p4
#Ave. rd
s<-subset(sub.seg,GENUS_CODE=="SSSS")
hist(sqrt(s$Ave.rd))
s$sqAve.rd<-sqrt(s$Ave.rd)
m<-lmer(sqAve.rd~METHOD*ANALYST + (1|SEC_NAME),data=s)
DPlots(m,s)
wilcox.test(Ave.rd ~ METHOD, data=subset(s,ANALYST=="1"))
wilcox.test(Ave.rd ~ METHOD, data=subset(s,ANALYST=="2"))
p5<-PlotANALYST(sub.seg,"GENUS_CODE","Ave.rd","SSSS","Average % Recent Dead",1,10,"Significant")
p5<-p5+geom_label(label="Significant", x=1,y=10,label.size = 0.35,color = "black", fill="#00BFC4")
p5
#Acute disease
s<-subset(sub.seg,GENUS_CODE=="SSSS")
hist(sqrt(s$AcuteDZ_prev))
s$sqAcuteDZ_prev<-sqrt(s$AcuteDZ_prev)
m<-lmer(sqAcuteDZ_prev~METHOD*ANALYST + (1|SEC_NAME),data=s)
DPlots(m,s)
wilcox.test(AcuteDZ_prev ~ METHOD, data=subset(s,ANALYST=="1"))
wilcox.test(AcuteDZ_prev ~ METHOD, data=subset(s,ANALYST=="2"))
p6<-PlotANALYST(sub.seg,"GENUS_CODE","AcuteDZ_prev","SSSS","Acute Disease Prevalence (%)",1,20,"Significant")
p6<-p6+geom_label(label="Significant", x=1,y=20,label.size = 0.35,color = "black", fill="#00BFC4")
p6
#Chronic disease
s<-subset(sub.seg,GENUS_CODE=="SSSS")
hist(sqrt(s$ChronicDZ_prev))
s$sqChronicDZ_prev<-sqrt(s$ChronicDZ_prev)
m<-lmer(sqChronicDZ_prev~METHOD*ANALYST + (1|SEC_NAME),data=s)
DPlots(m,s)
wilcox.test(ChronicDZ_prev ~ METHOD, data=subset(s,ANALYST=="1"))
wilcox.test(ChronicDZ_prev ~ METHOD, data=subset(s,ANALYST=="2"))
p7<-PlotANALYST(sub.seg,"GENUS_CODE","ChronicDZ_prev","SSSS","Chronic Disease Prevalence (%)",1.5,20,"NS")
p7
#Bleaching
s<-subset(sub.seg,GENUS_CODE=="SSSS")
hist(sqrt(s$BLE_prev))
s$sqBLE_prev<-sqrt(s$BLE_prev)
m<-lmer(sqBLE_prev~METHOD*ANALYST + (1|SEC_NAME),data=s)
DPlots(m,s)
wilcox.test(BLE_prev ~ METHOD, data=subset(s,ANALYST=="1"))
wilcox.test(BLE_prev ~ METHOD, data=subset(s,ANALYST=="2"))
p8<-PlotANALYST(sub.seg,"GENUS_CODE","BLE_prev","SSSS","Bleaching Prevalence (%)",1,45,"Significant")
p8<-p8+geom_label(label="Significant", x=1,y=45,label.size = 0.35,color = "black", fill="#00BFC4")
p8<-p8+geom_label(label="Significant", x=2,y=45,label.size = 0.35,color = "black", fill="#00BFC4")
p8
allplots<-grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,nrow=2,ncol=4)
ggsave(plot<-allplots,file="T:/Benthic/Data/SfM/Method Comparision/Figures/Analystplots_stats.png",width=10,height=5)
allplots<-grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,nrow=2,ncol=4)
ggsave(plot<-allplots,file="T:/Benthic/Data/SfM/Method Comparision/Figures/Analystplots_stats.png",width=10,height=5)
dev.off()
allplots<-grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,nrow=2,ncol=4)
ggsave(plot<-allplots,file="T:/Benthic/Data/SfM/Method Comparision/Figures/Analystplots_stats.png",width=10,height=5)
rm(list=ls())
library(gridExtra)
library(reshape2)
library(plyr)
#install.packages("ggpmisc")
library(hydroGOF)
library(tidyverse)
library(ggpmisc)
library(plotrix)
source("T:/Benthic/Data/SfM/ScriptFiles/SfMvDiver Plotting Functions.R")
data.gen<-read.csv("T:/Benthic/Data/SfM/Summarized Data/HARAMP_repeats_GENUS_Summarized Data.csv")
#List of segments that were surveyed by all methods and multiple divers....UNEQUAL
sfm2<-data.gen[data.gen$MethodRep=="SfM_2",]
length(unique(sfm2$SS)) #38 unique SS
sfm1<-data.gen[data.gen$MethodRep=="SfM_1",]
length(unique(sfm1$SS)) #31
diver1<-data.gen[data.gen$MethodRep=="DIVER_1",]
length(unique(diver1$SS)) #24
diver2<-data.gen[data.gen$MethodRep=="DIVER_2",]
length(unique(diver2$SS)) #23
#Create dataframe containing only site_segments that contain all 4 methodreps
data.gen$SST=paste0(data.gen$SS,"_",data.gen$GENUS_CODE)
seg4list=ddply(data.gen,.(SST,SS),summarize,NBox=length(unique(MethodRep)))
all4seglist=subset(seg4list,NBox>=4)
length(unique(all4seglist[,"SS"]))
#Create dataframe containing only sites containing 2 annotators and 2 divers
data.sm=subset(data.gen,SST%in%all4seglist$SST)
dim(data.sm)
length(unique(data.sm$SS))
#Check that all Site_Segments being used for analysis have 2 annotators and 2 divers
ddply(data.sm,.(SITE, SEGMENT), summarize, num.repeats = n_distinct(MethodRep)) #should be 4
ddply(data.sm,.(SITE, SEGMENT), summarize, num.repeats = n_distinct(METHOD)) #should = 2
# Plotting Regressions and Bland-Altman by Taxon --------------------------
### Separate 4 datasets and add the dataset name before the metric columns. Need to set up dataframe this way to make plotting easier.
d1<-data.sm[data.sm$MethodRep=="DIVER_1",];colnames(d1)[8:20] <- paste("d1", colnames(d1[8:20]), sep = "");d1<-subset(d1,select=-c(METHOD,SEGAREA_ad,MethodRep,TRANSECT,METHOD.1))
d2<-data.sm[data.sm$MethodRep=="DIVER_2",];colnames(d2)[8:20] <- paste("d2", colnames(d2[8:20]), sep = "");d2<-subset(d2,select=-c(METHOD,SEGAREA_ad,MethodRep,TRANSECT,METHOD.1))
sfm1<-data.sm[data.sm$MethodRep=="SfM_1",];colnames(sfm1)[8:20] <- paste("SfM1", colnames(sfm1[8:20]), sep = "");sfm1<-subset(sfm1,select=-c(METHOD,SEGAREA_ad,MethodRep,TRANSECT,METHOD.1))
sfm2<-data.sm[data.sm$MethodRep=="SfM_2",];colnames(sfm2)[8:20] <- paste("SfM2", colnames(sfm2[8:20]), sep = "");sfm2<-subset(sfm2,select=-c(METHOD,SEGAREA_ad,MethodRep,TRANSECT,METHOD.1))
#4 datasets together
df.all <- join_all(list(d1,d2,sfm1,sfm2), by= c("SITE","SITEVISITID","SEGMENT","GENUS_CODE","SS","OBS_YEAR","REGION","ISLAND","SEC_NAME","REEF_ZONE",
"DEPTH_BIN","HABITAT_CODE", "LATITUDE","LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M"), type='full');
head(df.all)
nrow(df.all)
ErrorComparision<-function(d,grouping_field="GENUS_CODE",metric_field="AdColDen"){
d$GROUP<-d[,grouping_field]
d$METRIC<-d[,metric_field]
d.new<-d[,c("METHOD","SITE","SITEVISITID","TRANSECT","GROUP","METRIC","MethodRep","SS")]
a1<-d.new[d.new$MethodRep %in% c("DIVER_1","SfM_1"),]
a1 <-dcast(a1, formula=SITE+SITEVISITID+GROUP+SS~METHOD,value.var="METRIC",fill=NA)
a2<-d.new[d.new$MethodRep %in% c("DIVER_2","SfM_2"),]
a2 <-dcast(a2, formula=SITE+SITEVISITID+GROUP+SS~METHOD,value.var="METRIC",fill=NA)
a3<-d.new[d.new$MethodRep %in% c("DIVER_1","SfM_2"),]
a3 <-dcast(a3, formula=SITE+SITEVISITID+GROUP+SS~METHOD,value.var="METRIC",fill=NA)
a4<-d.new[d.new$MethodRep %in% c("DIVER_2","SfM_1"),]
a4 <-dcast(a4, formula=SITE+SITEVISITID+GROUP+SS~METHOD,value.var="METRIC",fill=NA)
a5<-d.new[d.new$MethodRep %in% c("SfM_1","SfM_2"),]
a5 <-dcast(a5, formula=SITE+SITEVISITID+GROUP+SS~TRANSECT,value.var="METRIC",fill=NA)
colnames(a5)<-c("SITE","SITEVISITID","GROUP","SS","X","Y")
a5$Comp<-"S1vS2"
a6<-d.new[d.new$MethodRep %in% c("DIVER_1","DIVER_2"),]
a6 <-dcast(a6, formula=SITE+SITEVISITID+GROUP+SS~TRANSECT,value.var="METRIC",fill=NA)
colnames(a6)<-c("SITE","SITEVISITID","GROUP","SS","X","Y")
a6$Comp<-"D1vD2"
MO<-rbind(a1,a2,a3,a4); colnames(MO)<-c("SITE","SITEVISITID","GROUP","SS","X","Y"); MO$Comp<-"MO"
Obar<-ddply(d,.(SITE,SITEVISITID,GROUP,SS,METHOD),summarize,METRIC=mean(METRIC))
Obar.n <-dcast(Obar, formula=SITE+SITEVISITID+GROUP+SS~METHOD,value.var="METRIC",fill=NA)
colnames(Obar.n)<-c("SITE","SITEVISITID","GROUP","SS","X","Y")
Obar.n$Comp<-"Obar"
head(Obar.n)
Mbar<-ddply(d,.(SITE,SITEVISITID,GROUP,SS,TRANSECT),summarize,METRIC=mean(METRIC))
Mbar.n <-dcast(Mbar, formula=SITE+SITEVISITID+GROUP+SS~TRANSECT,value.var="METRIC",fill=NA)
colnames(Mbar.n)<-c("SITE","SITEVISITID","GROUP","SS","X","Y")
Mbar.n$Comp<-"Mbar"
head(Mbar.n)
all.comp<-rbind(MO,a5,a6,Obar.n,Mbar.n)
all.comp$Metric<-metric_field
colnames(all.comp)[which(colnames(all.comp) == 'GROUP')] <- grouping_field #change group to whatever your grouping field is.
return(all.comp)
}
####
ad.comp<-ErrorComparision(data.sm,"GENUS_CODE","AdColDen")
jd.comp<-ErrorComparision(data.sm,"GENUS_CODE","JuvColDen")
cl.comp<-ErrorComparision(data.sm,"GENUS_CODE","Ave.cl")
rd.comp<-ErrorComparision(data.sm,"GENUS_CODE","Ave.rd")
od.comp<-ErrorComparision(data.sm,"GENUS_CODE","Ave.od")
dz.comp<-ErrorComparision(data.sm,"GENUS_CODE","DZGN_G_prev")
ble.comp<-ErrorComparision(data.sm,"GENUS_CODE","BLE_prev")
chr.comp<-ErrorComparision(data.sm,"GENUS_CODE","CHRO_prev")
all.rmse<-rbind(ad.comp,jd.comp,cl.comp,od.comp,rd.comp,dz.comp,ble.comp,chr.comp)
#all.rmse<-rbind(ad.comp,jd.comp,dz.comp,cl.comp,rd.comp,od.comp)
bias_sc=function(X,Y){
del=(X-Y)
mn=apply(cbind(X,Y),1,mean,na.rm=T)
dm=0.5*del/mn
dm[which(mn==0)]=0
return(dm)
}
ae_sc=function(X,Y){
del=abs(X-Y)
mn=apply(cbind(X,Y),1,mean,na.rm=T)
dm=0.5*del/mn
dm[which(mn==0)]=0
return(dm)
}
meanbias_sc=function(X,Y){
return(mean(bias_sc(X,Y),na.rm=T))
}
medianbias_sc=function(X,Y){
return(median(bias_sc(X,Y),na.rm=T))
}
mae.mn=function(X,Y){
return(mean(abs(X-Y),na.rm=T))
}
mae.md=function(X,Y){
return(median(abs(X-Y),na.rm=T))
}
mae_sc=function(X,Y){
return(mean(ae_sc(X,Y),na.rm=T))
}
seae_sc=function(X,Y){
return(std.error(ae_sc(X,Y),na.rm=T))
}
mdae_sc=function(X,Y){
return(median(ae_sc(X,Y),na.rm=T))
}
rmse.mn=function(X,Y){
return(sqrt(mean((X-Y)^2,na.rm=T)))
}
rmse.md=function(X,Y){
return(sqrt(median((X-Y)^2,na.rm=T)))
}
log2AR=function(X,Y){
lar=log2(X/Y)
lar[is.infinite(lar)]=NA
lar[is.nan(lar)]=NA
return(lar)
}
all.rmse$delta=(all.rmse$X-all.rmse$Y)
all.rmse$mnXY=(all.rmse$Y+all.rmse$X)/2
all.rmse$L2delta=(log2(all.rmse$X)-log2(all.rmse$Y))
all.rmse$L2mnXY=(log2(all.rmse$Y)+log2(all.rmse$X))/2
all.rmse$Bias_SC=bias_sc(all.rmse$Y,all.rmse$X)
all.rmse$ae_sc=ae_sc(all.rmse$Y,all.rmse$X)
ssss.err=subset(all.rmse,GENUS_CODE=="SSSS"&Comp%in%c("D1vD2","S1vS2","MO"))
ssss.err$Metric=factor(ssss.err$Metric,
levels=c("AdColDen","JuvColDen","DZGN_G_prev","CHRO_prev",
"BLE_prev","Ave.cl","Ave.rd","Ave.od"))
ssss.err$Comp=factor(ssss.err$Comp,levels=c("D1vD2","S1vS2","MO"))
ssss.err.mnsd=ddply(ssss.err,.(Metric,Comp),summarize,
mean_mnXY=mean(mnXY,na.rm=T),
q75_mnXY=quantile(mnXY,probs = .75,na.rm=T),
q95_mnXY=quantile(mnXY,probs = .95,na.rm=T),
mean_delta=mean(delta,na.rm=T),
sd_delta=sd(delta,na.rm=T),
p_1t=t.test(delta,mu=0,alternative="two.sided")$p.value,
sigtext=if(p_1t<0.05){paste0("* p < ",signif(p_1t,2)," *")}else{"NS"})
dfError<-ddply(all.rmse,.(Metric,GENUS_CODE,Comp),
summarize,
N=length(X),
Nnz=length(which((X+Y)>0)),
Nz=length(which((X+Y)==0)),
Mean..=mean(rbind(Y,X),na.rm=T),
MeanBias=mean(Y-X,na.rm=T),
MedianBias=median(Y-X,na.rm=T),
MeanBias_sc=meanbias_sc(Y,X),
MedianBias_sc=medianbias_sc(Y,X),
MAE.mn=mean(abs(Y-X),na.rm=T),
MAE.md=median(abs(Y-X),na.rm=T),
MAE_sc.mn=mae_sc(Y,X),
MAE_sc.se=seae_sc(Y,X),
MAE_sc.md=mdae_sc(Y,X),
RMSE.mn=rmse.mn(Y,X),
RMSE.md=rmse.md(Y,X),
Log2AR_mn=mean(log2AR(X,Y),na.rm = T),
Log2AR_se=sd(log2AR(X,Y),na.rm=T)/sqrt(length(X)))
rmse.ssss<-subset(dfError,GENUS_CODE=="SSSS"&Comp%in%c("D1vD2","S1vS2","MO"))
rmse.ssss<-rmse.ssss %>% mutate(Comp=recode(Comp,
`D1vD2`="In water Observer",
#                                           `Mbar`="NA",
`MO`="Method Error",
#                                          `Obar`="NA",
`S1vS2`="SfM Observer"))
comporder<-c("In water Observer","SfM Observer","Method Error")
rmse.ssss <- rmse.ssss[ order(match(rmse.ssss$Comp, comporder)),]
rmse.ssss$Comp<-as.character(rmse.ssss$Comp)
rmse.ssss$Comp<-factor(rmse.ssss$Comp, levels = comporder)
rmse.ssss$Metric<-as.character(rmse.ssss$Metric)
rmse.ssss$Metric<-factor(rmse.ssss$Metric,
levels=c("AdColDen","JuvColDen","DZGN_G_prev","CHRO_prev",
"BLE_prev","Ave.cl","Ave.rd","Ave.od"))
#Scaled MAE plot for report
#Changing metric names to make more sense
rmse.ssss<-rmse.ssss %>% mutate(Metric.new=recode(Metric,
`AdColDen`="`Adult Density`",
`Ave.cl`="`Average Colony Length`",
`Ave.od`="`Average Old Dead`",
`Ave.rd`="`Average Recent Dead`",
`BLE_prev`="`Bleaching Prevalence`",
`CHRO_prev`="`Chronic Disease Prevalence`",
`DZGN_G_prev`="`Acute Disease Prevalence`",
`JuvColDen`="`Juvenile Density`"))
head(rmse.ssss)
hist(rmse.ssss$AdColDen))
hist(rmse.ssss$AdColDen)
View(rmse.ssss)
View(all.rmse)
head(all.rmse)
rmse.sub<-subset(all.rmse,GENUS_CODE=="SSSS")
head(rmse.sub)
#Identify significant difference between error types
rmse.sub<-subset(all.rmse,GENUS_CODE=="SSSS" & Metric=="AdColDen")
hist(rmse.sub$Metric)
hist(rmse.sub$ae_sc)
rmse.sub$sqae_sc<-sqrt(rmse.sub$ae_sc)
m<-lm(sqae_sc~Comp,data=rmse.sub)
DPlots<-function(m){
par(mfrow=c(2,2)) # make the subplots
qqnorm(resid(m))
E2<-resid(m, type = "response") # extract normalized residuals
F2<-fitted(m) # extract the fitted data
plot(F2, E2, xlab = "fitted values", ylab = "residuals") # plot the relationship
abline(h = 0, lty = 2) # add a flat line at zero
}
DPlots(m)
rmse.sub$sqae_sc<-log(rmse.sub$ae_sc+0.5)
m<-lm(sqae_sc~Comp,data=rmse.sub)
DPlots<-function(m){
par(mfrow=c(2,2)) # make the subplots
qqnorm(resid(m))
E2<-resid(m, type = "response") # extract normalized residuals
F2<-fitted(m) # extract the fitted data
plot(F2, E2, xlab = "fitted values", ylab = "residuals") # plot the relationship
abline(h = 0, lty = 2) # add a flat line at zero
}
DPlots(m)
hist(log(rmse.sub$ae_sc+0.5))
hist(rmse.sub$ae_sc)
View(rmse.sub)
library("TeachingDemos")
library(MASS)
a<-rmse.sub$ae_sc + 0.5
boxcox(a~rmse.sub$Comp)
boxcox(a~ffs$Comp, lambda=seq(-3,1))
boxcox(a~rmse.sub$Comp, lambda=seq(-3,1))
dp<-bct(a,-2.1)
m<-lm(dp~Comp,data=rmse.sub)
DPlots<-function(m){
par(mfrow=c(2,2)) # make the subplots
qqnorm(resid(m))
E2<-resid(m, type = "response") # extract normalized residuals
F2<-fitted(m) # extract the fitted data
plot(F2, E2, xlab = "fitted values", ylab = "residuals") # plot the relationship
abline(h = 0, lty = 2) # add a flat line at zero
}
DPlots(m)
hist(dp)
dp<-bct(a,-2.2)
m<-lm(dp~Comp,data=rmse.sub)
DPlots<-function(m){
par(mfrow=c(2,2)) # make the subplots
qqnorm(resid(m))
E2<-resid(m, type = "response") # extract normalized residuals
F2<-fitted(m) # extract the fitted data
plot(F2, E2, xlab = "fitted values", ylab = "residuals") # plot the relationship
abline(h = 0, lty = 2) # add a flat line at zero
}
DPlots(m)
hist(dp)
wilcox.test(ae_se ~ Comp, data=rmse.sub)
wilcox.test(ae_sc ~ Comp, data=rmse.sub)
wilcox.test(ae_sc ~ Comp, data=rmse.sub)
kruskal.test(ae_sc ~ Comp, data=rmse.sub)
install.packages("FSA")
library(FSA)
kruskal.test(ae_sc ~ Comp, data=rmse.sub)
DT<-dunnTest(ae_sc ~ Comp, data=rmse.sub,
method="bh")
DT
rmse.sub<-subset(all.rmse,GENUS_CODE=="SSSS"&Comp%in%c("D1vD2","S1vS2","MO")&Metric=="AdColDen")
rmse.sub<-rmse.sub %>% mutate(Comp=recode(Comp,
`D1vD2`="In water Observer",
#                                           `Mbar`="NA",
`MO`="Method Error",
#                                          `Obar`="NA",
`S1vS2`="SfM Observer"))
hist(rmse.sub$ae_sc)
rmse.sub$sqae_sc<-log(rmse.sub$ae_sc+0.5)
m<-lm(sqae_sc~Comp,data=rmse.sub)
DPlots<-function(m){
par(mfrow=c(2,2)) # make the subplots
qqnorm(resid(m))
E2<-resid(m, type = "response") # extract normalized residuals
F2<-fitted(m) # extract the fitted data
plot(F2, E2, xlab = "fitted values", ylab = "residuals") # plot the relationship
abline(h = 0, lty = 2) # add a flat line at zero
}
DPlots(m)
library(FSA)
kruskal.test(ae_sc ~ Comp, data=rmse.sub)
DT<-dunnTest(ae_sc ~ Comp, data=rmse.sub,
method="bh")
dunnTest(ae_sc ~ Comp, data=rmse.sub,
method="bh")
# This script will reads in the CLEANED/Analysis ready data that was generated using the following script
#C:\Users\Courtney.S.Couch\Documents\GitHub\Benthic-Scripts\REA_CoralDemography\Generate REA data\REA Coral Demography_DataPrep.R
#The script does some final tweaks to the data then generates Site-level data
#These data only include surveys conducted between 2013-2019
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data
awd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
jwd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
# awd<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
# jwd<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
#Final Tweaks before calculating Site-level data-------------------------------------------------
#Colony fragments and scleractinans are subseted in the functions
#Add a column for adult fragments so we can remove them from the dataset later (-1 indicates fragment)
# awd<-CreateFragment(awd)
awd$Fragment<-ifelse(awd$OBS_YEAR <2018 & awd$COLONYLENGTH <5 & awd$S_ORDER=="Scleractinia",-1,awd$Fragment)
head(subset(awd,Fragment==-1& OBS_YEAR<2018)) #double check that pre 2018 fragments create
awd$Fragment[is.na(awd$Fragment)] <- 0
jwd$Fragment <- 0 # you need to add this column so that you can use the site level functions correctly
#Simplify Bleaching Severity categories: in 2019 the team decided to simplify the bleaching severity from 1-5 to 1-3 to improve consistency in severity values
#This code converts the severity data collected prior to 2019 to a 1-3 scale
awd$DATE_ <- as.Date(awd$DATE_, format = "%Y-%m-%d")
jwd$DATE_ <- as.Date(jwd$DATE_, format = "%Y-%m-%d")
awd_pre <- awd %>% filter(DATE_ < as.Date('2019-07-11'))
awd_post<-awd %>% filter(DATE_ >= as.Date('2019-07-11'))
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_1","SEVERITY_1n")
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_2","SEVERITY_2n")
#awd_pre<-Convert_Severity(awd_pre,"SEVERITY_3","SEVERITY_3n") #There were no severity measurements prior to 2020
head(awd_pre)
#View(awd_pre)
#After checking that severity numbers were changed correctly, convert back to original column names & drop original columns
awd_pre<-subset(awd_pre,select=-c(SEVERITY_1));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_1n')] <- "SEVERITY_1" #change group to whatever your grouping field is.
awd_pre<-subset(awd_pre,select=-c(SEVERITY_2));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_2n')] <- "SEVERITY_2" #change group to whatever your grouping field is.
#awd_pre<-subset(awd_pre,select=-c(SEVERITY_3));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_3n')] <- "SEVERITY_3" #change group to whatever your grouping field is.
awd_pre$SEVERITY_3<-NA
head(awd_pre)
#Combine dataframes before and after 2019 & check that rows weren't dropped
awd.<-rbind(awd_pre,awd_post);write.csv(awd.,"test.csv")
#Do we want to remove these there are a lot of them.
#awd.$CONDITION_1<-ifelse(awd.$CONDITION_1 %in% c("BLE","BLP") & is.na(SEVERITY_1),"NDZ",as.character(awd.$CONDITION_1))
nrow(awd)
nrow(awd.);head(awd.)
awd<-awd.; rm("awd.") #remove temporary dataframe if all good.
#Create a look a table of all of the colony attributes- you will need this the functions below
SURVEY_COL<-c("DATE_","SITEVISITID", "OBS_YEAR", "REGION", "REGION_NAME", "ISLAND","ISLANDCODE","SEC_NAME", "SITE", "REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M","TRANSECT","SEGMENT","COLONYID","GENUS_CODE","TAXONCODE","SPCODE","COLONYLENGTH")
survey_colony<-unique(awd[,SURVEY_COL])#new_Aggregate_InputTable(awd, SURVEY_INFO)#TAO 2019/10/07
SURVEY_SITE<-c("MISSIONID","DATE_","SITEVISITID", "ANALYSIS_YEAR","OBS_YEAR", "REGION", "REGION_NAME", "ISLAND","ISLANDCODE","SEC_NAME", "SITE", "REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M","HABITAT_CODE")
survey_siteAd<-unique(awd[,SURVEY_SITE])#new_Aggregate_InputTable(awd, SURVEY_INFO)#TAO 2019/10/07
SURVEY_SITE<-c("MISSIONID","DATE_","SITEVISITID", "ANALYSIS_YEAR","OBS_YEAR", "REGION", "REGION_NAME", "ISLAND","ISLANDCODE","SEC_NAME", "SITE", "REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M")
survey_siteJ<-unique(jwd[,SURVEY_SITE])#new_Aggregate_InputTable(awd, SURVEY_INFO)#TAO 2019/10/07
table(survey_siteAd$OBS_YEAR,survey_siteAd$REGION)
137-81
137+81
14/4
2*2
2*6
7*45
315/60
3*45
135/60
2.5*200
500/40/4
9.5*200
1900/40/4
2.25*200
450/40/4
7*4
7*4*4
sm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
head(sfm)
head(sm)
fish<-subset(sm,Fish==1)
head(fish)
table(fish$REGION,fish$OBS_YEAR)
30/17
300*1.76
528/40/4
10.5*200
10.5*200
2100/730
9.5*200
1900/40/4
11.87+5.
18*4
72*3
4.5*200
200/*4.5
200/4.5
200/3
66*3
198/30
5+28+5+1+0.5
3.5+12+16.87+1.5+0.5
s<-subset(site,GENUS_CODE=="SSSS")
hist(log(s$AdColDen))
s$sqAdColDen<-sqrt(s$AdColDen)
#This script reads in the diver and SfM-generated demographic data that has been QC'd and cleaned up
#Then generates segment-level summarized that for methods comparision
rm(list=ls())
#LOAD LIBRARY FUNCTIONS ...
library(gridExtra)
library(reshape2)
library(plyr)
#install.packages("ggpmisc")
library(hydroGOF)
library(tidyverse)
library(ggpmisc)
library(lme4)
library(ggplot2)
library(sjPlot)
library(pander)
library(tidyr)
library(AICcmodavg)
library(MuMIn)
library(knitr)
library(glmmTMB)
source("T:/Benthic/Data/SfM/ScriptFiles/SfMvDiver Plotting Functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
setwd("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision")
#Read in files
seg<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_GENUS_SEGMENT.csv")
site<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_GENUS_SITE.csv")
# #Select columns to keep in segment data
seg<-dplyr::select(seg, c(METHOD,SITE,SITEVISITID,SEGMENT,GENUS_CODE,ANALYST,SEGAREA_ad,SEGAREA_j,AdColCount,AdColDen,JuvColDen,Ave.size,Ave.od,Ave.rd,
BLE_prev,AcuteDZ_prev,ChronicDZ_prev,ISLAND,SEC_NAME,DEPTH_BIN,LATITUDE,LONGITUDE,HABITAT_CODE,
MIN_DEPTH_M,MAX_DEPTH_M))
head(seg)
seg$SQAdColDen<-sqrt(seg$AdColDen)
head(seg)
seg$SQAdColDen
seg<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_GENUS_SEGMENT.csv")
12/28
(28-12)/28
10271-2500
