mtmp<-merge(tmp2,tmp,all.x=T)
mtmp
head(mtmp)
head(tmp)
head(tmp,10);head(mtmp)
head(tmp,10);head(mtmp,10)
tmp<-ddply(j_sfm,.(METHOD,SITE_SEG,ANALYST),summarize,n=length(COLONYID)) #identify # of colonies surveyed for each method, ss and annotoator
tmp2<-ddply(tmp,.(METHOD,SITE_SEG),summarize,n=max(n)) #identify the max number of colonies/seg and merge back with tmp to identify primary annoator
jtmp<-merge(tmp2,tmp,all.x=T)
head(tmp,10);head(jtmp,10)
head(ad_sfm)
?left_join
tmp<-ddply(ad_sfm,.(METHOD,SITE_SEG,ANALYST),summarize,n=length(COLONYID)) #identify # of colonies surveyed for each method, ss and annotoator
tmp2<-ddply(tmp,.(METHOD,SITE_SEG),summarize,n=max(n)) #identify the max number of colonies/seg and merge back with tmp to identify primary annoator
atmp<-left_join(tmp2,tmp)
head(tmp,10);head(atmp,10)
colnames(atmp)[colnames(atmp)=="ANALYST"]<-"N.ANALYST" #Change column name
head(atmp)
atmp<-subet(atmp,select=-n)
atmp<-subset(atmp,select=-n)
head(atmp)
test<-left_join(ad_sfm,atmp)
nrow(ad_sfm)
nrow(test)
test<-merge(ad_sfm,atmp,all.x=T)
test<-merge(ad_sfm,atmp,all=T)
View(test)
test[rowSums(is.na(test)) > 0,]
test[rowSums(is.na(test$MISSIONID)) > 0,]
test[rowSums(is.na(test$ANALYST)) > 0,]
test<-left_join(ad_sfm,atmp)
nrow(test)
length(unique(test$SITE))
length(unique(test$SITE_SEG))
levels(test$SITE)
levels(test$SITE_SEG)
levels(as.factor(test$SITE_SEG))
ad_sfmN<-left_join(ad_sfm,atmp)
length(unique(ad_sfmN$SITE_SEG));length(unique(ad_sfmN$SITE_SEG))# double check that numbers match Site should be 104
ad_sfmN<-subset(ad_sfmN,select=-ANALYST);colnames(Jtmp)[colnames(Jtmp)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(ad_sfmN)
ad_sfmN<-left_join(ad_sfm,atmp)
length(unique(ad_sfmN$SITE_SEG));length(unique(ad_sfmN$SITE_SEG))# double check that numbers match Site should be 104
ad_sfmN<-subset(ad_sfmN,select=-ANALYST);colnames(ad_sfmN)[colnames(ad_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(ad_sfmN)
ad_sfmN<-left_join(ad_sfm,atmp)
length(unique(ad_sfmN$SITE));length(unique(ad_sfmN$SITE_SEG))# double check that numbers match Site should be 104
ad_sfmN<-subset(ad_sfmN,select=-ANALYST);colnames(ad_sfmN)[colnames(ad_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(ad_sfmN)
j_sfmN<-left_join(j_sfm,jtmp)
length(unique(j_sfmN$SITE));length(unique(j_sfmN$SITE_SEG))# double check that numbers match Site should be 104
j_sfmN<-subset(j_sfmN,select=-ANALYST);colnames(j_sfmN)[colnames(j_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(j_sfmN)
#This script reads in the diver and SfM-generated demographic data that has been QC'd and cleaned up
#Then generates segment-level summarized that for methods comparision
rm(list=ls())
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
#Read in files
ad_sfm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_SfMAdult_MCLEANED.csv")
j_sfm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_SfMJuv_MCLEANED.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#Double check that the number of segments in the geodatabase matches what annoators said they completed
#metadata file manually assembled from the tracking sheet pulled from google drive
meta<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP2019_SfM_Meta.csv")
meta<-meta[,c("ISLAND","SITE","Mosaic_Issues","Segments_Annotated","Rugosity")]
head(meta)
# #Missing segments from geodatabase FOR ADULTS
# seg_tally<-ddply(ad_sfm,.(ISLAND,SITE),
#                  summarize,
#                  Segments_inGD=length(unique(SEGMENT)))
#
# tmp.seg<-full_join(meta,seg_tally)
# View(tmp.seg)
#
# miss.seg<-dplyr::filter(tmp.seg, Segments_Annotated !=Segments_inGD);miss.seg #identify sites that have missing segments
# miss.site<-dplyr::filter(tmp.seg, is.na(Segments_inGD));miss.site #identify sites that have missing segments
#
#
# #Missing segments from geodatabase FOR JUV
# seg_tally<-ddply(j_sfm,.(ISLAND,SITE),
#                  summarize,
#                  Segments_inGD=length(unique(SEGMENT)))
#
#
# tmp.seg<-full_join(meta,seg_tally)
# View(tmp.seg)
#
# miss.seg<-dplyr::filter(tmp.seg, Segments_Annotated !=Segments_inGD);miss.seg #identify sites that have missing segments
# miss.site<-dplyr::filter(tmp.seg, is.na(Segments_inGD));miss.site #identify sites that have missing segments
#
ad_sfm$TRANSECTAREA<-Transectarea(ad_sfm)
j_sfm$TRANSECTAREA<-Transectarea(j_sfm)
#Double check transect areas
summary(j_sfm$TRANSECTAREA)
summary(ad_sfm$TRANSECTAREA)
# head(subset(j_sfm,TRANSECTAREA==4.5)) #look at site LAN-01813
# View(subset(j_sfm,SITE=="LAN-01813"))
#Check if any site-segments have been dropped
ad_sfm$SITE_SEG<-paste(ad_sfm$SITE,ad_sfm$SEGMENT,sep ="_")
j_sfm$SITE_SEG<-paste(j_sfm$SITE,j_sfm$SEGMENT,sep ="_")
length(unique(ad_sfm$SITE_SEG));length(unique(ad_sfm$SITE)) #should be 389 ss and 104 sites
length(unique(j_sfm$SITE_SEG));length(unique(j_sfm$SITE)) #should be 312 ss and 104 sites
#Need to identify 1 analyst per segment
#Because we had different people go back and make some corrections on the belts,we may have more than 1 person on a segment.
#But the annoations are not evenly distributed across the 2 annoators (e.g. annoator 1 may have annoated 15 colonies and #2 only did 2)
#This won't work for the mixed models, so I've identified the person with the max number of annoatations and labeled them as the annoator of the full segment
#It's not perfect, but the best we can do right now.
#Adults
tmp<-ddply(ad_sfm,.(METHOD,SITE_SEG,ANALYST),summarize,n=length(COLONYID)) #identify # of colonies surveyed for each method, ss and annotoator
tmp2<-ddply(tmp,.(METHOD,SITE_SEG),summarize,n=max(n)) #identify the max number of colonies/seg and merge back with tmp to identify primary annoator
atmp<-left_join(tmp2,tmp)
head(tmp,10);head(atmp,10)
colnames(atmp)[colnames(atmp)=="ANALYST"]<-"N.ANALYST" #Change column name
atmp<-subset(atmp,select=-n)
#Juveniles
tmp<-ddply(j_sfm,.(METHOD,SITE_SEG,ANALYST),summarize,n=length(COLONYID)) #identify # of colonies surveyed for each method, ss and annotoator
tmp2<-ddply(tmp,.(METHOD,SITE_SEG),summarize,n=max(n)) #identify the max number of colonies/seg and merge back with tmp to identify primary annoator
jtmp<-left_join(tmp2,tmp)
head(tmp,10);head(jtmp,10)
colnames(jtmp)[colnames(jtmp)=="ANALYST"]<-"N.ANALYST" #Change column name
jtmp<-subset(jtmp,select=-n)
#Merge back to original dataframe and change column names
ad_sfmN<-left_join(ad_sfm,atmp)
length(unique(ad_sfmN$SITE));length(unique(ad_sfmN$SITE_SEG))# double check that numbers match Site should be 104 and 389
ad_sfmN<-subset(ad_sfmN,select=-ANALYST);colnames(ad_sfmN)[colnames(ad_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(ad_sfmN)
j_sfmN<-left_join(j_sfm,jtmp)
length(unique(j_sfmN$SITE));length(unique(j_sfmN$SITE_SEG))# double check that numbers match Site should be 104 and 312
j_sfmN<-subset(j_sfmN,select=-ANALYST);colnames(j_sfmN)[colnames(j_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(j_sfmN)
# PREP VISUAL DIVER DATA ---------------------------------------------
## LOAD benthic data
# awd_<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
# jwd_<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
awd_<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_E_raw_CLEANED.csv")
jwd_<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_F_raw_CLEANED.csv")
awd<-subset(awd_,OBS_YEAR=="2019"&TRANSECT==1)
jwd<-subset(jwd_,OBS_YEAR=="2019"&TRANSECT==1)
#Colony fragments and scleractinans are subseted in the functions
#Add a column for adult fragments so we can remove them from the dataset later (-1 indicates fragment)
awd$Fragment<-ifelse(awd$OBS_YEAR <2018 & awd$COLONYLENGTH <5 & awd$S_ORDER=="Scleractinia",-1,awd$Fragment)
head(subset(awd,Fragment==-1& OBS_YEAR<2018)) #double check that pre 2018 fragments create
awd$Fragment[is.na(awd$Fragment)] <- 0
jwd$Fragment <- 0 # you need to add this column so that you can use the site level functions correctly
#Simplify Bleaching Severity categories: in 2019 the team decided to simplify the bleaching severity from 1-5 to 1-3 to improve consistency in severity values
#This code converts the severity data collected prior to 2019 to a 1-3 scale
awd$DATE_ <- as.Date(awd$DATE_, format = "%Y-%m-%d")
jwd$DATE_ <- as.Date(jwd$DATE_, format = "%Y-%m-%d")
awd_pre <- awd %>% filter(DATE_ < as.Date('2019-07-11'))
awd_post<-awd %>% filter(DATE_ >= as.Date('2019-07-11'))
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_1","SEVERITY_1n")
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_2","SEVERITY_2n")
#awd_pre<-Convert_Severity(awd_pre,"SEVERITY_3","SEVERITY_3n") #There were no severity measurements prior to 2020
head(awd_pre)
#After checking that severity numbers were changed correctly, convert back to original column names & drop original columns
awd_pre<-subset(awd_pre,select=-c(SEVERITY_1));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_1n')] <- "SEVERITY_1" #change group to whatever your grouping field is.
awd_pre<-subset(awd_pre,select=-c(SEVERITY_2));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_2n')] <- "SEVERITY_2" #change group to whatever your grouping field is.
#awd_pre<-subset(awd_pre,select=-c(SEVERITY_3));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_3n')] <- "SEVERITY_3" #change group to whatever your grouping field is.
awd_pre$SEVERITY_3<-NA
head(awd_pre)
#Combine dataframes before and after 2019 & check that rows weren't dropped
awd.<-rbind(awd_pre,awd_post);write.csv(awd.,"test.csv")
#Change bleaching severity = 1 to NA
awd.<-awd. %>% mutate_at(.vars = c("CONDITION_1", "EXTENT_1", "SEVERITY_1"),
list(~replace(.,CONDITION_1 =='BLE' & SEVERITY_1=='1', NA)));View(awd.)
awd.<-awd. %>% mutate_at(.vars = c("CONDITION_2", "EXTENT_2", "SEVERITY_2"),
list(~replace(.,CONDITION_2 =='BLE' & SEVERITY_2=='1', NA)))
awd.<-awd. %>% mutate_at(.vars = c("CONDITION_3", "EXTENT_3", "SEVERITY_3"),
list(~replace(.,CONDITION_3 =='BLE' & SEVERITY_3=='1', NA)))
nrow(awd)
nrow(awd.);head(awd.)
awd<-awd.; rm("awd.") #remove temporary dataframe if all good.
#Change columns to merge with sfm data
colnames(awd)[which(colnames(awd) == 'DIVER')] <- "ANALYST"
colnames(jwd)[which(colnames(jwd) == 'DIVER')] <- "ANALYST"
awd$EX_BOUND<-0;awd$EX_BOUND<-as.numeric(awd$EX_BOUND)
jwd$EX_BOUND<-0;jwd$EX_BOUND<-as.numeric(jwd$EX_BOUND)
#Only include sites and segments surveyed by divers during HARAMP 2019
awd$SITE_SEG<-paste(awd$SITE,awd$SEGMENT,sep="_")
jwd$SITE_SEG<-paste(jwd$SITE,jwd$SEGMENT,sep="_")
awd$SEGAREA<-awd$SEGLENGTH*awd$SEGWIDTH
jwd$SEGAREA<-jwd$SEGLENGTH*jwd$SEGWIDTH
awd<-dplyr::select(awd,-c(bANALYSIS_SCHEME,ANALYSIS_YEAR,EXCLUDE_FLAG,REGION_NAME,NO_SURVEY_YN,DATE_,ISLANDCODE))
jwd<-dplyr::select(jwd,-c(bANALYSIS_SCHEME,ANALYSIS_YEAR,EXCLUDE_FLAG,REGION_NAME,NO_SURVEY_YN,DATE_,ISLANDCODE))
awd<-dplyr::filter(awd, SITE_SEG %in% c(ad_sfm$SITE_SEG));head(awd)
jwd<-dplyr::filter(jwd, SITE_SEG %in% c(j_sfm$SITE_SEG));head(jwd)
#Remove segments that were annoated in SfM, but not surveyd by divers
ad_sfm_sub<-dplyr::filter(ad_sfmN, SITE_SEG %in% c(awd$SITE_SEG));nrow(ad_sfm);nrow(ad_sfm_sub)
j_sfm_sub<-dplyr::filter(j_sfmN, SITE_SEG %in% c(awd$SITE_SEG));nrow(j_sfm);nrow(j_sfm_sub)
unique(length(awd$SITE))
length(unique(awd$SITE))
ad_sfm_sub<-dplyr::filter(ad_sfmN, SITE_SEG %in% c(awd$SITE_SEG));nrow(ad_sfm);nrow(ad_sfm_sub)
j_sfm_sub<-dplyr::filter(j_sfmN, SITE_SEG %in% c(awd$SITE_SEG));nrow(j_sfm);nrow(j_sfm_sub)
length(unique(ad_sfm_sub$SITE))
length(unique(j_sfm_sub$SITE))
length(unique(ad_sfm_sub$SITE));length(unique(ad_sfm_sub$SITE_SEG))
length(unique(j_sfm_sub$SITE));length(unique(j_sfm_sub$SITE_SEG))
#This script reads in the diver and SfM-generated demographic data that has been QC'd and cleaned up
#Then generates segment-level summarized that for methods comparision
rm(list=ls())
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
#Read in files
ad_sfm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_SfMAdult_MCLEANED.csv")
j_sfm<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_SfMJuv_MCLEANED.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#Double check that the number of segments in the geodatabase matches what annoators said they completed
#metadata file manually assembled from the tracking sheet pulled from google drive
meta<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP2019_SfM_Meta.csv")
meta<-meta[,c("ISLAND","SITE","Mosaic_Issues","Segments_Annotated","Rugosity")]
head(meta)
# #Missing segments from geodatabase FOR ADULTS
# seg_tally<-ddply(ad_sfm,.(ISLAND,SITE),
#                  summarize,
#                  Segments_inGD=length(unique(SEGMENT)))
#
# tmp.seg<-full_join(meta,seg_tally)
# View(tmp.seg)
#
# miss.seg<-dplyr::filter(tmp.seg, Segments_Annotated !=Segments_inGD);miss.seg #identify sites that have missing segments
# miss.site<-dplyr::filter(tmp.seg, is.na(Segments_inGD));miss.site #identify sites that have missing segments
#
#
# #Missing segments from geodatabase FOR JUV
# seg_tally<-ddply(j_sfm,.(ISLAND,SITE),
#                  summarize,
#                  Segments_inGD=length(unique(SEGMENT)))
#
#
# tmp.seg<-full_join(meta,seg_tally)
# View(tmp.seg)
#
# miss.seg<-dplyr::filter(tmp.seg, Segments_Annotated !=Segments_inGD);miss.seg #identify sites that have missing segments
# miss.site<-dplyr::filter(tmp.seg, is.na(Segments_inGD));miss.site #identify sites that have missing segments
#
ad_sfm$TRANSECTAREA<-Transectarea(ad_sfm)
j_sfm$TRANSECTAREA<-Transectarea(j_sfm)
#Double check transect areas
summary(j_sfm$TRANSECTAREA)
summary(ad_sfm$TRANSECTAREA)
# head(subset(j_sfm,TRANSECTAREA==4.5)) #look at site LAN-01813
# View(subset(j_sfm,SITE=="LAN-01813"))
#Check if any site-segments have been dropped
ad_sfm$SITE_SEG<-paste(ad_sfm$SITE,ad_sfm$SEGMENT,sep ="_")
j_sfm$SITE_SEG<-paste(j_sfm$SITE,j_sfm$SEGMENT,sep ="_")
length(unique(ad_sfm$SITE_SEG));length(unique(ad_sfm$SITE)) #should be 389 ss and 104 sites
length(unique(j_sfm$SITE_SEG));length(unique(j_sfm$SITE)) #should be 312 ss and 104 sites
#Need to identify 1 analyst per segment
#Because we had different people go back and make some corrections on the belts,we may have more than 1 person on a segment.
#But the annoations are not evenly distributed across the 2 annoators (e.g. annoator 1 may have annoated 15 colonies and #2 only did 2)
#This won't work for the mixed models, so I've identified the person with the max number of annoatations and labeled them as the annoator of the full segment
#It's not perfect, but the best we can do right now.
#Adults
tmp<-ddply(ad_sfm,.(METHOD,SITE_SEG,ANALYST),summarize,n=length(COLONYID)) #identify # of colonies surveyed for each method, ss and annotoator
tmp2<-ddply(tmp,.(METHOD,SITE_SEG),summarize,n=max(n)) #identify the max number of colonies/seg and merge back with tmp to identify primary annoator
atmp<-left_join(tmp2,tmp)
head(tmp,10);head(atmp,10)
colnames(atmp)[colnames(atmp)=="ANALYST"]<-"N.ANALYST" #Change column name
atmp<-subset(atmp,select=-n)
#Juveniles
tmp<-ddply(j_sfm,.(METHOD,SITE_SEG,ANALYST),summarize,n=length(COLONYID)) #identify # of colonies surveyed for each method, ss and annotoator
tmp2<-ddply(tmp,.(METHOD,SITE_SEG),summarize,n=max(n)) #identify the max number of colonies/seg and merge back with tmp to identify primary annoator
jtmp<-left_join(tmp2,tmp)
head(tmp,10);head(jtmp,10)
colnames(jtmp)[colnames(jtmp)=="ANALYST"]<-"N.ANALYST" #Change column name
jtmp<-subset(jtmp,select=-n)
#Merge back to original dataframe and change column names
ad_sfmN<-left_join(ad_sfm,atmp)
length(unique(ad_sfmN$SITE));length(unique(ad_sfmN$SITE_SEG))# double check that numbers match Site should be 104 and 389
ad_sfmN<-subset(ad_sfmN,select=-ANALYST);colnames(ad_sfmN)[colnames(ad_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(ad_sfmN)
j_sfmN<-left_join(j_sfm,jtmp)
length(unique(j_sfmN$SITE));length(unique(j_sfmN$SITE_SEG))# double check that numbers match Site should be 104 and 312
j_sfmN<-subset(j_sfmN,select=-ANALYST);colnames(j_sfmN)[colnames(j_sfmN)=="N.ANALYST"]<-"ANALYST" #Change back to ANALYST
View(j_sfmN)
# PREP VISUAL DIVER DATA ---------------------------------------------
## LOAD benthic data
# awd_<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
# jwd_<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
awd_<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_E_raw_CLEANED.csv")
jwd_<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_F_raw_CLEANED.csv")
awd<-subset(awd_,OBS_YEAR=="2019"&TRANSECT==1)
jwd<-subset(jwd_,OBS_YEAR=="2019"&TRANSECT==1)
#Colony fragments and scleractinans are subseted in the functions
#Add a column for adult fragments so we can remove them from the dataset later (-1 indicates fragment)
awd$Fragment<-ifelse(awd$OBS_YEAR <2018 & awd$COLONYLENGTH <5 & awd$S_ORDER=="Scleractinia",-1,awd$Fragment)
head(subset(awd,Fragment==-1& OBS_YEAR<2018)) #double check that pre 2018 fragments create
awd$Fragment[is.na(awd$Fragment)] <- 0
jwd$Fragment <- 0 # you need to add this column so that you can use the site level functions correctly
#Simplify Bleaching Severity categories: in 2019 the team decided to simplify the bleaching severity from 1-5 to 1-3 to improve consistency in severity values
#This code converts the severity data collected prior to 2019 to a 1-3 scale
awd$DATE_ <- as.Date(awd$DATE_, format = "%Y-%m-%d")
jwd$DATE_ <- as.Date(jwd$DATE_, format = "%Y-%m-%d")
awd_pre <- awd %>% filter(DATE_ < as.Date('2019-07-11'))
awd_post<-awd %>% filter(DATE_ >= as.Date('2019-07-11'))
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_1","SEVERITY_1n")
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_2","SEVERITY_2n")
#awd_pre<-Convert_Severity(awd_pre,"SEVERITY_3","SEVERITY_3n") #There were no severity measurements prior to 2020
head(awd_pre)
#After checking that severity numbers were changed correctly, convert back to original column names & drop original columns
awd_pre<-subset(awd_pre,select=-c(SEVERITY_1));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_1n')] <- "SEVERITY_1" #change group to whatever your grouping field is.
awd_pre<-subset(awd_pre,select=-c(SEVERITY_2));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_2n')] <- "SEVERITY_2" #change group to whatever your grouping field is.
#awd_pre<-subset(awd_pre,select=-c(SEVERITY_3));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_3n')] <- "SEVERITY_3" #change group to whatever your grouping field is.
awd_pre$SEVERITY_3<-NA
head(awd_pre)
#Combine dataframes before and after 2019 & check that rows weren't dropped
awd.<-rbind(awd_pre,awd_post);write.csv(awd.,"test.csv")
#Change bleaching severity = 1 to NA
awd.<-awd. %>% mutate_at(.vars = c("CONDITION_1", "EXTENT_1", "SEVERITY_1"),
list(~replace(.,CONDITION_1 =='BLE' & SEVERITY_1=='1', NA)));View(awd.)
awd.<-awd. %>% mutate_at(.vars = c("CONDITION_2", "EXTENT_2", "SEVERITY_2"),
list(~replace(.,CONDITION_2 =='BLE' & SEVERITY_2=='1', NA)))
awd.<-awd. %>% mutate_at(.vars = c("CONDITION_3", "EXTENT_3", "SEVERITY_3"),
list(~replace(.,CONDITION_3 =='BLE' & SEVERITY_3=='1', NA)))
nrow(awd)
nrow(awd.);head(awd.)
awd<-awd.; rm("awd.") #remove temporary dataframe if all good.
#Change columns to merge with sfm data
colnames(awd)[which(colnames(awd) == 'DIVER')] <- "ANALYST"
colnames(jwd)[which(colnames(jwd) == 'DIVER')] <- "ANALYST"
awd$EX_BOUND<-0;awd$EX_BOUND<-as.numeric(awd$EX_BOUND)
jwd$EX_BOUND<-0;jwd$EX_BOUND<-as.numeric(jwd$EX_BOUND)
#Only include sites and segments surveyed by divers during HARAMP 2019
awd$SITE_SEG<-paste(awd$SITE,awd$SEGMENT,sep="_")
jwd$SITE_SEG<-paste(jwd$SITE,jwd$SEGMENT,sep="_")
awd$SEGAREA<-awd$SEGLENGTH*awd$SEGWIDTH
jwd$SEGAREA<-jwd$SEGLENGTH*jwd$SEGWIDTH
awd<-dplyr::select(awd,-c(bANALYSIS_SCHEME,ANALYSIS_YEAR,EXCLUDE_FLAG,REGION_NAME,NO_SURVEY_YN,DATE_,ISLANDCODE))
jwd<-dplyr::select(jwd,-c(bANALYSIS_SCHEME,ANALYSIS_YEAR,EXCLUDE_FLAG,REGION_NAME,NO_SURVEY_YN,DATE_,ISLANDCODE))
awd<-dplyr::filter(awd, SITE_SEG %in% c(ad_sfmN$SITE_SEG));head(awd)
jwd<-dplyr::filter(jwd, SITE_SEG %in% c(j_sfmN$SITE_SEG));head(jwd)
length(unique(awd$SITE))
length(unique(jwd$SITE))
#Remove segments that were annoated in SfM, but not surveyd by divers
ad_sfm_sub<-dplyr::filter(ad_sfmN, SITE_SEG %in% c(awd$SITE_SEG));nrow(ad_sfm);nrow(ad_sfm_sub)
j_sfm_sub<-dplyr::filter(j_sfmN, SITE_SEG %in% c(awd$SITE_SEG));nrow(j_sfm);nrow(j_sfm_sub)
length(unique(ad_sfm_sub$SITE));length(unique(ad_sfm_sub$SITE_SEG))
length(unique(j_sfm_sub$SITE));length(unique(j_sfm_sub$SITE_SEG))
awd$METHOD<-"Diver";awd$METHOD<-as.factor(awd$METHOD)
jwd$METHOD<-"Diver";jwd$METHOD<-as.factor(jwd$METHOD)
sort(colnames(awd))
sort(colnames(ad_sfm_sub))
sort(colnames(jwd))
sort(colnames(j_sfm_sub))
sapply(awd,class)
sapply(ad_sfm,class)
awd.all<-rbind(ad_sfm_sub,awd)
jwd.all<-rbind(j_sfm_sub,jwd)
#Create a look up table of all of the colony attributes- you will need this for the functions below
SURVEY_COL<-c("METHOD","SITEVISITID", "OBS_YEAR", "REGION", "ISLAND","SEC_NAME", "SITE", "REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M","TRANSECT","SEGMENT","COLONYID","GENUS_CODE","TAXONCODE","SPCODE","COLONYLENGTH")
survey_colony<-unique(awd.all[,SURVEY_COL])
SURVEY_SITE<-c("METHOD","SITEVISITID", "OBS_YEAR", "REGION", "ISLAND","SEC_NAME", "SITE", "REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M")
survey_site<-unique(awd.all[,SURVEY_SITE])
SURVEY<-c("METHOD","SITEVISITID", "OBS_YEAR", "REGION", "ISLAND","SEC_NAME", "SITE", "REEF_ZONE",
"DEPTH_BIN","HABITAT_CODE", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M","TRANSECT","SEGMENT","SITE_SEG","ANALYST")
survey_segment<-unique(awd.all[,SURVEY])
nrow(survey_segment)
#TEMPORARY WORK AROUND-ASK MICHAEL TO FIX
survey_site$REEF_ZONE<-ifelse(survey_site$SITE=="HAW-04285","Forereef",as.character(survey_site$REEF_ZONE))
survey_segment$REEF_ZONE<-ifelse(survey_segment$SITE=="HAW-04285","Forereef",as.character(survey_segment$REEF_ZONE))
# GENERATE SUMMARY METRICS at the Segment-leveL BY GENUS--------------------------------------------------
#Calc_ColDen_SEG
acd.gen<-Calc_ColDen_Seg(data = awd.all,grouping_field = "GENUS_CODE");colnames(acd.gen)[colnames(acd.gen)=="ColCount"]<-"AdColCount";colnames(acd.gen)[colnames(acd.gen)=="ColDen"]<-"AdColDen";colnames(acd.gen)[colnames(acd.gen)=="SEGAREA"]<-"SEGAREA_ad"# calculate density at genus level as well as total
jcd.gen<-Calc_ColDen_Seg(jwd.all,"GENUS_CODE"); colnames(jcd.gen)[colnames(jcd.gen)=="ColCount"]<-"JuvColCount";colnames(jcd.gen)[colnames(jcd.gen)=="ColDen"]<-"JuvColDen";colnames(jcd.gen)[colnames(jcd.gen)=="SEGAREA"]<-"SEGAREA_j"
## This function calculates mean colony length, % recent dead, % old dead, condition severity or condition extent to the segment level
## NOTE: can run both adult & juvenile data with this function for COLONYLENGTH
#c("COLONYLENGTH","RDEXTENT1", "RDEXTENT2", "RDEXTENT3", "OLDDEAD","SEVERITY_1","SEVERITY_2", "SEVERITY_3", "EXTENT_1", "EXTENT_2", "EXTENT_3")
ex_b<-subset(awd.all,EX_BOUND==0)
cl.gen<-Calc_ColMetric_Seg(data = ex_b,grouping_field = "GENUS_CODE",pool_fields = "COLONYLENGTH"); colnames(cl.gen)[colnames(cl.gen)=="Ave.y"]<-"Ave.size" #Average % old dead
od.gen<-Calc_ColMetric_Seg(data = awd.all,grouping_field = "GENUS_CODE",pool_fields = "OLDDEAD"); colnames(od.gen)[colnames(od.gen)=="Ave.y"]<-"Ave.od" #Average % old dead
rd.gen<-Calc_ColMetric_Seg(data = awd.all,grouping_field = "GENUS_CODE",pool_fields = c("RDEXTENT1", "RDEXTENT2","RDEXTENT3")); colnames(rd.gen)[colnames(rd.gen)=="Ave.y"]<-"Ave.rd" #Average % recent dead
#Calc_RDden_Transect
rdden.gen<-Calc_RDden_Seg(data=awd.all,grouping_field ="GENUS_CODE") # Density of recent dead colonies by condition, you will need to subset which ever condition you want. The codes ending in "S" are the general categories
acutedz.gen<-subset(rdden.gen,select = c(METHOD,SITEVISITID,SITE,TRANSECT,SEGMENT,GENUS_CODE,DZGN_G));colnames(acutedz.gen)[colnames(acutedz.gen)=="DZGN_G"]<-"AcuteDZ" #subset just acute diseased colonies
#Calc_CONDden_Transect
condden.gen<-Calc_CONDden_Seg(data=awd.all,grouping_field ="GENUS_CODE")# Density of condition colonies by condition, you will need to subset which ever condition you want
ble.gen<-subset(condden.gen,select = c(METHOD,SITEVISITID,SITE,TRANSECT,SEGMENT,GENUS_CODE,BLE));colnames(ble.gen)[colnames(ble.gen)=="BLE"]<-"BLE" #subset just bleached colonies
chronicdz.gen<-subset(condden.gen,select = c(METHOD,SITEVISITID,SITE,TRANSECT,SEGMENT,GENUS_CODE,CHRO));colnames(chronicdz.gen)[colnames(chronicdz.gen)=="CHRO"]<-"ChronicDZ"
#Calc_Richness_Transect
#rich.gen<-Calc_Richness_Transect(ad_sfm,"GENUS_CODE")
#Join density and partial moratlity data together.You will need to replace the DUMMY field with the one you want
data.gen <- join_all(list(acd.gen,jcd.gen,cl.gen,od.gen,rd.gen,acutedz.gen,chronicdz.gen,ble.gen),
by=c("METHOD","SITE","SITEVISITID","TRANSECT","SEGMENT","GENUS_CODE"), type='full')
head(data.gen)
length(unique(data.gen$SITE))
#LOOK AT NAS IN SEGMENTS AND SEG AREA
View(data.gen)
#Change NAs for abunanance and density metrics to 0. Don't change NAs in the partial mortality columns to 0
data.gen$JuvColCount[is.na(data.gen$JuvColCount)]<-0;data.gen$JuvColDen[is.na(data.gen$JuvColDen)]<-0
data.gen$AdColCount[is.na(data.gen$AdColCount)]<-0;data.gen$AdColDen[is.na(data.gen$AdColDen)]<-0
data.gen$JuvColCount<-ifelse(data.gen$SEGMENT==15,NA,data.gen$JuvColCount) #Segment 15 wasn't surveyed for juvs
data.gen$JuvColDen<-ifelse(data.gen$SEGMENT==15,NA,data.gen$JuvColDen) #Segment 15 wasn't surveyed for juvs
#Calculate transect level prevalence for acute dz, chronic dz and bleaching
data.gen$AcuteDZ_prev<-(data.gen$AcuteDZ*data.gen$SEGAREA_ad)/data.gen$AdColCount*100
data.gen$BLE_prev<-(data.gen$BLE*data.gen$SEGAREA_ad)/data.gen$AdColCount*100
data.gen$ChronicDZ_prev<-(data.gen$ChronicDZ*data.gen$SEGAREA_ad)/data.gen$AdColCount*100
View(data.gen)
#Add adult and juvenile pres/ab columns
data.gen$Adpres.abs<-ifelse(data.gen$AdColDen>0,1,0)
data.gen$Juvpres.abs<-ifelse(data.gen$JuvColDen>0,1,0)
#We only surveyed 1 transect/site so data.gen is site-level data
if(length(unique(data.gen$TRANSECT))>1) {cat("WARNING:MORE THAN 1 TRANSECT/SITE IN DF")} #Check that adult data weren't dropped
seg.data.gen2<-dplyr::select(data.gen,-(TRANSECT))
#Merge site data with metadata
# Merge Site level data with sectors file and export site data ------------
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#Merge together survey meta data and sector area files and check for missmatches
meta<-left_join(survey_segment,sectors)
meta[which(is.na(meta$AREA_HA)),]
nrow(survey_segment)
nrow(meta)
#Merge site level data and meta data
seg.data.gen2<-left_join(seg.data.gen2,meta);head(seg.data.gen2)
length(unique(seg.data.gen2))
length(unique(seg.data.gen2$SITE_SEG))
length(unique(seg.data.gen2$SITE))
View(seg.data.gen2)
write.csv(seg.data.gen2,file="C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_GENUS_SEGMENT.csv",row.names = F)
write.csv(seg.data.gen2,file="C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_GENUS_SEGMENT.csv",row.names = F)
View(seg.data.gen2)
#This script reads in the diver and SfM-generated demographic data that has been QC'd and cleaned up
#Then generates segment-level summarized that for methods comparision
rm(list=ls())
#LOAD LIBRARY FUNCTIONS ...
library(gridExtra)
library(reshape2)
library(plyr)
#install.packages("ggpmisc")
library(hydroGOF)
library(tidyverse)
library(ggpmisc)
library(lme4)
library(ggplot2)
library(sjPlot)
library(pander)
library(tidyr)
library(AICcmodavg)
source("T:/Benthic/Data/SfM/ScriptFiles/SfMvDiver Plotting Functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
setwd("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision")
#Read in files
seg<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_GENUS_SEGMENT.csv")
#site<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/SfM/Method Comparision/HARAMP19_SfMGENUS_SITE.csv")
#Select columns to keep in segment data
seg<-dplyr::select(seg, c(METHOD,SITE,SITEVISITID,SEGMENT,GENUS_CODE,ANALYST,SEGAREA_ad,SEGAREA_j,AdColCount,AdColDen,JuvColDen,Ave.size,Ave.od,Ave.rd,
BLE_prev,AcuteDZ_prev,ChronicDZ_prev,ISLAND,SEC_NAME,DEPTH_BIN,LATITUDE,LONGITUDE,HABITAT_CODE,
MIN_DEPTH_M,MAX_DEPTH_M))
# #Select columns to keep in site data
# site<-dplyr::select(site, c(METHOD,SITE,SITEVISITID,GENUS_CODE,TRANSECTAREA_ad,TRANSECTAREA_j,AdColCount,AdColDen,JuvColDen,Ave.size,Ave.od,Ave.rd,
#                                     BLE_prev,AcuteDZ_prev,ChronicDZ_prev,ISLAND,SEC_NAME,DEPTH_BIN,LATITUDE,LONGITUDE,
#                                     MIN_DEPTH_M,MAX_DEPTH_M))
seg<-subset(seg,SITE!="HAW-04285"&SEGMENT!="5") #Something doesn't look right with dive data.
sfm_seg<-subset(seg,METHOD=="SfM")
diver_seg<-subset(seg,METHOD=="Diver")
#Set up in wide format
colnames(sfm_seg)[9:17] <- paste("SfM_", colnames(sfm_seg[,c(9:17)]), sep = "");sfm_seg<-dplyr::select(sfm_seg,-c(METHOD,ANALYST,HABITAT_CODE))
colnames(diver_seg)[9:17] <- paste("Diver_", colnames(diver_seg[,c(9:17)]), sep = "");diver_seg<-dplyr::select(diver_seg,-c(METHOD,ANALYST,ISLAND,HABITAT_CODE,SEC_NAME,DEPTH_BIN,LATITUDE,LONGITUDE,MIN_DEPTH_M,MAX_DEPTH_M))
seg.wide<-merge(sfm_seg,diver_seg,by=c("SITE","SITEVISITID","SEGMENT","GENUS_CODE","SEGAREA_ad","SEGAREA_j"),all=T)
#################IMPORTANT- CHECK FOR MERGING ERRORS
View(subset(seg.wide,GENUS_CODE=="SSSS")) #Make sure columns merge properly
#Merge together and remove segs that aren't merging properly
seg.wide<-merge(sfm_seg,diver_seg,by=c("SITE","SITEVISITID","SEGMENT","GENUS_CODE","SEGAREA_ad","SEGAREA_j"))
View(seg.wide) ##NOTE- LAN-01819 seg 10 SfM is duplicated for some reason-hopefully this will be fixed with final data
# #Change NAs for abunanance and density metrics to 0. Don't change NAs in the partial mortality columns to 0
seg.wide$Diver_JuvColDen[is.na(seg.wide$Diver_JuvColDen)]<-0
seg.wide$Diver_AdColDen[is.na(seg.wide$Diver_AdColDen)]<-0
seg.wide$SfM_JuvColDen[is.na(seg.wide$SfM_JuvColDen)]<-0
seg.wide$SfM_AdColDen[is.na(seg.wide$SfM_AdColDen)]<-0
head(seg.wide)
head(subset(seg.wide,GENUS_CODE=="SSSS"))
# Plotting Regressions and Bland-Altman by Taxon --------------------------
#PlotAll(dataframe, variable 1, variable 2, y-axis name 1, y-axis name 2, x-axis name 1, x-axis name 2)
outpath<- "T:/Benthic/Data/SfM/Method Comparision/Figures/Adult Density"
if(!dir.exists(outpath)){dir.create(outpath)}
p1<-PlotAll(seg.wide,"Diver_AdColDen","SfM_AdColDen","SfM Adult Density","Difference SfM Analyst and Diver", "Diver Adult Density","Mean Adult Density")
p1
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/Juvenile Density"
if(!dir.exists(outpath)){dir.create(outpath)}
p4<-PlotAll(seg.wide,"Diver_JuvColDen","SfM_JuvColDen","SfM Juvenile Density","Difference SfM Analyst and Diver", "Diver Juvenile Density","Mean Juvenile Density")
p4
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/Colony Size"
if(!dir.exists(outpath)){dir.create(outpath)}
p7<-PlotAll(seg.wide,"Diver_Ave.size","SfM_Ave.size","SfM Colony Length","Difference SfM Analyst and Diver", "Diver Colony Length","Mean Colony Length")
p7
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/Old Dead"
if(!dir.exists(outpath)){dir.create(outpath)}
p10<-PlotAll(seg.wide,"Diver_Ave.od","SfM_Ave.od","SfM Average Old Dead Pct","Difference SfM Analyst and Diver", "Diver Average Old Dead Pct","Average Old Dead Pct")
p10
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/Recent Dead"
if(!dir.exists(outpath)){dir.create(outpath)}
p13<-PlotAll(seg.wide,"Diver_Ave.rd","SfM_Ave.rd","SfM Average Recent Dead Pct","Difference SfM Analyst and Diver", "Diver Average Recent Dead Pct","Average Recent Dead Pct")
p13
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/Bleaching"
if(!dir.exists(outpath)){dir.create(outpath)}
p16<-PlotAll(seg.wide,"Diver_BLE_prev","SfM_BLE_prev","SfM Bleaching Prevalence","Difference SfM Analyst and Diver", "Diver Bleaching Prevalence","Mean Bleaching Prevalence")
p16
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/ChronicDZ"
if(!dir.exists(outpath)){dir.create(outpath)}
p19<-PlotAll(seg.wide,"Diver_ChronicDZ_prev","SfM_ChronicDZ_prev","SfM Chronic Disease Prevalence","Difference SfM Analyst and Diver", "Diver Chronic Disease Prevalence","Mean Chronic Disease Prevalence")
p19
outpath<-"T:/Benthic/Data/SfM/Method Comparision/Figures/AcuteDZ"
if(!dir.exists(outpath)){dir.create(outpath)}
p22<-PlotAll(seg.wide,"Diver_AcuteDZ_prev","SfM_AcuteDZ_prev","SfM General Disease Prevalence","Difference SfM Analyst and Diver", "Diver General Disease Prevalence","Mean General Disease Prevalence")
p22
