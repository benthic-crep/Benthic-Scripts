a<- sapply(sfm$RDCAUSE1, unique)
levels(a)
is.logical(sfm$RD_1)
is.logical(sfm$RDCAUSE2)
#10. Identify colonies with recent dead >0%, but there is no RDCAUSE code - This check should result in 0 records
sfm[sfm$RD_1 >0 & sfm$RDCAUSE1=="NA",]
sfm[sfm$RD_2 >0 & sfm$RDCAUSE2=="NA",]
a<-(sfm[sfm$RD_2 >0 & sfm$RDCAUSE2=="NA",], na.rm=T)
a<- sfm[sfm$RD_2 >0 & sfm$RDCAUSE2=="NA",]
a[rowSums(is.na(a)) != ncol(a), ]
sfm[sfm$RD_2 >0 & sfm$RDCAUSE2=="NA",rowSums(is.na(a)) != ncol(a), ]
sfm[sfm$RD_3 >0 & sfm$RDCAUSE3=="NA",]
sfm[sfm$RD_3 >0 & sfm$RDCAUSE3=="NA",rowSums(is.na(a)) != ncol(a), ]
#10. Identify colonies with recent dead >0%, but there is no RDCAUSE code - This check should result in 0 records
sfm[sfm$RD_1 >0 & sfm$RDCAUSE1=="NA",rowSums(is.na(a)) != ncol(a),]
#11. Identify colonies with NO % EXTENT, but a condition - This check should result in 0 records
sfm[sfm$EXTENT_1=="0"& sfm$CON_1!="NA",]
sfm[sfm$EXTENT_2=="0"& sfm$CON_2!="NA",]
sfm[sfm$EXTENT_3=="0"& sfm$CON_3!="NA",]
#12. Identify colonies that have no condition, but a value in extent - This check should result in 0 records
sfm[sfm$CON_1=="NA"& sfm$EXTENT_1!="0",]
#12. Identify colonies that have no condition, but a value in extent - This check should result in 0 records
sfm[sfm$CON_1=="NA"& sfm$EXTENT_1!="0",rowSums(is.na(a)) != ncol(a),]
sfm[sfm$CON_2=="NA"& sfm$EXTNET_2!="0",]
sfm[sfm$CON_3=="NA"& sfm$EXTENT_3!="0",]
sfm[sfm$CON_3=="NA"& sfm$EXTENT_3!="0",rowSums(is.na(a)) != ncol(a),]
#13. Identify colonies with nothing in condition column, but a value in severity. Double check that these shouldn't be 0
sfm[sfm$EXTENT_1=="0"& sfm$SEV_1!="0",]
#13. Identify colonies with nothing in condition column, but a value in severity. Double check that these shouldn't be 0
sfm[sfm$EXTENT_1=="0"& sfm$SEV_1!="0",rowSums(is.na(a)) != ncol(a),]
sfm[sfm$EXTENT_2=="0"& sfm$SEV_2!="0",]
sfm[sfm$EXTENT_2=="0"& sfm$SEV_2!="0", & sfm$SEV_2 != "NA",]
sfm[sfm$EXTENT_2=="0"& sfm$SEV_2!="0" & sfm$SEV_2 != "NA",]
sfm[sfm$EXTENT_2=="0"& sfm$SEV_2!="0" & sfm$ANALYST != "NA",]
#14. make sure that the only rows with severity filled contain BLE or BLP in condition
sfm[sfm$SEV_1=="0"& sfm$CON_1 %in% c("BLE","BLP"),]
sfm[sfm$SEV_2=="0"& sfm$CON_2%in% c("BLE","BLP"),]
sfm[sfm$SEV_3=="0"& sfm$CON_3%in% c("BLE","BLP"),]
`%notin%` <- Negate(`%in%`)
sfm[sfm$SEV_1!="0"& sfm$CON_1 %notin% c("BLE","BLP"),]
sfm[sfm$SEV_2!="0"& sfm$CON_2 %notin% c("BLE","BLP"),]
sfm <- droplevels(sfm)
sfm[sfm$SEV_2!="0"& sfm$CON_2 %notin% c("BLE","BLP"),]
sfm[sfm$SEV_3!="0"& sfm$CON_3 %notin% c("BLE","BLP"),]
#15. RD + OD is not greater than 100%
sfm$OLDDEAD<-as.numeric(sfm$OLDDEAD)
sfm$RD_2<-as.numeric(sfm$RD_2)
sfm$RD_1<-as.numeric(sfm$RD_1)
sfm$RD_3<-as.numeric(sfm$RD_3)
sfm$totaldead = sfm$RD_1+sfm$RD_2+sfm$RD_3 + sfm$OLDDEAD
sfm[sfm$totaldead>100,]
a<- sfm[sfm$totaldead>100,]
View(a)
ad<-subset(sfm,Adult_Juvenile=="A")
View(ad)
ad<-subset(ad,select=-c(Adult_Juvenile,totaldead)) #This also includes segments where NO_COLONY = -1 and shape_length < 0.05
j<-subset(sfm,Adult_Juvenile=="J") #This also includes segments where NO_COLONY = -1
View(j)
j<-subset(sfm,Adult_Juvenile=="J" & NO_COLONY_==0)
j<-subset(j,select=c(FID,ANALYST,OBS_YEAR,SITE,SEGMENT,SEGLENGTH,SEGWIDTH,NO_COLONY_,SPCODE,FRAGMENT_Y,MORPH_CODE,EX_BOUND,SHAPE_Leng,SEGAREA))
#Export QC'd data
write.csv(ad,"HARAMP2019_QCdsfm_ADULT.csv",row.names = F)
write.csv(j,"HARAMP2019_QCdsfm_JUV.csv",row.names = F)
#Export QC'd data
write.csv(ad,"HARAMP2019_QCdsfm_ADULT.csv",row.names = F)
write.csv(j,"HARAMP2019_QCdsfm_JUV.csv",row.names = F)
#DIVER:ADULT CLEAN ANALYSIS READY DATA----------------------------------------
# This script will clean the raw benthic REA data using method E that comes directly from the new data base application.
rm(list=ls())
source("C:/Users/Corinne.Amir/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Corinne.Amir/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Corinne.Amir/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data (ADULTS)
# setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_REA_ADULTCORAL_RAW_2013-2019.rdata") #from oracle
x<-df
x<-df
x$SITE<-SiteNumLeadingZeros(x$SITE) # Change site number such as MAR-22 to MAR-0022
#Convert date formats
class(x$DATE_)
x$DATE_ <- as.Date(x$DATE_, format = "%Y-%m-%d")
### Use these functions to look at data
head(x)
tail(x)
sapply(x, unique)
View(x)
View(df)
is.logical(x$CLADIELLA_YN)
is.numeric(x$CLADIELLA_YN)
#Convert Segment number from old to new numbering system
x$SEGMENT<-ConvertSegNumber(x)
head(table(x$SITE,x$SEGMENT)) #Double check that segment numbers are correct
#Create vector of column names to include then exclude unwanted columns from dataframe
DATA_COLS<-c("MISSIONID","REGION","REGION_NAME","ISLAND","ISLANDCODE","SITE","LATITUDE",	"LONGITUDE","REEF_ZONE","DEPTH_BIN","OBS_YEAR",
"DATE_","NO_SURVEY_YN","EXCLUDE_FLAG","SITEVISITID","HABITAT_CODE","DIVER","TRANSECTNUM","SEGMENT","SEGWIDTH","SEGLENGTH","FRAGMENT_YN",
"COLONYID","TAXONCODE","COLONYLENGTH","OLDDEAD",
"RECENTDEAD_1","RECENT_GENERAL_CAUSE_CODE_1","RECENT_SPECIFIC_CAUSE_CODE_1",
"RECENTDEAD_2",	"RECENT_GENERAL_CAUSE_CODE_2","RECENT_SPECIFIC_CAUSE_CODE_2",
"RECENT_GENERAL_CAUSE_CODE_3","RECENT_SPECIFIC_CAUSE_CODE_3","RECENTDEAD_3","COND",
"CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1","SEVERITY_2","SEVERITY_3",
"GENUS_CODE","S_ORDER","TAXONNAME","SITE_MIN_DEPTH","SITE_MAX_DEPTH")
x<-subset(x,REGION=="MHI" & OBS_YEAR =="2019") #subset just MHI 2019 data
#remove extraneous columns
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
sort(colnames(x))
#Double check level and class of variables to make sure there aren't any errors
sapply(x,levels)
sapply(x,class)##Change column names to make code easier to code
View(x)
is.logical(x$SEVERITY_1)
is.logical(x$SEVERITY_3)
for(i in 1:ncol(sfm.raw)) if(is.factor(sfm.raw[,i])) levels(sfm.raw[,i]) <- c(levels(sfm.raw[,i]),"NA")
sfm.raw[sfm.raw == " "] <- "NA"
sfm.raw[sfm.raw == ""] <- "NA"
head(sfm.raw)
sfm.raw<-droplevels(sfm.raw) #drop levels
sapply(sfm.raw,levels)# check that all " " were converted
sapply(sfm.raw,class)
#### Run function that removes logical NAs ####
RemoveLogicalNA <- function(b)
{
if (is.logical(b) == "TRUE") {
b[is.logical(b)] <- "NA"
b <- as.factor(b)
}
return(b)
}
#### end function ####
head(x)
class(x)
sapply(x, class)
sapply(x, unique)
View(x)
View(df)
source("C:/Users/Corinne.Amir/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Corinne.Amir/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Corinne.Amir/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## DIVER-ADULT: Load benthic data
# setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_REA_ADULTCORAL_RAW_2013-2019.rdata") #from oracle
x<-df
x$SITE<-SiteNumLeadingZeros(x$SITE) # Change site number such as MAR-22 to MAR-0022
#Convert date formats
class(x$DATE_)
x$DATE_ <- as.Date(x$DATE_, format = "%Y-%m-%d")
### Use these functions to look at data
head(x)
tail(x)
sapply(x, unique)
table(x$REGION, x$OBS_YEAR) #review years and regions in dataframe
#Convert Segment number from old to new numbering system
x$SEGMENT<-ConvertSegNumber(x)
View(x)
#Create vector of column names to include then exclude unwanted columns from dataframe
DATA_COLS<-c("MISSIONID","REGION","REGION_NAME","ISLAND","ISLANDCODE","SITE","LATITUDE",	"LONGITUDE","REEF_ZONE","DEPTH_BIN","OBS_YEAR",
"DATE_","NO_SURVEY_YN","EXCLUDE_FLAG","SITEVISITID","HABITAT_CODE","DIVER","TRANSECTNUM","SEGMENT","SEGWIDTH","SEGLENGTH","FRAGMENT_YN",
"COLONYID","TAXONCODE","COLONYLENGTH","OLDDEAD",
"RECENTDEAD_1","RECENT_GENERAL_CAUSE_CODE_1","RECENT_SPECIFIC_CAUSE_CODE_1",
"RECENTDEAD_2",	"RECENT_GENERAL_CAUSE_CODE_2","RECENT_SPECIFIC_CAUSE_CODE_2",
"RECENT_GENERAL_CAUSE_CODE_3","RECENT_SPECIFIC_CAUSE_CODE_3","RECENTDEAD_3","COND",
"CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1","SEVERITY_2","SEVERITY_3",
"GENUS_CODE","S_ORDER","TAXONNAME","SITE_MIN_DEPTH","SITE_MAX_DEPTH")
x<-subset(x,REGION=="MHI" & OBS_YEAR =="2019") #subset just MHI 2019 data
#remove extraneous columns
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
sort(colnames(x))
View(x)
View(x)
source("C:/Users/Corinne.Amir/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Corinne.Amir/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Corinne.Amir/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## DIVER-ADULT: Load benthic data
# setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_REA_ADULTCORAL_RAW_2013-2019.rdata") #from oracle
x<-df
x$SITE<-SiteNumLeadingZeros(x$SITE) # Change site number such as MAR-22 to MAR-0022
#Convert date formats
class(x$DATE_)
x$DATE_ <- as.Date(x$DATE_, format = "%Y-%m-%d")
View(x)
#Convert Segment number from old to new numbering system
x$SEGMENT<-ConvertSegNumber(x)
#Create vector of column names to include then exclude unwanted columns from dataframe
DATA_COLS<-c("MISSIONID","REGION","REGION_NAME","ISLAND","ISLANDCODE","SITE","LATITUDE",	"LONGITUDE","REEF_ZONE","DEPTH_BIN","OBS_YEAR",
"DATE_","NO_SURVEY_YN","EXCLUDE_FLAG","SITEVISITID","HABITAT_CODE","DIVER","TRANSECTNUM","SEGMENT","SEGWIDTH","SEGLENGTH","FRAGMENT_YN",
"COLONYID","TAXONCODE","COLONYLENGTH","OLDDEAD",
"RECENTDEAD_1","RECENT_GENERAL_CAUSE_CODE_1","RECENT_SPECIFIC_CAUSE_CODE_1",
"RECENTDEAD_2",	"RECENT_GENERAL_CAUSE_CODE_2","RECENT_SPECIFIC_CAUSE_CODE_2",
"RECENT_GENERAL_CAUSE_CODE_3","RECENT_SPECIFIC_CAUSE_CODE_3","RECENTDEAD_3","COND",
"CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1","SEVERITY_2","SEVERITY_3",
"GENUS_CODE","S_ORDER","TAXONNAME","SITE_MIN_DEPTH","SITE_MAX_DEPTH")
x<-subset(x,REGION=="MHI" & OBS_YEAR =="2019") #subset just MHI 2019 data
df$REGION <- as.factor(df$REGION)
View(df)
levels(df$REGION)
#remove extraneous columns
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
sort(colnames(x))
View(x)
x<- x %>% mutate_each(funs(empty_as_na))
x <- anyNA(x, recursive=F)
## DIVER-ADULT: Load benthic data
# setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_REA_ADULTCORAL_RAW_2013-2019.rdata") #from oracle
x<-df
x$SITE<-SiteNumLeadingZeros(x$SITE) # Change site number such as MAR-22 to MAR-0022
#Convert date formats
class(x$DATE_)
x$DATE_ <- as.Date(x$DATE_, format = "%Y-%m-%d")
#Convert Segment number from old to new numbering system
x$SEGMENT<-ConvertSegNumber(x)
#Create vector of column names to include then exclude unwanted columns from dataframe
DATA_COLS<-c("MISSIONID","REGION","REGION_NAME","ISLAND","ISLANDCODE","SITE","LATITUDE",	"LONGITUDE","REEF_ZONE","DEPTH_BIN","OBS_YEAR",
"DATE_","NO_SURVEY_YN","EXCLUDE_FLAG","SITEVISITID","HABITAT_CODE","DIVER","TRANSECTNUM","SEGMENT","SEGWIDTH","SEGLENGTH","FRAGMENT_YN",
"COLONYID","TAXONCODE","COLONYLENGTH","OLDDEAD",
"RECENTDEAD_1","RECENT_GENERAL_CAUSE_CODE_1","RECENT_SPECIFIC_CAUSE_CODE_1",
"RECENTDEAD_2",	"RECENT_GENERAL_CAUSE_CODE_2","RECENT_SPECIFIC_CAUSE_CODE_2",
"RECENT_GENERAL_CAUSE_CODE_3","RECENT_SPECIFIC_CAUSE_CODE_3","RECENTDEAD_3","COND",
"CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1","SEVERITY_2","SEVERITY_3",
"GENUS_CODE","S_ORDER","TAXONNAME","SITE_MIN_DEPTH","SITE_MAX_DEPTH")
x<-subset(x,REGION=="MHI" & OBS_YEAR =="2019") #subset just MHI 2019 data
#remove extraneous columns
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
sort(colnames(x))
#Double check level and class of variables to make sure there aren't any errors
sapply(x,levels)
x[x == " "] <- "NA"
x[x == NA] <- "NA"
for(i in 1:ncol(x)) if(is.factor(x[,i])) levels(x[,i]) <- c(levels(x[,i]),"NA")
x[x == " "] <- "NA"
x[x == ""] <- "NA"
RemoveLogicalNA <- function(b)
{
if (is.logical(b) == "TRUE") {
b[is.logical(b)] <- "NA"
b <- as.factor(b)
}
return(b)
}
#### end function ####
#Add "NA" to columns with class = logical (whole column filled with italized, shaded "NA")
x <- RemoveLogicalNA(x)
NA
#Add "NA" to columns with class = logical (whole column filled with italized, shaded "NA")
x <- RemoveLogicalNA(c("SEVERITY_1","SEVERITY_3","SEVERITY_3"))
# setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
load("T:/Benthic/Data/REA Coral Demography & Cover/Raw from Oracle/ALL_REA_ADULTCORAL_RAW_2013-2019.rdata") #from oracle
x<-df
x$SITE<-SiteNumLeadingZeros(x$SITE) # Change site number such as MAR-22 to MAR-0022
#Convert date formats
class(x$DATE_)
x$DATE_ <- as.Date(x$DATE_, format = "%Y-%m-%d")
### Use these functions to look at data
head(x)
tail(x)
sapply(x, unique)
table(x$REGION, x$OBS_YEAR) #review years and regions in dataframe
#Convert Segment number from old to new numbering system
x$SEGMENT<-ConvertSegNumber(x)
head(table(x$SITE,x$SEGMENT)) #Double check that segment numbers are correct
#Create vector of column names to include then exclude unwanted columns from dataframe
DATA_COLS<-c("MISSIONID","REGION","REGION_NAME","ISLAND","ISLANDCODE","SITE","LATITUDE",	"LONGITUDE","REEF_ZONE","DEPTH_BIN","OBS_YEAR",
"DATE_","NO_SURVEY_YN","EXCLUDE_FLAG","SITEVISITID","HABITAT_CODE","DIVER","TRANSECTNUM","SEGMENT","SEGWIDTH","SEGLENGTH","FRAGMENT_YN",
"COLONYID","TAXONCODE","COLONYLENGTH","OLDDEAD",
"RECENTDEAD_1","RECENT_GENERAL_CAUSE_CODE_1","RECENT_SPECIFIC_CAUSE_CODE_1",
"RECENTDEAD_2",	"RECENT_GENERAL_CAUSE_CODE_2","RECENT_SPECIFIC_CAUSE_CODE_2",
"RECENT_GENERAL_CAUSE_CODE_3","RECENT_SPECIFIC_CAUSE_CODE_3","RECENTDEAD_3","COND",
"CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1","SEVERITY_2","SEVERITY_3",
"GENUS_CODE","S_ORDER","TAXONNAME","SITE_MIN_DEPTH","SITE_MAX_DEPTH")
x<-subset(x,REGION=="MHI" & OBS_YEAR =="2019") #subset just MHI 2019 data
#remove extraneous columns
#Add "NA" to columns with class = logical (whole column filled with italized, shaded "NA")
x <- RemoveLogicalNA(c(x$SEVERITY_1,x$SEVERITY_3,x$SEVERITY_3))
x<-df
x$SITE<-SiteNumLeadingZeros(x$SITE) # Change site number such as MAR-22 to MAR-0022
#Convert date formats
class(x$DATE_)
x$DATE_ <- as.Date(x$DATE_, format = "%Y-%m-%d")
### Use these functions to look at data
head(x)
tail(x)
sapply(x, unique)
table(x$REGION, x$OBS_YEAR) #review years and regions in dataframe
#Convert Segment number from old to new numbering system
x$SEGMENT<-ConvertSegNumber(x)
head(table(x$SITE,x$SEGMENT)) #Double check that segment numbers are correct
#Create vector of column names to include then exclude unwanted columns from dataframe
DATA_COLS<-c("MISSIONID","REGION","REGION_NAME","ISLAND","ISLANDCODE","SITE","LATITUDE",	"LONGITUDE","REEF_ZONE","DEPTH_BIN","OBS_YEAR",
"DATE_","NO_SURVEY_YN","EXCLUDE_FLAG","SITEVISITID","HABITAT_CODE","DIVER","TRANSECTNUM","SEGMENT","SEGWIDTH","SEGLENGTH","FRAGMENT_YN",
"COLONYID","TAXONCODE","COLONYLENGTH","OLDDEAD",
"RECENTDEAD_1","RECENT_GENERAL_CAUSE_CODE_1","RECENT_SPECIFIC_CAUSE_CODE_1",
"RECENTDEAD_2",	"RECENT_GENERAL_CAUSE_CODE_2","RECENT_SPECIFIC_CAUSE_CODE_2",
"RECENT_GENERAL_CAUSE_CODE_3","RECENT_SPECIFIC_CAUSE_CODE_3","RECENTDEAD_3","COND",
"CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1","SEVERITY_2","SEVERITY_3",
"GENUS_CODE","S_ORDER","TAXONNAME","SITE_MIN_DEPTH","SITE_MAX_DEPTH")
x<-subset(x,REGION=="MHI" & OBS_YEAR =="2019") #subset just MHI 2019 data
#remove extraneous columns
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
sort(colnames(x))
#Add "NA" to columns with class = logical (whole column filled with italized, shaded "NA")
x$SEVERITY_1 <- RemoveLogicalNA(x$SEVERITY_1)
#Add "NA" to columns with class = logical (whole column filled with italized, shaded "NA")
x$SEVERITY_3 <- RemoveLogicalNA(x$SEVERITY_3)
colnames(x)[colnames(x)=="TAXONCODE"]<-"SPCODE" #Change column name- we will eventually change this column back to "taxoncode" after we modify the spcode names to match the taxalist we all feel comfortable identifying
colnames(x)[colnames(x)=="TRANSECTNUM"]<-"TRANSECT" #Change column name
colnames(x)[colnames(x)=="RECENTDEAD_1"]<-"RDEXTENT1" #Change column name
colnames(x)[colnames(x)=="RECENT_GENERAL_CAUSE_CODE_1"]<-"GENRD1" #Change column name
colnames(x)[colnames(x)=="RECENT_SPECIFIC_CAUSE_CODE_1"]<-"RD1" #Change column name
colnames(x)[colnames(x)=="RECENTDEAD_2"]<-"RDEXTENT2" #Change column name
colnames(x)[colnames(x)=="RECENTDEAD_3"]<-"RDEXTENT3" #Change column name
colnames(x)[colnames(x)=="RECENT_GENERAL_CAUSE_CODE_2"]<-"GENRD2" #Change column name
colnames(x)[colnames(x)=="RECENT_SPECIFIC_CAUSE_CODE_2"]<-"RD2" #Change column name
colnames(x)[colnames(x)=="RECENT_GENERAL_CAUSE_CODE_3"]<-"GENRD3" #Change column name
colnames(x)[colnames(x)=="RECENT_SPECIFIC_CAUSE_CODE_3"]<-"RD3" #Change column name
colnames(x)[colnames(x)=="FRAGMENT_YN"]<-"Fragment" #Change column name
colnames(x)[colnames(x)=="COND"]<-"CONDITION_1" #Change column name
#Add column for method type
x$METHOD<-"DIVER"
#DIVER/ADULT: Merge Diver/Adult data and SURVEY MASTER -------------------------------------
#SURVEY MASTER was created by Ivor and Courtney by extracting sites directly from the Site Visit table from Oracle. It should be the complete list of sites surveyed since 2000
#survey_master<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
setwd("C:/Users/Corinne.Amir/Documents/GitHub/Benthic-Scripts/SfM")
survey_master <- read.csv("SURVEY MASTER.csv")
#Check that OBS_YEAR, SITEVISITID, and SITE are all the same in both x and survey master
OYerror=which(x$OBS_YEAR!=survey_master$OBS_YEAR[match(x$SITEVISITID,survey_master$SITEVISITID)])
SIerror=which(as.vector(x$SITE)!=survey_master$SITE[match(x$SITEVISITID,survey_master$SITEVISITID)])
SIOYerrors=unique(c(OYerror,SIerror))
#add SITE MASTER information to x
length(unique(x$SITEVISITID)) #check the number of sites in demographic data
#join 'em
x<- inner_join(x, survey_master[,c("OBS_YEAR","SITEVISITID","SITE","SEC_NAME","ANALYSIS_YEAR","bANALYSIS_SCHEME","MIN_DEPTH_M","MAX_DEPTH_M")], by=c("OBS_YEAR","SITEVISITID","SITE"))
#add SITE MASTER information to x
length(unique(x$SITEVISITID)) #check the number of sites in demographic data
#Ensure that all rows in X have properly assigned SEC_NAME...
####CHECK THAT all SEC_NAME are present in the survey_master file
test<-x[is.na(x$SEC_NAME), c("MISSIONID","REGION", "SITE","OBS_YEAR"),]
View(survey_master)
#Create a list of missing sites that can be imported into the SITE MASTER file if needed
test<-x[is.na(x$SEC_NAME),]
miss.sites<-ddply(test,.(OBS_YEAR,SITEVISITID,SITE,MISSIONID,REGION,REGION_NAME,ISLAND,LATITUDE,LONGITUDE,
REEF_ZONE,DEPTH_BIN,DATE_,EXCLUDE_FLAG,HABITAT_CODE),
summarize,temp=median(SITEVISITID),SITE_MAX_DEPTH=median(SITE_MAX_DEPTH),SITE_MIN_DEPTH=median(SITE_MIN_DEPTH))
#Should be a 0 row data.frame
head(miss.sites,20)
#Generate General RD cause code
gencodes<-read.csv("T:/Benthic/Data/SpGen_Reference/GeneralRDcode_lookup.csv")
levels(x$RD1)
#Remove exisiting GENRD columns until Michael can fix database
x<-subset(x,select=-c(GENRD1,GENRD2,GENRD3))
x<- droplevels(x)
x<-CreateGenRDCode(x,"RD1","GENRD1",gencodes)
View(CreateGenRDCode)
View(gencodes)
colnames(x)
levels(x$RD2)
x<-CreateGenRDCode(x,"RD2","GENRD2",gencodes)
levels(x$RD2)
levels(x$RD3)
levels(gencodes$CODE)
levels(gencodes$GENCODE)
x<-CreateGenRDCode(x,"RD3","GENRD3",gencodes)
levels(x$RD3)
colnames(x)
##Remove sites that were only surveyed for photoquads but not demographics
#Note-photoquad only sites are not included in data prior to 2018
#Test whether there are missing values in the NO_SURVEY_YN column. The value should be 0 or -1
x.na<-x[is.na(x$NO_SURVEY_YN)&x$OBS_YEAR>2013,]
x.na
# test<-ddply(x.na,.(SITE),
#             summarize,
#             SEG=length(unique(SEGMENT)))
# test
x$NO_SURVEY_YN[is.na(x$NO_SURVEY_YN)]<-0 #Change NAs (blank cells) to 0
#TEMPORARY FIX-SPEAK WITH DM TO CORRECT IN ORACLE
x<-subset(x,SEGLENGTH!="NA") #Remove segments that were not surveyed for coral demography (no SEGLENGTH=0 in db)
#Actually remove special missions.
x<-subset(x,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(x,EXCLUDE_FLAG==-1))
#Change NAs in RecentDead extent to 0
head(subset(x,S_ORDER=="Scleractinia" & is.na(x$RDEXTENT1))) #identify columns that have NAs
x$RDEXTENT1<-ifelse(x$S_ORDER=="Scleractinia"& is.na(x$RDEXTENT1),0,x$RDEXTENT1)
head(subset(x,S_ORDER=="Scleractinia" & is.na(x$RDEXTENT2))) #identify columns that have NAs
x$RDEXTENT2<-ifelse(x$S_ORDER=="Scleractinia"& is.na(x$RDEXTENT2),0,x$RDEXTENT2)
head(subset(x,S_ORDER=="Scleractinia" & is.na(x$RDEXTENT3))) #identify columns that have NAs
x$RDEXTENT3<-ifelse(x$S_ORDER=="Scleractinia"& is.na(x$RDEXTENT3),0,x$RDEXTENT3)
#DIVER/ADULT: Assign TAXONCODE --------------------------------------------------------
#read in list of taxa that we feel comfortable identifying to species or genus level. Note, taxa lists vary by year and region. This will need to be updated through time.
taxa<-read.csv("T:/Benthic/Data/SpGen_Reference/2013-19_Taxa_MASTER.csv")
#Convert SPCODE in raw colony data to TAXONCODE -generates a look up table
#x$TAXONCODE<-Convert_to_Taxoncode_tom(data = x,taxamaster = taxa)#not working need to ask tom
x<-Convert_to_Taxoncode(x)
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE,]
head(b[rowSums(is.na(b)) != ncol(b), ])
View(b)
b<- b[which(b$number1 < b$number2), ]
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE,]
View(b)
b<- b[1:56,]
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE & REGION !=NA,]
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE & x$REGION !=NA,]
b <- b[x$REGION != "NA",]
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE,]
b <- b[x$REGION != "NA",]
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE,]
b <- b[b$REGION != "NA",]
b <- b[b$REGION != NA,]
b <- b[b$REGION != <NA>,]
b <- b[b$REGION = "MHI",]
b <- b[b$REGION = "MHI",]
str(b)
b <- b[b$REGION = "MHI",]
b <- b[b$REGION="MHI",]
b <- b[b$REGION="MHI"]
b <- b[,b$REGION="MHI"]
#If there are issues, use this code to create a list SPCODE (lowest taxonomic resolution we have), TAXONCODE (the taxonomic level we all feel comfortable with) and associated genera
#This is used for spot checking that TAXONCODE was converted properly & can be compared against TAXA MASTER
SURVEY_INFO<-c("OBS_YEAR","REGION","SPCODE","TAXONCODE","GENUS_CODE","TAXONNAME")
test<-new_Aggregate_InputTable(x, SURVEY_INFO)
#Check to see whether S_ORDER is NA and not AAAA (the code for no colonies observed on the segment)
x[x$SPCODE!="AAAA"& is.na(x$S_ORDER),] #this dataframe should be empty
#Change columns to character
x$GENUS_CODE<-as.character(x$GENUS_CODE)
x$SPCODE<-as.character(x$SPCODE)
x$TAXONCODE<-as.character(x$TAXONCODE)
x$S_ORDER<-as.character(x$S_ORDER)
#Check to make sure SPCODE was converted correctly
b <- x[x$SPCODE!=x$TAXONCODE,]
b <- b[b$REGION="MHI"]
#Make sure there are no NA values in genus code or taxoncode if it's supposed to be a scleractinian
subset(x,S_ORDER=="Scleractinia" & GENUS_CODE=="NA") #this dataframe should be empty
subset(x,S_ORDER=="Scleractinia" & TAXONCODE=="NA") #this dataframe should be empty
#There are some old SPCODES that were a combination of taxa and weren't included in the complete taxa list
#Change these unknown genera or taxoncodes to the spcode and the remaining NAs in the Taxon and genus code to AAAA
x$GENUS_CODE<-ifelse(x$TAXONCODE=="UNKN","UNKN",x$GENUS_CODE)
x$TAXONCODE<-ifelse(x$SPCODE=="AAAA","AAAA",x$TAXONCODE)
x$GENUS_CODE<-ifelse(x$TAXONCODE=="AAAA","AAAA",x$GENUS_CODE)
#Check that Unknown scl were changed correctly
head(subset(x,TAXONCODE=="UNKN"&S_ORDER=="Scleractinia"),40)
head(subset(x,GENUS_CODE=="UNKN"&S_ORDER=="Scleractinia"))
head(subset(x,GENUS_CODE=="AAAA"))
##Calcuating segment and transect area and add column for transect area
x$SEGAREA<-x$SEGWIDTH*x$SEGLENGTH
x$TRANSECTAREA<-Transectarea(x)
NegNineCheckCols=c("RDEXTENT1","GENRD1","RD1","RDEXTENT2","GENRD2","RD2","GENRD3","RD3",
"RDEXTENT3","CONDITION_1","CONDITION_2","CONDITION_3","EXTENT_1","EXTENT_2","EXTENT_3","SEVERITY_1",
"SEVERITY_2","SEVERITY_3","GENUS_CODE","S_ORDER")
x[,NegNineCheckCols][x[,NegNineCheckCols]==-9] <- NA #Convert missing numeric values to NA (they are entered as -9 in Oracle)
rity and extent?
tmp.lev<-levels(x$GENRD1); tmp.lev
levels(x$GENRD1)<-c(tmp.lev, "NONE") # change to NONE
x[is.na(x$GENRD1),"GENRD1"]<-"NONE"
tmp.lev<-levels(x$RD1); head(tmp.lev)
levels(x$RD1)<-c(tmp.lev, "NONE")
x[is.na(x$RD1),"RD1"]<-"NONE"
tmp.lev<-levels(x$GENRD2); head(tmp.lev)
levels(x$GENRD2)<-c(tmp.lev, "NONE")
x[is.na(x$GENRD2),"GENRD2"]<-"NONE"
tmp.lev<-levels(x$RD2); head(tmp.lev)
levels(x$RD2)<-c(tmp.lev, "NONE")
x[is.na(x$RD2),"RD2"]<-"NONE"
tmp.lev<-levels(x$GENRD3); head(tmp.lev)
levels(x$GENRD3)<-c(tmp.lev, "NONE")
x[is.na(x$GENRD3),"GENRD3"]<-"NONE"
tmp.lev<-levels(x$RD3); head(tmp.lev)
levels(x$RD3)<-c(tmp.lev, "NONE")
x[is.na(x$RD3),"RD3"]<-"NONE"
tmp.lev<-levels(x$CONDITION_1); head(tmp.lev)
levels(x$CONDITION_1)<-c(tmp.lev, "NONE")
x[is.na(x$CONDITION_1),"CONDITION_1"]<-"NONE"
tmp.lev<-levels(x$CONDITION_2); head(tmp.lev)
levels(x$CONDITION_2)<-c(tmp.lev, "NONE")
x[is.na(x$CONDITION_2),"CONDITION_2"]<-"NONE"
tmp.lev<-levels(x$CONDITION_3); head(tmp.lev)
levels(x$CONDITION_3)<-c(tmp.lev, "NONE")
x[is.na(x$CONDITION_3),"CONDITION_3"]<-"NONE"
tmp.lev<-levels(x$EXTENT_1); head(tmp.lev)
levels(x$EXTENT_1)<-c(tmp.lev, "NONE")
x[is.na(x$EXTENT_1),"EXTENT_1"]<-"NONE"
tmp.lev<-levels(x$EXTENT_1); head(tmp.lev)
levels(x$EXTENT_1)<-c(tmp.lev, 0)
x[is.na(x$EXTENT_1),"EXTENT_1"]<-0
tmp.lev<-levels(x$EXTENT_2); head(tmp.lev)
levels(x$EXTENT_2)<-c(tmp.lev, 0)
x[is.na(x$EXTENT_2),"EXTENT_2"]<-0
tmp.lev<-levels(x$EXTENT_3); head(tmp.lev)
levels(x$EXTENT_3)<-c(tmp.lev, 0)
x[is.na(x$EXTENT_3),"EXTENT_3"]<-0
tmp.lev<-levels(x$SEVERITY_1); head(tmp.lev)
levels(x$SEVERITY_1)<-c(tmp.lev, 0)
x[is.na(x$SEVERITY_1),"SEVERITY_1"]<-0
tmp.lev<-levels(x$SEVERITY_2); head(tmp.lev)
levels(x$SEVERITY_2)<-c(tmp.lev, 0)
x[is.na(x$SEVERITY_2),"SEVERITY_2"]<-0
tmp.lev<-levels(x$SEVERITY_3); head(tmp.lev)
levels(x$SEVERITY_3)<-c(tmp.lev, 0)
x[is.na(x$SEVERITY_3),"SEVERITY_3"]<-0
sapply(x, unique)
tmp.lev<-levels(x$S_ORDER); head(tmp.lev)
levels(x$S_ORDER)<-c(tmp.lev, "NA")
x[is.na(x$S_ORDER),"S_ORDER"]<-"NA"
