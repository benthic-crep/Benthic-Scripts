#View(awd_pre)
install.packages("vegan")
# This script will reads in the CLEANED/Analysis ready data that was generated using the following script
#C:\Users\Courtney.S.Couch\Documents\GitHub\Benthic-Scripts\REA_CoralDemography\Generate REA data\REA Coral Demography_DataPrep.R
#The script does some final tweaks to the data then generates Site-level data
#These data only include surveys conducted between 2013-2019
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data
awd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
jwd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
#Final Tweaks before calculating site-level data-------------------------------------------------
#Colony fragments will be removed when you generate the site level data
#We have denoted fragments differently over the course of our dataset. This code makes sure Fragment is 0 or -1 (-1 indicates it's a fragment)
awd$Fragment<-ifelse(awd$OBS_YEAR <2018 & awd$COLONYLENGTH <5 & awd$S_ORDER=="Scleractinia",-1,awd$Fragment)
head(subset(awd,Fragment==-1& OBS_YEAR<2018)) #double check that pre 2018 fragments create
awd$Fragment[is.na(awd$Fragment)] <- 0
jwd$Fragment <- 0 # you need to add this column so that you can use the site level functions correctly
awd$METHOD<-"DIVER"
jwd$METHOD<-"DIVER"
#Simplify Bleaching Severity categories: in 2019 the team decided to simplify the bleaching severity from 1-5 to 1-3 to improve consistency in severity values
#This code converts the severity data collected prior to 2019 to a 1-3 scale
awd$DATE_ <- as.Date(awd$DATE_, format = "%m/%d/%Y")
jwd$DATE_ <- as.Date(jwd$DATE_, format = "%m/%d/%Y")
#We simplified bleaching severity ranking from 1-5 to 1-3 on 7/11/2019. We decided to drop severity 1 because there is too much inconsistency between divers
awd_pre <- awd %>% filter(DATE_ < as.Date('2019-07-11'))
awd_post<-awd %>% filter(DATE_ >= as.Date('2019-07-11'))
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_1","SEVERITY_1n")
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_2","SEVERITY_2n")
#awd_pre<-Convert_Severity(awd_pre,"SEVERITY_3","SEVERITY_3n") #There were no severity measurements prior to 2020
head(awd_pre)
#View(awd_pre)
data=awd_pre
data$SEV=data$SEVERITY_1
data<-data %>% mutate(sev_new=recode(SEV,
`1`="1",
`2`="1",
`3`="2",
`4`="3",
`5`="3"))
data$sev_new<-as.integer(data$sev_new)
colnames(data)[which(colnames(data) == 'sev_new')] <- severity_new #change group to whatever your grouping field is.
Convert_Severity<-function(data,severity_field,severity_new){
data$SEV<-data[,severity_field]
data<-data %>% mutate(sev_new=recode(SEV,
`1`="1",
`2`="1",
`3`="2",
`4`="3",
`5`="3"))
data$sev_new<-as.integer(data$sev_new)
colnames(data)[which(colnames(data) == 'sev_new')] <- severity_new #change group to whatever your grouping field is.
data<-subset(data,select=-c(SEV))
return(data)
}
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_1","SEVERITY_1n")
#These data only include surveys conducted between 2013-2019
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
install.packages("statmod")
#These data only include surveys conducted between 2013-2019
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
#These data only include surveys conducted between 2013-2019
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data
awd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
jwd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
#Final Tweaks before calculating site-level data-------------------------------------------------
#Colony fragments will be removed when you generate the site level data
#We have denoted fragments differently over the course of our dataset. This code makes sure Fragment is 0 or -1 (-1 indicates it's a fragment)
awd$Fragment<-ifelse(awd$OBS_YEAR <2018 & awd$COLONYLENGTH <5 & awd$S_ORDER=="Scleractinia",-1,awd$Fragment)
head(subset(awd,Fragment==-1& OBS_YEAR<2018)) #double check that pre 2018 fragments create
awd$Fragment[is.na(awd$Fragment)] <- 0
jwd$Fragment <- 0 # you need to add this column so that you can use the site level functions correctly
awd$METHOD<-"DIVER"
jwd$METHOD<-"DIVER"
#Simplify Bleaching Severity categories: in 2019 the team decided to simplify the bleaching severity from 1-5 to 1-3 to improve consistency in severity values
#This code converts the severity data collected prior to 2019 to a 1-3 scale
awd$DATE_ <- as.Date(awd$DATE_, format = "%m/%d/%Y")
jwd$DATE_ <- as.Date(jwd$DATE_, format = "%m/%d/%Y")
#We simplified bleaching severity ranking from 1-5 to 1-3 on 7/11/2019. We decided to drop severity 1 because there is too much inconsistency between divers
awd_pre <- awd %>% filter(DATE_ < as.Date('2019-07-11'))
awd_post<-awd %>% filter(DATE_ >= as.Date('2019-07-11'))
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_1","SEVERITY_1n")
awd_pre<-Convert_Severity(awd_pre,"SEVERITY_2","SEVERITY_2n")
View(awd_pre)
head(awd_pre)
head(subset(awd_pre))
head(subset(awd_pre,CONDTION_1=="BLE"))
head(subset(awd_pre,CONDITION_1=="BLE"))
#After checking that severity numbers were changed correctly, convert back to original column names & drop original columns
awd_pre<-subset(awd_pre,select=-c(SEVERITY_1));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_1n')] <- "SEVERITY_1" #change group to whatever your grouping field is.
awd_pre<-subset(awd_pre,select=-c(SEVERITY_2));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_2n')] <- "SEVERITY_2" #change group to whatever your grouping field is.
#awd_pre<-subset(awd_pre,select=-c(SEVERITY_3));colnames(awd_pre)[which(colnames(awd_pre) == 'SEVERITY_3n')] <- "SEVERITY_3" #change group to whatever your grouping field is.
awd_pre$SEVERITY_3<-NA
head(awd_pre)
#Combine dataframes before and after 2019 & check that rows weren't dropped
awd.<-rbind(awd_pre,awd_post);write.csv(awd.,"test.csv")
nrow(awd)
nrow(awd.);head(awd.)
awd<-awd.; rm("awd.") #remove temporary dataframe if all good.
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data
setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
site.data.gen2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
site.data.sp2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_SPCODE.csv")
site.data.tax2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_TAXONCODE.csv")
#Change all special missions to exclude flag =-1, right now they are 0. Then exclude these sites
levels(site.data.gen2$MISSIONID)
site.data.gen2$EXCLUDE_FLAG<-ifelse(site.data.gen2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.gen2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.gen2<-subset(site.data.gen2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.gen2,EXCLUDE_FLAG==-1))
#Taxoncode
levels(site.data.tax2$MISSIONID)
site.data.tax2$EXCLUDE_FLAG<-ifelse(site.data.tax2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.tax2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.tax2<-subset(site.data.tax2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.tax2,EXCLUDE_FLAG==-1))
#Spcode
levels(site.data.sp2$MISSIONID)
site.data.sp2$EXCLUDE_FLAG<-ifelse(site.data.sp2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.sp2<-subset(site.data.sp2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
survey_master<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
site.data.sp2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_SPCODE.csv")
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data
setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
site.data.gen2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
site.data.sp2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_SPCODE.csv")
site.data.tax2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_TAXONCODE.csv")
#Change all special missions to exclude flag =-1, right now they are 0. Then exclude these sites
levels(site.data.gen2$MISSIONID)
site.data.gen2$EXCLUDE_FLAG<-ifelse(site.data.gen2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.gen2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.gen2<-subset(site.data.gen2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.gen2,EXCLUDE_FLAG==-1))
#Taxoncode
levels(site.data.tax2$MISSIONID)
site.data.tax2$EXCLUDE_FLAG<-ifelse(site.data.tax2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.tax2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.tax2<-subset(site.data.tax2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.tax2,EXCLUDE_FLAG==-1))
#Spcode
levels(site.data.sp2$MISSIONID)
site.data.sp2$EXCLUDE_FLAG<-ifelse(site.data.sp2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.sp2<-subset(site.data.sp2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
survey_master<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#This function will pool data at Sector scale according to predetermined groups. Protected reef slope is converted to Forereef here
site.data.sp2<-PoolSecStrat(site.data.sp2)
# rich.data<-PoolSecStrat(rich.data.gen)
#QC CHECK to make sure the sectors and strata pooled correctly
data.test<-ddply(subset(site.data.sp2,SPCODE=="SSSS"),.(REGION,BEN_SEC,OBS_YEAR,STRATANAME),summarize,n=length(SITE))
sm.test<-ddply(subset(survey_master,Benthic=="1"&EXCLUDE_FLAG=="0"&OBS_YEAR>=2013),.(REGION,ISLAND,SEC_NAME,OBS_YEAR,REEF_ZONE,DEPTH_BIN),summarize,n=length(SITE))
View(data.test)
View(sm.test)
#Set ANALYSIS_SCHEMA to STRATA and DOMAIN_SCHEMA to whatever the highest level you want estimates for (e.g. sector, island, region)
site.data.sp2$ANALYSIS_SCHEMA<-site.data.sp2$STRATANAME
site.data.sp2$DOMAIN_SCHEMA<-site.data.sp2$ISLAND
#Calculate metrics at Strata-level-We need to work on combining metrics into 1 function
#Create a vector of columns to subset for strata estimates
c.keep<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","D._h","SE_D._h","avp","SEprop","Y._h","SE_Y._h","CV_Y._h")
c.keep2<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","D._h","SE_D._h")
c.keep3<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","D._h","SE_D._h","avp","SEprop","Y._h","SE_Y._h","CV_Y._h")
c.keep4<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","prev","SEprev")
acdSP_st<-Calc_Strata(site.data.sp2,"SPCODE","AdColDen","Adpres.abs");acdSP_st=acdSP_st[,c.keep]
colnames(acdSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","AdColDen","SE_AdColDen","Adult_avp","Adult_seprop","Adult_Abun","Adult_SE_Abun","Adult_CV")
warnings()
head(acdSP_st)
jcdSP_st<-Calc_Strata(site.data.sp2,"SPCODE","JuvColDen","Juvpres.abs");jcdSP_st=jcdSP_st[,c.keep]
colnames(jcdSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","JuvColDen","SE_JuvColDen","Juv_avp","Juv_seprop","Juv_Abun","Juv_SE_Abun","Juv_CV")
odSP_st<-Calc_Strata(site.data.sp2,"SPCODE","Ave.od");odSP_st=odSP_st[,c.keep2]
colnames(odSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","Ave.od","SE_Ave.od")
rdSP_st<-Calc_Strata(site.data.sp2,"SPCODE","Ave.rd");rdSP_st=rdSP_st[,c.keep2]
colnames(rdSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","Ave.rd","SE_Ave.rd")
clSP_st<-Calc_Strata(site.data.sp2,"SPCODE","Ave.size");clSP_st=clSP_st[,c.keep2]
colnames(clSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","Ave.size","SE_Ave.size")
BLESP_st<-Calc_Strata_Prevalence(site.data.sp2,"SPCODE","BLE");BLESP_st=BLESP_st[,c.keep4]
colnames(BLESP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","BLE","SE_BLE")
AcuteDZSP_st<-Calc_Strata_Prevalence(site.data.sp2,"SPCODE","AcuteDZ");AcuteDZSP_st=AcuteDZSP_st[,c.keep4]
colnames(AcuteDZSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","AcuteDZ","SE_AcuteDZ")
ChronicDZSP_st<-Calc_Strata_Prevalence(site.data.sp2,"SPCODE","ChronicDZ");ChronicDZSP_st=ChronicDZSP_st[,c.keep4]
colnames(ChronicDZSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","ChronicDZ","SE_ChronicDZ")
#Double Check that revised pooling is adding up NH (total sites) correctly
View(acdSP_st)
View(sectors)
#Calculate Island Estimates
acdSP_is<-Calc_Domain(site.data.sp2,"SPCODE","AdColDen","Adpres.abs")
acdSP_is<-acdSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AdColDen","SE_AdColDen")]
jcdSP_is<-Calc_Domain(site.data.sp2,"SPCODE","JuvColDen","Juvpres.abs")
jcdSP_is<-jcdSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_JuvColDen","SE_JuvColDen")]
odSP_is<-Calc_Domain(site.data.sp2,"SPCODE","Ave.od")
odSP_is<-odSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.od","SE_Ave.od")]
rdSP_is<-Calc_Domain(site.data.sp2,"SPCODE","Ave.rd")
rdSP_is<-rdSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.rd","SE_Ave.rd")]
clSP_is<-Calc_Domain(site.data.sp2,"SPCODE","Ave.size")
clSP_is<-clSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.size","SE_Ave.size")]
bleSP_is<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","BLE")
bleSP_is<-bleSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_BLE_Prev","SE_BLE_Prev")]
AcuteDZSP_is<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","AcuteDZ")
AcuteDZSP_is<-AcuteDZSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AcuteDZ_Prev","SE_AcuteDZ_Prev")]
ChronicDZSP_is<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","ChronicDZ")
ChronicDZSP_is<-ChronicDZSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_ChronicDZ_Prev","SE_ChronicDZ_Prev")]
#Calculate Sector Estimates
site.data.sp2$ANALYSIS_SCHEMA<-site.data.sp2$STRATANAME
site.data.sp2$DOMAIN_SCHEMA<-site.data.sp2$BEN_SEC
acdSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","AdColDen","Adpres.abs")
acdSP_sec<-acdSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AdColDen","SE_AdColDen")]
jcdSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","JuvColDen","Juvpres.abs")
jcdSP_sec<-jcdSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_JuvColDen","SE_JuvColDen")]
odSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","Ave.od")
odSP_sec<-odSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.od","SE_Ave.od")]
rdSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","Ave.rd")
rdSP_sec<-rdSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.rd","SE_Ave.rd")]
clSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","Ave.size")
clSP_sec<-clSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.size","SE_Ave.size")]
bleSP_sec<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","BLE")
bleSP_sec<-bleSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_BLE_Prev","SE_BLE_Prev")]
AcuteDZSP_sec<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","AcuteDZ")
AcuteDZSP_sec<-AcuteDZSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AcuteDZ_Prev","SE_AcuteDZ_Prev")]
ChronicDZSP_sec<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","ChronicDZ")
ChronicDZSP_sec<-ChronicDZSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_ChronicDZ_Prev","SE_ChronicDZ_Prev")]
MyMerge <- function(x, y){
df <- merge(x, y, by= c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot"), all.x= TRUE, all.y= TRUE)
return(df)
}
st.data.sp<-Reduce(MyMerge, list(acdSP_st,jcdSP_st,odSP_st,rdSP_st,clSP_st,BLESP_st,AcuteDZSP_st,ChronicDZSP_st))
colnames(st.data.sp)[colnames(st.data.sp)=="ANALYSIS_SCHEMA"]<-"Stratum"
write.csv(st.data.sp,file="T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Stratum/BenthicREA_stratadata_SPCODE.csv")
# write.csv(rich_st,"Pacificwide_richness_frf_str3.csv")
MyMerge <- function(x, y){
df <- merge(x, y, by= c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot"), all.x= TRUE, all.y= TRUE)
return(df)
}
is.data.sp<-Reduce(MyMerge, list(acdSP_is,jcdSP_is,odSP_is,rdSP_is,clSP_is,bleSP_is,AcuteDZSP_is,ChronicDZSP_is))
colnames(is.data.sp)[colnames(is.data.sp)=="DOMAIN_SCHEMA"]<-"Island"
write.csv(is.data.sp,file="T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Island/BenthicREA_islanddata_SPCODE.csv")
MyMerge <- function(x, y){
df <- merge(x, y, by= c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot"), all.x= TRUE, all.y= TRUE)
return(df)
}
sec.data.sp<-Reduce(MyMerge, list(acdSP_sec,jcdSP_sec,odSP_sec,rdSP_sec,clSP_sec,bleSP_sec,AcuteDZSP_sec,ChronicDZSP_sec))
colnames(sec.data.sp)[colnames(sec.data.sp)=="DOMAIN_SCHEMA"]<-"Sector"
write.csv(sec.data.sp,file="T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Sector/BenthicREA_sectordata_SPCODE.csv")
#Things to work on
#1. put pooling changes into csv file rather than write them out in text, too clunky and easy to get confused with different years
#2. Separate rz/db from sector name so have a column for sector and stratum- this will allow us to subset just certain depths and zone more easily later on.
#3. Make sure that ntot added up correctly across years and domains
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
## LOAD benthic data
setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Benthic REA")
site.data.sp2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_SPCODE.csv")
#Spcode
levels(site.data.sp2$MISSIONID)
site.data.sp2$EXCLUDE_FLAG<-ifelse(site.data.sp2$MISSIONID %in% c("MP1410","MP1512","MP1602","MP2006"),-1,0) #I left SE1602 in (2016 Jarvis and Rose)
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
#Actually remove special missions.
site.data.sp2<-subset(site.data.sp2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
# GENERATE DATA FOR TEMPORAL ANALYSIS---------------------------------------------------
site.data.sp2$STRATANAME<- paste(site.data.sp2$SEC_NAME,site.data.sp2$REEF_ZONE,site.data.sp2$DEPTH_BIN,sep="_")
st.list<-ddply(site.data.sp2,.(METHOD,OBS_YEAR,REGION,ISLAND,SEC_NAME,STRATANAME),summarize,n=length(unique(SITE)))
st.list2<-subset(st.list,n>=2);head(st.list)
#Generate list of strata that were surveyed in all years for a given region and had at least 2 sites/stratum
st.list_w<-dcast(st.list2, formula=METHOD+REGION+ISLAND+SEC_NAME+STRATANAME~ OBS_YEAR, value.var="n",fill=0)
dCOLS<-c("2013","2014","2015","2016","2017","2018","2019")
st.list_w$year_n<-rowSums(st.list_w[,dCOLS] > 0, na.rm=T) #count # of years of data
head(st.list_w)
View(st.list_w)
table(st.list_w$REGION)
#Actually remove special missions.
site.data.sp2<-subset(site.data.sp2,EXCLUDE_FLAG==0);
# this dataframe should be empty
head(subset(site.data.sp2,EXCLUDE_FLAG==-1))
# GENERATE DATA FOR TEMPORAL ANALYSIS---------------------------------------------------
site.data.sp2$STRATANAME<- paste(site.data.sp2$SEC_NAME,site.data.sp2$REEF_ZONE,site.data.sp2$DEPTH_BIN,sep="_")
st.list<-ddply(site.data.sp2,.(METHOD,OBS_YEAR,REGION,ISLAND,SEC_NAME,STRATANAME),summarize,n=length(unique(SITE)))
st.list2<-subset(st.list,n>=2);head(st.list)
#Generate list of strata that were surveyed in all years for a given region and had at least 2 sites/stratum
st.list_w<-dcast(st.list2, formula=METHOD+REGION+ISLAND+SEC_NAME+STRATANAME~ OBS_YEAR, value.var="n",fill=0)
dCOLS<-c("2013","2014","2015","2016","2017","2018","2019")
st.list_w$year_n<-rowSums(st.list_w[,dCOLS] > 0, na.rm=T) #count # of years of data
st.list_w2<-subset(st.list_w,REGION %in% c("MARIAN","PRIAs","SAMOA") & year_n>=2) #only include strata that have at least 2 years
st.list_w3<-subset(st.list_w,REGION %in% c("MHI","NWHI") & year_n>=3)#only include strata that have at least 3 years
st.list_w4<-rbind(st.list_w2,st.list_w3)
head(st.list_w4);st.list_w4<-droplevels(st.list_w4) #generate the list
data.gen_temp<-site.data.sp2[site.data.sp2$STRATANAME %in% c(st.list_w4$STRATANAME),] #Subset data to only include strata of interest
View(data.gen_temp) #double check that strata were dropped correctly
# POOLING DATA from Site to Strata and Domain at SPCODE-level---------------------------------------------------
survey_master<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/SURVEY MASTER.csv")
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#This function will pool data at Sector scale according to predetermined groups. Protected reef slope is converted to Forereef here
site.data.sp2<-PoolSecStrat(site.data.sp2)
# rich.data<-PoolSecStrat(rich.data.gen)
#QC CHECK to make sure the sectors and strata pooled correctly
data.test<-ddply(subset(site.data.sp2,SPCODE=="SSSS"),.(REGION,BEN_SEC,OBS_YEAR,STRATANAME),summarize,n=length(SITE))
sm.test<-ddply(subset(survey_master,Benthic=="1"&EXCLUDE_FLAG=="0"&OBS_YEAR>=2013),.(REGION,ISLAND,SEC_NAME,OBS_YEAR,REEF_ZONE,DEPTH_BIN),summarize,n=length(SITE))
write.csv(data.test,"tmp_sitedataQC.csv")
write.csv(sm.test,"tmp_sitemasterQC.csv")
# #Subset just Forereef Sites & just target taxa
# site.data.sp2<-subset(site.data.sp2,REEF_ZONE=="Forereef")
# site.data.sp2<-subset(site.data.sp2,SPCODE %in% c("ACSP", "MOSP", "PAVS", "POCS","POSP","SSSS"))
# rich.data<-subset(rich.data,REEF_ZONE=="Forereef")
# #Make sure you everything but forereef are dropped
# table(site.data.sp2$REEF_ZONE,site.data.sp2$SPCODE)
# table(rich.data$REEF_ZONE)
#Set ANALYSIS_SCHEMA to STRATA and DOMAIN_SCHEMA to whatever the highest level you want estimates for (e.g. sector, island, region)
site.data.sp2$ANALYSIS_SCHEMA<-site.data.sp2$STRATANAME
site.data.sp2$DOMAIN_SCHEMA<-site.data.sp2$ISLAND
#Calculate metrics at Strata-level-We need to work on combining metrics into 1 function
#Create a vector of columns to subset for strata estimates
c.keep<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","D._h","SE_D._h","avp","SEprop","Y._h","SE_Y._h","CV_Y._h")
c.keep2<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","D._h","SE_D._h")
c.keep3<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","D._h","SE_D._h","avp","SEprop","Y._h","SE_Y._h","CV_Y._h")
c.keep4<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","ANALYSIS_SCHEMA","REEF_ZONE","DB_RZ","SPCODE",
"n_h","N_h","prev","SEprev")
acdSP_st<-Calc_Strata(site.data.sp2,"SPCODE","AdColDen","Adpres.abs");acdSP_st=acdSP_st[,c.keep]
colnames(acdSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","AdColDen","SE_AdColDen","Adult_avp","Adult_seprop","Adult_Abun","Adult_SE_Abun","Adult_CV")
jcdSP_st<-Calc_Strata(site.data.sp2,"SPCODE","JuvColDen","Juvpres.abs");jcdSP_st=jcdSP_st[,c.keep]
colnames(jcdSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","JuvColDen","SE_JuvColDen","Juv_avp","Juv_seprop","Juv_Abun","Juv_SE_Abun","Juv_CV")
odSP_st<-Calc_Strata(site.data.sp2,"SPCODE","Ave.od");odSP_st=odSP_st[,c.keep2]
colnames(odSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","Ave.od","SE_Ave.od")
rdSP_st<-Calc_Strata(site.data.sp2,"SPCODE","Ave.rd");rdSP_st=rdSP_st[,c.keep2]
colnames(rdSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","Ave.rd","SE_Ave.rd")
clSP_st<-Calc_Strata(site.data.sp2,"SPCODE","Ave.size");clSP_st=clSP_st[,c.keep2]
colnames(clSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","Ave.size","SE_Ave.size")
BLESP_st<-Calc_Strata_Prevalence(site.data.sp2,"SPCODE","BLE");BLESP_st=BLESP_st[,c.keep4]
colnames(BLESP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","BLE","SE_BLE")
AcuteDZSP_st<-Calc_Strata_Prevalence(site.data.sp2,"SPCODE","AcuteDZ");AcuteDZSP_st=AcuteDZSP_st[,c.keep4]
colnames(AcuteDZSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","AcuteDZ","SE_AcuteDZ")
ChronicDZSP_st<-Calc_Strata_Prevalence(site.data.sp2,"SPCODE","ChronicDZ");ChronicDZSP_st=ChronicDZSP_st[,c.keep4]
colnames(ChronicDZSP_st)<-c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot","ChronicDZ","SE_ChronicDZ")
#Double Check that revised pooling is adding up NH (total sites) correctly
View(acdSP_st)
View(sectors)
#Calculate Island Estimates
acdSP_is<-Calc_Domain(site.data.sp2,"SPCODE","AdColDen","Adpres.abs")
acdSP_is<-acdSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AdColDen","SE_AdColDen")]
jcdSP_is<-Calc_Domain(site.data.sp2,"SPCODE","JuvColDen","Juvpres.abs")
jcdSP_is<-jcdSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_JuvColDen","SE_JuvColDen")]
odSP_is<-Calc_Domain(site.data.sp2,"SPCODE","Ave.od")
odSP_is<-odSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.od","SE_Ave.od")]
rdSP_is<-Calc_Domain(site.data.sp2,"SPCODE","Ave.rd")
rdSP_is<-rdSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.rd","SE_Ave.rd")]
clSP_is<-Calc_Domain(site.data.sp2,"SPCODE","Ave.size")
clSP_is<-clSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.size","SE_Ave.size")]
bleSP_is<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","BLE")
bleSP_is<-bleSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_BLE_Prev","SE_BLE_Prev")]
AcuteDZSP_is<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","AcuteDZ")
AcuteDZSP_is<-AcuteDZSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AcuteDZ_Prev","SE_AcuteDZ_Prev")]
ChronicDZSP_is<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","ChronicDZ")
ChronicDZSP_is<-ChronicDZSP_is[,c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_ChronicDZ_Prev","SE_ChronicDZ_Prev")]
#Calculate Sector Estimates
site.data.sp2$ANALYSIS_SCHEMA<-site.data.sp2$STRATANAME
site.data.sp2$DOMAIN_SCHEMA<-site.data.sp2$BEN_SEC
acdSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","AdColDen","Adpres.abs")
acdSP_sec<-acdSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AdColDen","SE_AdColDen")]
jcdSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","JuvColDen","Juvpres.abs")
jcdSP_sec<-jcdSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_JuvColDen","SE_JuvColDen")]
odSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","Ave.od")
odSP_sec<-odSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.od","SE_Ave.od")]
rdSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","Ave.rd")
rdSP_sec<-rdSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.rd","SE_Ave.rd")]
clSP_sec<-Calc_Domain(site.data.sp2,"SPCODE","Ave.size")
clSP_sec<-clSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_Ave.size","SE_Ave.size")]
bleSP_sec<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","BLE")
bleSP_sec<-bleSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_BLE_Prev","SE_BLE_Prev")]
AcuteDZSP_sec<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","AcuteDZ")
AcuteDZSP_sec<-AcuteDZSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_AcuteDZ_Prev","SE_AcuteDZ_Prev")]
ChronicDZSP_sec<-Calc_Domain_Prevalence(site.data.sp2,"SPCODE","ChronicDZ")
ChronicDZSP_sec<-ChronicDZSP_sec[,c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot","Mean_ChronicDZ_Prev","SE_ChronicDZ_Prev")]
MyMerge <- function(x, y){
df <- merge(x, y, by= c("METHOD","REGION","ISLAND","ANALYSIS_YEAR","Stratum","REEF_ZONE","DB_RZ","SPCODE","n","Ntot"), all.x= TRUE, all.y= TRUE)
return(df)
}
st.data.sp<-Reduce(MyMerge, list(acdSP_st,jcdSP_st,odSP_st,rdSP_st,clSP_st,BLESP_st,AcuteDZSP_st,ChronicDZSP_st))
colnames(st.data.sp)[colnames(st.data.sp)=="ANALYSIS_SCHEMA"]<-"Stratum"
write.csv(st.data.sp,file="T:/Benthic/Data/Data Requests/ESDPacificwide_STRATA_Timeseries.csv")
#write.csv(st.data.sp,file="T:/Benthic/Data/Data Requests/ESDPacificwide_STRATA_ESA.csv")
MyMerge <- function(x, y){
df <- merge(x, y, by= c("METHOD","REGION","ANALYSIS_YEAR","DOMAIN_SCHEMA","SPCODE","n","Ntot"), all.x= TRUE, all.y= TRUE)
return(df)
}
is.data.sp<-Reduce(MyMerge, list(acdSP_is,jcdSP_is,odSP_is,rdSP_is,clSP_is,bleSP_is,AcuteDZSP_is,ChronicDZSP_is))
colnames(is.data.sp)[colnames(is.data.sp)=="DOMAIN_SCHEMA"]<-"ISLAND"
write.csv(is.data.sp,file="T:/Benthic/Data/Data Requests/ESDPacificwide_ISLAND_Timeseries.csv")
#write.csv(sec.data.sp,file="T:/Benthic/Data/Data Requests/ESDPacificwide_ISLAND_ESA.csv")
MyMerge <- function(x, y){
df <- merge(x, y, by= c("METHOD","REGION","ANALYSIS_YEAR","ISLAND","DOMAIN_SCHEMA","SPCODE","n","Ntot"), all.x= TRUE, all.y= TRUE)
return(df)
}
sec.data.sp<-Reduce(MyMerge, list(acdSP_sec,jcdSP_sec,odSP_sec,rdSP_sec,clSP_sec,bleSP_sec,AcuteDZSP_sec,ChronicDZSP_sec))
colnames(sec.data.sp)[colnames(sec.data.sp)=="DOMAIN_SCHEMA"]<-"Sector"
write.csv(sec.data.sp,file="T:/Benthic/Data/Data Requests/ESDPacificwide_SECTOR_Timeseries.csv")
#write.csv(sec.data.sp,file="T:/Benthic/Data/Data Requests/ESDPacificwide_SECTOR_ESA.csv")
file.info("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Adults_raw_CLEANED.csv")
73111413/1000
73111413/1000000
table(sec.data.sp$REGION)
table(sec.data.sp$REGION,sec.data.sp$ANALYSIS_YEAR)
table(sec.data.sp$ISLAND,sec.data.sp$ANALYSIS_YEAR)
st.data.sp_esa<-st.data.sp[st.data.sp$SPCODE %in% c(esa$SPCODE),]
esa<-read.csv("T:/Benthic/Data/Lookup Tables/ESACorals_lookup.csv")
head(esa)
st.data.sp_esa<-st.data.sp[st.data.sp$SPCODE %in% c(esa$SPCODE),]
head(st.data.sp_esa)
View(st.data.sp_esa)
which(colnames(st.data.sp_esa)=="Adult_CV" )
st.data.sp_esa<-st.data.sp[st.data.sp$SPCODE %in% c(esa$SPCODE),];st.data.sp_esa<-st.data.sp_esa[,1:17]
head(st.data.sp_esa)
levels(st.data.sp_esa$DB_RZ)
levels(as.factor(st.data.sp_esa$DB_RZ))
head(site.data.sp2)
Generate_DB<-function(data){
data$DB_RZ<-as.factor(data$DB_RZ)
data<-data %>% mutate(DEPTH_BIN=recode(DB_RZ,
`BA`="All",
`BM`="Mid",
`FM`="Mid",
`LM`="Mid",
`BS`="Shallow",
`FS`="Shallow",
`LS`="Shallow",
`FD`="Deep",
`LD`="Deep"))
return(data$DEPTH_BIN)
}
st.data.sp_esa$DEPTH_BIN<-Generate_DB(st.data.sp_esa)
head(st.data.sp_esa)
st.data.sp_esa<-st.data.sp[st.data.sp$SPCODE %in% c(esa$SPCODE),]
st.data.sp_esa<-st.data.sp_esa[,1:17]
st.data.sp_esa$DEPTH_BIN<-Generate_DB(st.data.sp_esa)
st.data.sp_esa<-st.data.sp_esa[,-c(7,13,14)]
st.data.sp_esa<-left_join(st.data.sp_esa,esa)
head(st.data.sp_esa)
st.data.sp_esa<-st.data.sp_esa[,c(1:6,15:17,7:14)]
head(st.data.sp_esa)
is.data.sp_esa<-is.data.sp[is.data.sp$SPCODE %in% c(esa$SPCODE),] #subset just esa taxa
head(is.data.sp_esa)
is.data.sp_esa<-is.data.sp[is.data.sp$SPCODE %in% c(esa$SPCODE),] #subset just esa taxa
is.data.sp_esa<-is.data.sp_esa[,1:11] #subset columns of interest
is.data.sp_esa<-left_join(is.data.sp_esa,esa)
head(is.data.sp_esa)
is.data.sp_esa<-is.data.sp_esa[,c(1:6,12:13,5:11)] #reorder columns
head(is.data.sp_esa)
is.data.sp_esa<-is.data.sp[is.data.sp$SPCODE %in% c(esa$SPCODE),] #subset just esa taxa
is.data.sp_esa<-is.data.sp_esa[,1:11] #subset columns of interest
is.data.sp_esa<-left_join(is.data.sp_esa,esa) # join data with esa taxa look up table
is.data.sp_esa<-is.data.sp_esa[,c(1:4,12:13,5:11)] #reorder columns
head(is.data.sp_esa)
