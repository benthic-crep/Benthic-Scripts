all_pred<-subset(all_pred,select=-c(ANALYSIS_SEC,ANALYSIS_YEAR,years,DeltaDen))
all_pred_l<- all_pred %>% pivot_longer(
cols = DeltaDen_mo:MeanWavePower,
names_to = "METRIC",
values_to = "Value")
Plot_Preds<-function(data,metric_name="MeanWavePower"){
data$METRIC=data[,metric_name]
# data$METRIC<-data$metric_name
p<-ggplot(data,aes(x=SEC_NAME,y=METRIC,fill=DEPTH_BIN))+
geom_bar(position="stack", stat="identity")+
facet_wrap(~REGION,scale='free_x')+
theme_bw() +
theme(
axis.text.x = element_text(angle = 90)
,plot.background = element_blank()
,panel.grid.major = element_blank()
,panel.grid.minor = element_blank()
,axis.ticks.x = element_blank() # no x axis ticks
,axis.title.x = element_text( vjust = -.0001) # adjust x axis to lower the same amount as the genus labels
,legend.position="bottom")
return(p)
}
WavePlot<-Plot_Preds(all_pred,"MeanWavePower");WavePlot
CORALPlot<-Plot_Preds(all_pred,"CORAL");CORALPlot
CCAPlot<-Plot_Preds(all_pred,"CCA");CCAPlot
BasaltPlot<-Plot_Preds(all_pred,"Basalt_HC");BasaltPlot
MeanMaxDHWPlot<-Plot_Preds(all_pred,"MeanMaxDHW10");MeanMaxDHWPlot
WavePlot<-Plot_Preds(all_pred,"MeanWavePower");WavePlot
#Useful websites: https://m-clark.github.io/generalized-additive-models/application.html
rm(list=ls())
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
library(VCA)
library(forcats)
library(geosphere)
library(rgdal)
library(stringr)
library(mgcv)
detach(package:dplyr) #dplyr has issues if plyr is loaded first
library(dplyr)
setwd("T:/Benthic/Projects/Juvenile Project")
#LOAD DATA
df<-read.csv("T:/Benthic/Projects/Juvenile Project/JuvDeltaDen_Pred.csv")#Combined juvenile delta density and all predictors
#remove columns
df<-subset(df,select=-c(GENUS_CODE,N_h.as,Dom_N_h, w, ANALYSIS_SEC,ANALYSIS_YEAR, r_y, RUBBLE,SAND,MA,MeanMaxDepth,Carbonate_HC,Sand_Rubble_HC,utmlat_strata_weighted_mean,HUMANS200_mean,SE_MEAN_SH,meankdPAR,MaxMaxDHW10))
df<-subset(df,select=-c(Delta_CORAL,Delta_CCA,Delta_SAND_RUB,Delta_TURF,Basalt_HC))
##Mannually adding in substrate height for Tut_aunuu_a (used all years rather than just most recent survey since no fish surveys were done in this sector in 2018)
df$MEAN_SH<-ifelse(df$STRATANAME=="TUT_AUNUU_A_Forereef_Deep",0.3850,df$MEAN_SH)
df$MEAN_SH<-ifelse(df$STRATANAME=="TUT_AUNUU_A_Forereef_Mid",0.31,df$MEAN_SH)
#
# jwd_site<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Juvenile Project/JuvProject_pb_SITE.csv")#Post bleaching strata-level juvenile data
#
# #Only use Total Scl juvenile data
# jwd_siteS<-subset(jwd_site,GENUS_CODE=="SSSS")
#
#
# #Plot Juv Den vs. Depth at Site level- is there a cutoff for where juveniles start to decline?
# jwd_siteS$ANALYSIS_YEAR<-as.factor(jwd_siteS$ANALYSIS_YEAR)
#
# p1<-jwd_siteS %>%
#   mutate(REGION = fct_relevel(REGION,"NWHI","MHI","PHOENIX","LINE","SAMOA","SMARIAN","NMARIAN")) %>% #reorder varibles
#   ggplot(aes(x=MAX_DEPTH_M, y=JuvColDen, color=ANALYSIS_YEAR)) +
#   geom_smooth(se=T,method="lm",lwd=1.5)+
#   geom_point()+
#   facet_wrap(~REGION,scales = "free_y")+
#   theme_bw() +
#   theme(
#     plot.background = element_blank()
#     ,panel.grid.major = element_blank()
#     ,panel.grid.minor = element_blank()
#     ,axis.ticks.x = element_blank() # no x axis ticks
#     ,axis.title.x = element_text( vjust = -.0001))+
#   geom_vline(data=jwd_siteS, xintercept = 6.096,  size=0.75,color="grey")+
#   geom_vline(data=jwd_siteS,xintercept = 18.288,  size=0.75,color="grey")+
#    labs(x="Max Depth (m)",y="Juvenile Density")
# p1
#
#
# #Plot juv v depth at strata level
#
# jwd_siteS$REGION<-str_replace(jwd_siteS$REGION,"Line", "LINE")
# jwd_siteS$REGION<-str_replace(jwd_siteS$REGION,"Phoenix", "PHOENIX")
# depth_strat$REGION<-str_replace(depth_strat$REGION,"Line", "LINE")
# depth_strat$REGION<-str_replace(depth_strat$REGION,"Phoenix", "PHOENIX")
#
# stratD<-left_join(d_strat,depth_strat)
# head(stratD)
#
#
#
# p2<-
#   ggplot(stratD,aes(x=MeanMaxDepth, y=DeltaDen)) +
#   geom_smooth(se=T,method="lm",lwd=1.5)+
#   geom_point()+
#   #geom_errorbar(data=jcd_sum,aes(y=jcdMEAN, x=ANALYSIS_YEAR,ymin=jcdMEAN-jcdSE, ymax=jcdMEAN+jcdSE), width=.2)+
#   facet_wrap(~fct_relevel(REGION,"NWHI","MHI","PHOENIX","LINE","SAMOA","SMARIAN","NMARIAN"),scales = "free_y")+
#   theme_bw() +
#   theme(
#     plot.background = element_blank()
#     ,panel.grid.major = element_blank()
#     ,panel.grid.minor = element_blank())+
#   labs(x="Mean Max Depth (m)",y="Juvenile Density")
# p2
#
#
#General Additive Models
head(df)
#Check for multicolinearity across predictors
fit1<-lm(DeltaDen_yr~CORAL+CCA+TURF+SAND_RUB+MeanDepth+Basalt_HC+lat_strata_weighted_mean+MeanMaxDHW10+Meankd490+
MEAN_SH+HUMANS20_mean+MeanWavePower,data=df)
fit2<-gam(DeltaDen_yr~s(CORAL)+s(CCA)+s(SAND_RUB)+s(MeanDepth)+s(Basalt_HC)+s(MeanMaxDHW10)+s(Meankd490)+
s(MEAN_SH)+s(HUMANS20_mean)+s(MeanWavePower),data=df) #overparameterized
fit2<-gam(DeltaDen_yr~s(CCA)+s(SAND_RUB)+s(MeanDepth)+s(MeanMaxDHW10)+
s(HUMANS20_mean)+s(MeanWavePower),data=df) #I can't include more than 6
# summary(fit2)
# par(mfrow=c(3,2))
# plot(fit2)
#Testing for Multicolinarity
which( colnames(df)=="CORAL" )
preds<-df[,19:length(df)]
library(GGally)
ggpairs(preds)
library(car)
car::vif(fit1)
library(corrplot)
M = cor(preds)
corrplot(M, method = 'number')
library(MASS)
head(df)
den_mod1<-glm(T2_JuvColDen~ CORAL + CCA + SAND_RUB + MeandDepth + MeanMaxDHW10 + MaxMaxDHW03 + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
den_mod1<-glm(T2_JuvColDen~ CORAL + CCA + SAND_RUB + MeanDepth + MeanMaxDHW10 + MaxMaxDHW03 + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
df$JuvColDen_pos<-df$JuvColDenW +0.5
df$JuvColDen_pos<-df$T2_JuvColDen +0.5
den_mod1<-glm(JuvColDen_pos~ CORAL + CCA + SAND_RUB + MeanDepth + MeanMaxDHW10 + MaxMaxDHW03 + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
step_mod_bic <- stepAIC(den_mod1, k = log(nrow(df)))
summary(step_mod_bic)
# variance inflaction factors ####
# checks for collinearity
vif(step_mod_bic) # looks good, all < 2 (if > 4 then that is bad)
den_mod2<-glm(JuvColDen_pos~ CORAL + CCA + SAND_RUB + MeandDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
# run model first with no interactions to assess VIF
step_mod_bic <- stepAIC(den_mod1, k = log(nrow(df)))
summary(step_mod_bic)
step_mod_bic <- stepAIC(den_mod2, k = log(nrow(df)))
summary(step_mod_bic)
den_mod2<-glm(JuvColDen_pos~ CORAL + CCA + SAND_RUB + MeandDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
den_mod2<-glm(JuvColDen_pos~ CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
# run model first with no interactions to assess VIF
step_mod_bic <- stepAIC(den_mod1, k = log(nrow(df)))
summary(step_mod_bic)
step_mod_bic <- stepAIC(den_mod2, k = log(nrow(df)))
summary(step_mod_bic)
39/61
head(df)
#Checking normality/equal variance for WEIGHTED Delta Density
plotNormalHistogram(df$DeltaDen_yr)
library(VCA)
library(forcats)
library(geosphere)
library(rgdal)
library(stringr)
library(mgcv)
detach(package:dplyr) #dplyr has issues if plyr is loaded first
library(dplyr)
library(MASS)
library(performance)
library(see)
library(patchwork)
library(emmeans)
library(rcompanion)
#Checking normality/equal variance for WEIGHTED Delta Density
plotNormalHistogram(df$DeltaDen_yr)
delta.df$Delta_trans<-sqrt(df$DeltaDen_yr) #sqrt
delta.df$Delta_trans<-sqrt(df$DeltaDen_yr+0.5) #sqrt
df$Delta_trans<-sqrt(df$DeltaDen_yr+0.5) #sqrt
min(df$DeltaDen_yr)
df$Delta_trans<-sqrt(df$DeltaDen_yr+3) #sqrt
plotNormalHistogram(df$Delta_trans)
mod<-glm(Delta_trans~ CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower, data=df)
performance::check_model(mod)
mod<-lm(Delta_trans~ CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower, data=df)
performance::check_model(mod)
mod<-lm(Delta_trans~REGION,data=df)
performance::check_model(mod)
leveneTest(Delta_trans~CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower,data=df)
leveneTest(Delta_trans~REGION,data=df)
df$Delta_trans<-log(df$DeltaDen_yr+3) #sqrt
plotNormalHistogram(df$Delta_trans)
mod<-lm(Delta_trans~ CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower, data=df)
performance::check_model(mod)
df$Delta_trans<-sign(df$DeltaDen_yr+3) + abs(df$DeltaDen_yr+3)^1/3 #cube root
mod<-lm(Delta_trans~ CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower, data=df)
performance::check_model(mod)
leveneTest(Delta_trans~REGION,data=df)
#Option 1 for predictors
den_mod1<-glm(Delta_trans~ CORAL + CCA + SAND_RUB + MeanDepth + MeanMaxDHW10 + MaxMaxDHW03 + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
#Option 2 for predictors
den_mod2<-glm(Delta_trans~ CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower,
family = "Gamma",data= df)
# run model first with no interactions to assess VIF
step_mod_bic <- stepAIC(den_mod1, k = log(nrow(df)))
summary(step_mod_bic)
step_mod_bic <- stepAIC(den_mod2, k = log(nrow(df)))
summary(step_mod_bic)
head(df)
mod<-lm(Delta_trans~ T1_JuvColDen + CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower, data=df)
performance::check_model(mod)
#Option 1 for predictors
den_mod1<-lm(Delta_trans~T1_JuvColDen + CORAL + CCA + SAND_RUB + MeanDepth + MeanMaxDHW10 + MaxMaxDHW03 + MEAN_SH + HUMANS20_mean + MeanWavePower,
data= df)
#Option 2 for predictors
den_mod2<-lm(Delta_trans~ T1_JuvColDen + CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower,
data= df)
# run model first with no interactions to assess VIF
step_mod_bic <- stepAIC(den_mod1, k = log(nrow(df)))
summary(step_mod_bic)
step_mod_bic <- stepAIC(den_mod2, k = log(nrow(df)))
summary(step_mod_bic)
den_mod2<-lm(Delta_trans~  CORAL + CCA + SAND_RUB + MeanDepth + MaxMaxDHW03 + Mean_Mon_SST_Range + MEAN_SH + HUMANS20_mean + MeanWavePower+T1_JuvColDen,
data= df)
step_mod_bic <- stepAIC(den_mod2, k = log(nrow(df)))
summary(step_mod_bic)
15*2*3
3*2
82122.72*0.03
2463/12
#This script reads in the raw DHW data that were merged with the SURVEY_MASTER file using the M:\Environmental Data Summary\EDS GitHub respository\scripts\Extract_Full_EnvironmentalData.R
#The script calculates the time between the last survey date and the previously most recent 8 DHW event
#The raw DHW files are large, but the for loop reads them in individually then removed the df from the workspace before reading in the next- you can run this script on your laptop
rm(list = ls())
library(dplyr)
library(tidyr)
library(plyr)
library(stringr)
library(lubridate)
setwd("M:/Environmental Data Summary/DataDownload/Degree_Heating_Weeks/RAW")
#Define the list of island files you will be loading
file_list <- list.files("M:/Environmental Data Summary/DataDownload/Degree_Heating_Weeks/RAW")
# file.miss<-c("Swains_raw_Degree_Heating_Weeks.RData","Kauai_raw_Degree_Heating_Weeks.RData","Kingman_raw_Degree_Heating_Weeks.RData",
#              "Molokai_raw_Degree_Heating_Weeks.RData","Niihau_raw_Degree_Heating_Weeks.RData","Oahu_raw_Degree_Heating_Weeks.RData",
#              "Palmyra_raw_Degree_Heating_Weeks.RData")
#
#
# #file_list<- subset(file_list, !(file_list %in% file.bad))
# #file_list<-file_list[c(34:38)]
# #file_list<-("Maui_raw_Degree_Heating_Weeks.RData")
#load("M:/Environmental Data Summary/DataDownload/Degree_Heating_Weeks/RAW/Guam_raw_Degree_Heating_Weeks.RData")
#Read in raw juvenile data (this file is used to identify which sites you want to extract DHW for- the file needs to have a date column)
juvdata<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
juvdata_recent<-dplyr::filter(juvdata,OBS_YEAR>=2017) #Only use most recent survey years
juvdata_recent <- mutate_if(juvdata_recent,
is.character,
stringr::str_replace_all, pattern = " ", replacement = "_")
levels(as.factor(juvdata_recent$ISLAND))
#Calculate minimum positive value
minpositive = function(x) min(x[x > 0])
#Calculate time since last DHW  4 and 8 event
TimeSinceDHW8<-function(data,jwd){
#Remove columns with column names = NA and rows with NaN
data <- data[!is.na(names(data))]
data <- na.omit(data)
#Subset data to make it easier to work with
dhw<-pivot_longer(data, cols = 6:ncol(data), names_to = "DATE_", values_to = "DHW")
dhw$DATE_<-as.Date(dhw$DATE_, format = "%Y-%m-%d")
head(dhw)
dhw4<-as.data.frame(dplyr::filter(dhw,DHW >="4"))
class(dhw4$DATE_)
class(dhw4$DHW4_DATE)
head(dhw4)
dhw8<-as.data.frame(dplyr::filter(dhw,DHW >="8"));dhw8<-subset(dhw8,select= -c(LATITUDE_LOV,LONGITUDE_LOV))
class(dhw8$DATE_)
head(dhw8)
#Only include juvenile sites
jwd.meta<-ddply(jwd,.(SITE,SITEVISITID,DATE_),summarize,x=mean(SITEVISITID,na.rm=T))
jwd.meta<-subset(jwd.meta,select=-c(x));colnames(jwd.meta)<-c("SITE","SITEVISITID","J.DATE")
jwd.meta$J.DATE<-as.Date(jwd.meta$J.DATE, format = "%Y-%m-%d")
class(jwd.meta$J.DATE)
head(jwd.meta)
#Merge 4 DHW data and Juvenile data
dhw4<-merge(jwd.meta,dhw4,by=c("SITE","SITEVISITID"),all.x=T) #tried using left_join- it doesn't like the date columns
head(dhw4)
#Calculate difference between dates
dhw4$Tdiff4<-difftime(as.Date(dhw4$J.DATE) ,as.Date(dhw4$DATE_) , units = c("weeks"))
dhw4$YearSinceDHW4<-as.numeric(dhw4$Tdiff/52) #transform Tdiff into years
#Merge 8 DHW data and Juvenile data
dhw8<-merge(jwd.meta,dhw8,by=c("SITE","SITEVISITID"),all.x=T) #tried using left_join- it doesn't like the date columns
#Calculate difference between dates
dhw8$Tdiff8<-difftime(as.Date(dhw8$J.DATE) ,as.Date(dhw8$DATE_) , units = c("weeks"))
dhw8$YearSinceDHW8<-as.numeric(dhw8$Tdiff/52) #transform Tdiff into years
head(dhw8)
#Select most recent date for 4DHW
df4<-ddply(dhw4,.(SITE,SITEVISITID,ISLAND),summarize,
YearSinceDHW4=minpositive(YearSinceDHW4)) #Identify minimum positive value (aka most recent date prior to survey)
df8<-ddply(dhw8,.(SITE,SITEVISITID,ISLAND),summarize,
YearSinceDHW8=minpositive(YearSinceDHW8))
head(df4);head(df8)
df<-merge(df4,df8,by=c("SITE","SITEVISITID","ISLAND"),all=T) #merge DHW4 and DHW8
#Note- NA values are sites where no DHW events have ever been observed, Inf values indicate sites that saw DHW events only after the most recent surveys
#Change Inf to NA
df<-df%>% mutate_if(is.numeric, ~ifelse(abs(.) == Inf,NA,.))
return(df)
}
df.all<-NULL
for(i in 1:length(file_list)){
#i = 1
filename = file_list[i]
load(filename)
df<-TimeSinceDHW8(df_i,juvdata_recent)
rm(list='df_i') #remove the dhw df for a given island from work space- files are too large to load all at once
df.all<-rbind(df.all,df)
}
View(df.all)
#df.all3<-rbind(df.all,df.all2)
write.csv(df.all,file="T:/Benthic/Projects/Juvenile Project/Juvenile_TimeSinceDHW4_8.csv")
#Issues to address:
#pagan - both 0.3 and 3 years, which is correct?
#Missing: Swains, Kauai, Kingman,molokai,niihau,oahu,palmyra
#Plot DHW time series to spot check
library(ggplot2)
dhw8$DATE_<-as.Date(dhw8$DATE_)
dhw4$DATE_<-as.Date(dhw4$DATE_)
dhw$DATE_<-as.Date(dhw$DATE_)
dhw_r<-subset(dhw,DATE_>="2010-01-01")
dhw_r$DATE_ <- as.POSIXct(dhw_r$DATE_, format = "%m/%d/%Y")
dhw_r$year<-format(dhw_r$DATE_, format = "%Y")
dhw_r$mon<-format(dhw_r$DATE_, format = "%m")
dhw_r$day<-format(dhw_r$DATE_, format = "%d")
dhw_mon_max<-ddply(dhw_r,.(ISLAND,year,mon),
summarize,
DHW=max(DHW))
ggplot(subset(dhw_mon_max), aes(x=mon, y=DHW,group=year,color=year)) +
geom_line(size=1.5)+
theme_bw()+
geom_hline(yintercept=8,color="red")
df.all<-read.csv("T:/Benthic/Projects/Juvenile Project/Juvenile_TimeSinceDHW4_8.csv")
library(ggplot2)
library(dplyr)
library(ggalt)
library(cowplot)
library(tibble)
library(lubridate)
library(ggrepel)
#Create data to plot
data<-tribble( ~peak_date, ~REGION, ~displ,~type,
ymd(20130915), "MARIAN", 0.7,"Bleaching Event",
ymd(20140825), "MARIAN", 0.5,"Bleaching Event",
ymd(20160830), "MARIAN", 0.5,"Bleaching Event",
ymd(20170830), "MARIAN", 0.9,"Bleaching Event",
ymd(20141015), "MHI", 0.3,"Bleaching Event",
ymd(20151020), "MHI", 0.9,"Bleaching Event",
ymd(20141001), "NWHI", 0.7,"Bleaching Event",
ymd(20151030), "LINE", 0.8,"Bleaching Event",
ymd(20150315), "SAMOA", 0.6,"Bleaching Event",
ymd(20130818), "MHI", 0.01,"RAMP Survey",
ymd(20150416), "LINE",-0.01,"RAMP Survey",
ymd(20150216), "PHOENIX",0.03,"RAMP Survey",
ymd(20150817), "NWHI", 0.01,"RAMP Survey",
ymd(20150315), "SAMOA", 0.01,"RAMP Survey",
ymd(20160811), "MHI", 0.01,"RAMP Survey",
ymd(20160920), "NWHI", 0.01,"RAMP Survey",
ymd(20170609), "MARIAN", 0.01,"RAMP Survey",
ymd(20180803), "LINE", -0.01,"RAMP Survey",
ymd(20180603), "PHOENIX", 0.03,"RAMP Survey",
ymd(20180708), "SAMOA", 0.01,"RAMP Survey")
head(data)
write.csv(data,"PacificBleachingEvents.csv")
dir()
load("C:/Users/Courtney.S.Couch/Documents/GitHub/env_data_summary/outputs/Survey_Master_Timeseries_2021-11-16.Rdata")
View(SM)
colnames(SM)
# This script will clean the raw benthic REA data using method E that comes directly from the new data base application.
#Note- these data represent the revised data structure insituted in November 2018. Several recent dead and condition columns were added
#These data only include surveys conducted between 2013-2019
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/fish_team_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/Islandwide Mean&Variance Functions.R")
library(VCA)
library(forcats)
library(geosphere)
library(rgdal)
library(stringr)
library(mgcv)
detach(package:dplyr) #dplyr has issues if plyr is loaded first
library(dplyr)
setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Juvenile Project")
#LOAD DATA
jwd_site<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
d_strat<-read.csv("T:/Benthic/Projects/Juvenile Project/JuvProject_deltadensity_STRATA.csv"); d_strat<-subset(d_strat,select= -c(X))
tsdhw<-read.csv("T:/Benthic/Projects/Juvenile Project/Juvenile_TimeSinceDHW4_8.csv"); tsdhw<-subset(tsdhw,select= -c(X))
wave<-read.csv("T:/Benthic/Projects/Juvenile Project/Pacific_WaveActionData.csv")
load("C:/Users/Courtney.S.Couch/Documents/GitHub/env_data_summary/outputs/Survey_Master_Timeseries_2021-11-16.Rdata")
sh<-read.csv("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Juvenile Project/Predictor Variables/ESD_Fish_Complexity.csv")#Substrate height from fish sites
cover1<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicCover_2010-2020_Tier1_SITE.csv")#Cover from all sites
cover3<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicCover_2010-2020_Tier3_SITE.csv")#Cover from all sites
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#load("C:/Users/Courtney.S.Couch/Documents/GitHub/env_data_summary/outputs/Survey_Master_Timeseries_2021-02-27.Rdata") #Survey master file with env data
#Change Regions to correspond to juvenile data
Convert_Region<-function(data){
data$REGION<-ifelse(data$ISLAND %in% c("Farallon de Pajaros", "Maug", "Asuncion", "Alamagan", "Pagan", "Agrihan", "Guguan", "Sarigan","Farallon_de_Pajaros")
,"NMARIAN", as.character(data$REGION))
data$REGION<-ifelse(data$ISLAND %in% c("Saipan", "Tinian", "Aguijan", "Rota", "Guam")
,"SMARIAN", as.character(data$REGION))
data$REGION<-ifelse(data$ISLAND %in% c("Howland","Baker")
,"PHOENIX", as.character(data$REGION))
data$REGION<-ifelse(data$ISLAND =="Wake"
,"WAKE", as.character(data$REGION))
data$REGION<-ifelse(data$ISLAND %in% c("Kingman","Palmyra","Jarvis")
,"LINE", as.character(data$REGION))
return(data$REGION)
}
SM$REGION<-Convert_Region(SM)
sh$REGION<-Convert_Region(sh)
cover1$REGION<-Convert_Region(cover1)
cover3$REGION<-Convert_Region(cover3)
sectors$REGION<-Convert_Region(sectors)
jwd_site$REGION<-Convert_Region(jwd_site)
#Remove spaces in island and sec names
d_strat<- mutate_if(d_strat,
is.character,
str_replace_all, pattern = " ", replacement = "_")
jwd_site <- mutate_if(jwd_site,
is.character,
str_replace_all, pattern = " ", replacement = "_")
wave<-mutate_if(wave,
is.character,
str_replace_all, pattern = " ", replacement = "_")
sh<-mutate_if(sh,
is.character,
str_replace_all, pattern = " ", replacement = "_")
cover1<-mutate_if(cover1,
is.character,
str_replace_all, pattern = " ", replacement = "_")
cover3<-mutate_if(cover3,
is.character,
str_replace_all, pattern = " ", replacement = "_")
sectors<-mutate_if(sectors,
is.character,
str_replace_all, pattern = " ", replacement = "_")
SM<-mutate_if(SM,
is.character,
str_replace_all, pattern = " ", replacement = "_")
#Clean up juv site data
levels(jwd_site$MISSIONID)
jwd_site<-jwd_site[!jwd_site$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
jwd_site$Year_Island<-paste(jwd_site$OBS_YEAR,jwd_site$ISLAND,sep="_")
jwd_site$Year_Region<-paste(jwd_site$OBS_YEAR,jwd_site$REGION,sep="_")
jwd_site<-jwd_site[!jwd_site$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
jwd_site<-subset(jwd_site,Year_Region !="2013_MHI")
jwd_site<-droplevels(jwd_site);levels(jwd_site$MISSIONID)
View(jwd_site)
#Only use Total Scl juvenile data
jwd_siteS<-jwd_site%>%dplyr::filter(GENUS_CODE=="SSSS")
jwd_siteS$ANALYSIS_SEC<-jwd_siteS$SEC_NAME
jwd_siteS$STRATANAME<-paste(jwd_siteS$ANALYSIS_SEC,jwd_siteS$REEF_ZONE,jwd_siteS$DEPTH_BIN,sep="_")
#Subset survey master and env columns of interest
cols<-c("MISSIONID","DATE_","SITEVISITID", "OBS_YEAR", "REGION", "ISLAND","SEC_NAME", "SITE","HABITAT_CODE","REEF_ZONE",
"DEPTH_BIN", "LATITUDE_LOV", "LONGITUDE_LOV","new_MIN_DEPTH_M","new_MAX_DEPTH_M","DHW.MeanMax_Degree_Heating_Weeks_YR01","DHW.MeanMax_Degree_Heating_Weeks_YR03", "DHW.MeanMax_Degree_Heating_Weeks_YR10",
"DHW.MaxMax_Degree_Heating_Weeks_YR03","DHW.MaxMax_Degree_Heating_Weeks_YR10",
"mean_monthly_range_SST_CRW_Daily_YR10","mean_biweekly_range_SST_CRW_Daily_YR10","mean_annual_range_Chlorophyll_A_ESAOCCCI_8Day_YR10","mean_Chlorophyll_A_VIIRS_Monthly_750m_YR05",
"mean_annual_range_Kd490_ESAOCCCI_8Day_YR10","mean_kdPAR_VIIRS_Weekly_YR10")
sm_env<-SM[,cols]
View(sm_env)
#Generate a list of Regions and years to include in final summary
REGION<-c("NWHI","MHI","PHOENIX","LINE","SMARIAN","NMARIAN","SAMOA","WAKE")
OBS_YEAR<-c("2016","2019","2018","2018","2017","2017","2018","2017")
keep<-as.data.frame(cbind(REGION,OBS_YEAR))
keep$r_y<-paste(keep$REGION,keep$OBS_YEAR,sep = "_")
#ONly include years where sites were most recently surveyed for each region
sm_env$r_y<-paste(sm_env$REGION,sm_env$OBS_YEAR,sep = "_")
sm_env<-sm_env[sm_env$r_y %in% c(keep$r_y),]
#Subset survey master to only include juvenile sites
sm_env<-sm_env[sm_env$SITEVISITID %in% c(jwd_site$SITEVISITID),]
table(sm_env$REGION,sm_env$OBS_YEAR)
sm_env$ANALYSIS_SEC<-sm_env$SEC_NAME
sm_env$STRATANAME<-paste(sm_env$ANALYSIS_SEC,sm_env$REEF_ZONE,sm_env$DEPTH_BIN,sep="_")
#List of Predictor Variables, where the data can be found and whether they are ready to use at the Stratum level
predlist<-data.frame(Variable=c("Habitat Code","Frequency of DHW events","Mean Max DHW over previous 10yr","Mean Max DHW over previous 5yr",
"Time Since last > 8 DHW","Latitude","kd490","kdPAR","Chlorophylla", "Mean Depth","Mean Proximity to Humans","Wave Power","Substrate Height",
"Benthic Cover"),
Data_Location= c("SURVEY_MASTER","EDS","EDS","EDS","EDS","SURVEY_MASTER","EDS","EDS","SURVEY_MASTER","SURVEY_MASTER","M Drive","Predictor Variables Folder",
"T drive"),
Summarized_to_Stratum= c("Y","N","Y","Y","N","Y","N","N","Y","N","N","Y","Y"))
# Time Since DHW ----------------------------------------------------------
tsdhw<-tsdhw %>% drop_na(ISLAND) #drop rows that have NA values in ISLAND
sm_env<-left_join(sm_env,tsdhw)
ts_sum<-sm_env %>%
group_by(REGION,ISLAND,ANALYSIS_SEC,STRATANAME) %>%
summarize(YearSinceDHW4=mean(YearSinceDHW4,na.rm=T),
YearSinceDHW8=mean(YearSinceDHW8,na.rm=T))
ts_sum
head(tsdhw)
View(tsdhw)
sm_env<-left_join(sm_env,tsdhw)
View(sm_env)
nrow(Sm)
nrow(SM)
load("C:/Users/Courtney.S.Couch/Documents/GitHub/env_data_summary/outputs/Survey_Master_Timeseries_2021-02-27.Rdata")
nrow(SM)
