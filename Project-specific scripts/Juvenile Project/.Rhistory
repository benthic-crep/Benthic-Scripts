sh_sum<-dpst
head(sh_sum)
# Habitat code ------------------------------------------------------------
# in order to convert habitat type to continuous factor- calculate % of sites in a stratum that are carbonate reef, basalt and sand/rubble
#Simplify habitat codes into 3 groups (carbonate, basalt, sand/rubble)
jwd_siteS$ANALYSIS_SEC<-jwd_siteS$SEC_NAME
jwd_siteS<-jwd_siteS %>% mutate(Hab_simple=recode(HABITAT_CODE,
`AGR`="Carbonate",
`APR`="Carbonate",
`APS`="Carbonate",
`WAL`="Carbonate",
`PAV`="Basalt",
`PPR`="Basalt",
`RRB`="Sand_Rubble",
`ROB`="Basalt",
`SAG`="Carbonate",
`SCR`="Sand_Rubble",
`PSC`="Sand_Rubble"))
hab_sum<-jwd_siteS %>%
group_by(REGION,OBS_YEAR,ISLAND,ANALYSIS_SEC,STRATANAME,Hab_simple) %>%
summarize(n=length(unique(SITEVISITID)))
jwd_siteS %>%
group_by(REGION) %>%
summarize(n=length(unique(SITEVISITID)))
site_sum<-jwd_siteS %>%
group_by(REGION,OBS_YEAR,ISLAND,ANALYSIS_SEC,STRATANAME) %>%
summarize(ntot=length(unique(SITEVISITID)))
hab_sum<-left_join(hab_sum,site_sum)
hab_sum$prop<-hab_sum$n/hab_sum$ntot*100
hab_sum<-subset(hab_sum,select= -c(n,ntot))
hab_sum$Hab_simple = paste(hab_sum$Hab_simple,"HC",sep = "_")
head(hab_sum)
hab_sum_w<-hab_sum %>%
spread(Hab_simple,prop)
head(hab_sum_w)
# MEAN DEPTH --------------------------------------------------------------
jwd_siteS$MidDepth<-(jwd_siteS$MAX_DEPTH_M+jwd_siteS$MIN_DEPTH_M)/2
depth_sum<-jwd_siteS %>%
group_by(REGION,OBS_YEAR,ISLAND,ANALYSIS_SEC,STRATANAME) %>%
summarize(MeanDepth=mean(MidDepth),MeanMaxDepth=mean(MAX_DEPTH_M))
# LATITUDE ----------------------------------------------------------------
# Calculate mean latitutde/stratum
#Use projected coordinates (utm) instead of unprojected coordinates (lat/lon).
#Use"weighted mean" (i.e, latitudinal gravity center) instead of the arithmetic mean.
#Convert unprojected to projected coordinates
islands = unique(jwd_siteS$ISLAND)#Create vector of island names from your dataframe
df_utm = NULL #create empty dataframe
for (isl in 1:length(islands)) {
df_i = jwd_siteS %>% subset(ISLAND %in% islands[[isl]])
zone <- (floor((df_i$LONGITUDE[1] + 180)/6) %% 60) + 1 #identify UTM zone for each island
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df_i[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone)))) #convert to projected coordinates
colnames(xy_utm) = c("X", "Y")
df_i = cbind(df_i, xy_utm) #add the new projected coordinates back into original dataframe
df_utm = rbind(df_utm, df_i) #do this for each island
}
#df=jwd_siteS
df=df_utm
# df_sub = as.data.frame(str_match(df$STRATANAME, "^(.*)_(.*)$")[,-1])[2]
# colnames(df_sub) = "depth_strata"
# df = cbind(df, df_sub)
# lat_mean = df %>%
#   group_by(REGION,OBS_YEAR,ISLAND,ANALYSIS_SEC,STRATANAME)%>%
#   mutate(depth_strata_sum = n())%>%
#   summarize(lat_strata_weighted_mean = weighted.mean(LATITUDE, depth_strata_sum))
# View(df.)
lat_sum = df %>%
group_by(REGION,OBS_YEAR,ISLAND,ANALYSIS_SEC,STRATANAME)%>%
mutate(depth_strata_sum = n())%>%
summarize(utmlat_strata_weighted_mean = weighted.mean(X, depth_strata_sum),
lat_strata_weighted_mean = weighted.mean(LATITUDE, depth_strata_sum))
View(lat_sum)
# model = gam(JuvColDen ~ + s(lat_strata_weighted_mean, k = 3),
#             family = "tw(theta = NULL, link = 'log',a = 1.01, b = 1.99)",
#             data = df,
#             weights = df$weight,
#             gamma = 1.4)
#
# plot(model)
#
#
# model = gam(JuvColDen ~ + s(lat_depth_weighted_mean, k = 3),
#             family = "tw(theta = NULL, link = 'log',a = 1.01, b = 1.99)",
#             data = df,
#             #weights = df$weight,
#             gamma = 1.4)
#
# plot(model)
# BENTHIC COVER
cover<-left_join(cover3,cover1[,c("SITEVISITID","CORAL","MA","TURF","SED")])
nrow(cover);View(cover)
#Create summarized benthic columns
cover$RUBBLE<-cover$CCAR+cover$RUB+cover$TURFR
cover$TURF_BARE<-cover$TURFH+cover$HARD
cover$CCA<-cover$CCAH
cover$SAND<-cover$SED
cover$TURF<-cover$TURFH
#Consolidate columns and combine rubble and sand
cols<-c("SITEVISITID", "OBS_YEAR", "REGION", "ISLAND","SEC_NAME", "SITE","REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","CORAL","CCA","RUBBLE","SAND","TURF","MA")
cover<-cover[,cols]
cover$SAND_RUB<-cover$RUBBLE+cover$SAND
head(cover)
cover$STRATANAME<-paste(cover$SEC_NAME,cover$REEF_ZONE,cover$DEPTH_BIN,sep="_") #Create stratum
#Calculate Strata-Level Cover data
nrow(jwd_siteS)
wsd<-left_join(jwd_siteS,cover[,c("SITEVISITID","CORAL","CCA","RUBBLE","SAND","TURF","MA","SAND_RUB")]); head(wsd);nrow(wsd)
head(wsd[which(is.na(wsd)),])
#Merge together wsd and sectors
wsd<-left_join(wsd,sectors[,c("SEC_NAME","REEF_ZONE","DEPTH_BIN","AREA_HA")]);nrow(wsd);head(wsd)
#Subset just Forereef sites
wsd$REEF_ZONE<-ifelse(wsd$REEF_ZONE=="Protected Slope","Forereef",as.character(wsd$REEF_ZONE))
wsd<-subset(wsd,REEF_ZONE=="Forereef")
wsd$STRATANAME<-paste(wsd$SEC_NAME,wsd$REEF_ZONE,wsd$DEPTH_BIN,sep="_") #Create stratum
head(wsd)
wsd$ANALYSIS_SEC<-wsd$SEC_NAME
wsd$ANALYSIS_YEAR<-wsd$OBS_YEAR
data.cols<-c("CORAL","CCA","RUBBLE","SAND","TURF","MA","SAND_RUB")
### CALCULATE MEAN AND VARIANCE WITHIN STRATA ###
SPATIAL_POOLING_BASE<-c("REGION","ISLAND", "ANALYSIS_SEC", "REEF_ZONE", "STRATANAME")
ADDITIONAL_POOLING_BY<-c("ANALYSIS_YEAR")                                    # additional fields that we want to break data at, but which do not relate to physical areas (eg survey year or method)
#generate within strata means and vars
POOLING_LEVEL<-c(SPATIAL_POOLING_BASE, ADDITIONAL_POOLING_BY)
dps<-Calc_PerStrata(wsd, data.cols, c(POOLING_LEVEL, "AREA_HA"))
head(dps$Mean)
###### REMOVE STRATA with N=1 (cannot pool those up)
dps$Mean<-dps$Mean[dps$Mean$N>1,]
dps$SampleVar<-dps$SampleVar[dps$SampleVar$N>1,]
dps$SampleSE<-dps$SampleSE[dps$SampleSE$N>1,]
# e.g. SAVE BY ISLAND AND REEF_ZONE PER YEAR
OUTPUT_LEVEL<-c("REGION","ISLAND","ANALYSIS_SEC","STRATANAME","ANALYSIS_YEAR")
dpst<-Calc_Pooled_Simple(dps$Mean, dps$SampleVar, data.cols, OUTPUT_LEVEL, "AREA_HA");dpst<-as.data.frame(dpst)
#Clean up- remove SE columns and remove "Mean" from column names
dpst<-dpst %>% dplyr::select(Mean.REGION:Mean.SAND_RUB,-c(Mean.N))
dpst<-dpst %>%
dplyr::rename_all(funs(stringr::str_replace_all(., "Mean.", "")))
head(dpst)
cover_sum<-dpst
head(cover_sum)
# Combine all summaries into 1 dataframe ----------------------------------
all_pred<- cover_sum %>%
left_join(depth_sum) %>%
left_join(hab_sum_w) %>%
left_join(lat_sum) %>%
left_join(eds_sum) %>%
left_join(sh_sum) %>%
left_join(humans_sum)
head(all_pred)
View(all_pred)
# WAVE ACTION CALCULATOR #
## this code assigns wave action per HCBC site using two data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # 15m contour data
fish <- read.csv("FISH_waves_1979_2010.csv") # fish site data
head(fish)
# WAVE ACTION CALCULATOR #
## this code assigns wave action per HCBC site using two data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # 15m contour data
fish <- read.csv("FISH_waves_1979_2010.csv") # fish site data
# modify data
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish <- fish[ which(fish$BAD_FLAG == 0),]
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
unique(all$ISL)
target <- c("KUR", "LIS", "PHR", "FFS", "HAW", "MAI", "KAU", "MOL", "LAN", "NII", "OAH")
all <- all[ which(all$ISL %in% target),] # only want hawaiian islands
# calculate mean per coordinate across all years
all_2 <- all %>%
rowwise() %>%
mutate(means=mean(X1979:X2010, na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
setwd("C:/Users/Courtney.S.Couch/Desktop")
write.csv(all_2, "WaveActionHawaii_1997_2010.csv")
wave_dist <- gcdist(all_2$x, all_2$y)
wave_dist_f <- gcdist(cont$x, cont$y)
dim(wave_dist)
dim(all_2)
hist(wave_dist)
min(wave_dist[ which(wave_dist>0)])
all <- rbind(fish, cont) # combined data sets
View(all)
unique(all$ISL)
plot(table(round(wave_dist[ which(wave_dist>0 & wave_dist<1)],3)))
plot(table(round(wave_dist_f[ which(wave_dist_f>0 & wave_dist_f<10)],3)))
#This script summarizes juvenile data from NCRMP 2013-2019 at the site, stratum, island and sector level
#It also identifies which sectors and strata have been surveyed in all years
#It calculate delta density
rm(list=ls())
#Set Run Flags
DEBUG=TRUE
#LOAD LIBRARY FUNCTIONS ...
source("C:/Users/Courtney.S.Couch/Documents/GitHub/Benthic-Scripts/Functions/Benthic_Functions_newApp_vTAOfork.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/core_functions.R")
source("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/lib/GIS_functions.R")
setwd("C:/Users/Courtney.S.Couch/Documents/Courtney's Files/R Files/ESD/Juvenile Project")
#LOAD DATA
jwd<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Analysis Ready Raw data/CoralBelt_Juveniles_raw_CLEANED.csv")
## LOAD data
# site.data.gen2<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Tweaks before calculating Site-level data-------------------------------------------------
#Colony fragments and scleractinans are subseted in the functions
#Add a column for adult fragments so we can remove them from the dataset later (-1 indicates fragment)
jwd$Fragment <- 0 # you need to add this column so that you can use the site level functions correctly
jwd$DATE_ <- as.Date(jwd$DATE_, format = "%Y-%m-%d")
jwd$METHOD<-"DIVER"
jwd$ANALYST<-jwd$DIVER
jwd$SEGAREA<-jwd$SEGLENGTH*jwd$SEGWIDTH
#Create a look a table of all of the colony attributes- you will need this the functions below
SURVEY_SITE<-c("METHOD","MISSIONID","DATE_","SITEVISITID", "ANALYSIS_YEAR","OBS_YEAR", "REGION", "REGION_NAME", "ISLAND","ISLANDCODE","SEC_NAME", "SITE","HABITAT_CODE","REEF_ZONE",
"DEPTH_BIN", "LATITUDE", "LONGITUDE","MIN_DEPTH_M","MAX_DEPTH_M")
survey_site<-unique(jwd[,SURVEY_SITE])
#TEMPORARY WORK AROUND-ASK MICHAEL TO FIX
survey_site$REEF_ZONE<-ifelse(survey_site$SITE=="HAW-04285","Forereef",as.character(survey_site$REEF_ZONE))
#Remove 2 sites that weren't surveyed for juveniles
jwd<-jwd[!(jwd$SITE %in% c("OFU-01012","PAG-00596")),]
#Look at the size class data to determine the min colony size cut off for analysis
#Subset 2019 Hawaii data
hi<-subset(jwd,OBS_YEAR=="2019")
ggplot(hi) +
geom_density(aes(x = COLONYLENGTH, fill = ANALYST), alpha = 0.2)+
geom_vline(xintercept=1, color = "black")+
facet_wrap(~ISLAND)
ggplot(hi) +
geom_histogram(aes(x = COLONYLENGTH, fill = ANALYST))+
geom_vline(xintercept=1, color = "black")+
facet_wrap(~ISLAND)
ggplot(hi) +
geom_density(aes(x = COLONYLENGTH, fill = ISLAND), alpha = 0.2)+
geom_vline(xintercept=1, color = "black")+
facet_wrap(~ISLAND)
s.data<-ddply(hi,.(ISLAND,ANALYST),
summarise,
min=min(COLONYLENGTH,na.rm=T),
mean=mean(COLONYLENGTH,na.rm=T),
ncol=length(COLONYLENGTH,na.rm=T))
s.all<-ddply(jwd,.(ISLAND,ANALYST),
summarise,
min=min(COLONYLENGTH,na.rm=T),
mean=mean(COLONYLENGTH,na.rm=T),
ncol=length(COLONYLENGTH))
#Change colonies that are <1cm or >5cm to NA. I'm not subsetting these data because I need to keep the placeholder in the dataframe in case a site only had colonies <1cm or >5cm
View(subset(jwd,COLONYLENGTH<1))
nrow(subset(jwd,COLONYLENGTH<1))
nrow(jwd)
jwd$S_ORDER<-ifelse(jwd$COLONYLENGTH<1|jwd$COLONYLENGTH==5,NA,as.character(jwd$S_ORDER))
jwd$GENUS_CODE<-ifelse(jwd$COLONYLENGTH<1|jwd$COLONYLENGTH==5,NA,as.character(jwd$GENUS_CODE))
jwd$TAXONCODE<-ifelse(jwd$COLONYLENGTH<1|jwd$COLONYLENGTH==5,NA,as.character(jwd$TAXONCODE))
jwd$SPCODE<-ifelse(jwd$COLONYLENGTH<1|jwd$COLONYLENGTH==5,NA,as.character(jwd$SPCODE))
jwd$COLONYLENGTH<-ifelse(jwd$COLONYLENGTH<1|jwd$COLONYLENGTH==5,NA,jwd$COLONYLENGTH)
nrow(subset(jwd,COLONYLENGTH>1))
View(subset(jwd,COLONYLENGTH>1))
nrow(jwd)
View(jwd)
# Generate Juvenile Density at the TRANSECT & SITE-LEVEL BY GENUS--------------------------------------------------
jcd.gen<-Calc_ColDen_Transect(jwd,"GENUS_CODE"); colnames(jcd.gen)[colnames(jcd.gen)=="ColCount"]<-"JuvColCount";colnames(jcd.gen)[colnames(jcd.gen)=="ColDen"]<-"JuvColDen";colnames(jcd.gen)[colnames(jcd.gen)=="TRANSECTAREA"]<-"TRANSECTAREA_j"
site.data.gen<-ddply(jcd.gen, .(SITE,SITEVISITID,GENUS_CODE), #calc total colonies by condition
summarise,
JuvColDen=mean(JuvColDen,na.rm=T))
site.data.gen2<-site.data.gen
# Merge Site level data with sectors file and export site data ------------
sectors<-read.csv("C:/Users/Courtney.S.Couch/Documents/GitHub/fish-paste/data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
#Merge together survey meta data and sector area files and check for missmatches
meta<-left_join(survey_site,sectors)
meta[which(is.na(meta$AREA_HA)),]
nrow(survey_site)
nrow(meta)
#Merge site level data and meta data
site.data.gen2<-left_join(site.data.gen2,meta)
site.data.gen2$Juvpres.abs<-ifelse(site.data.gen2$JuvColDen>0,1,0)
#Change all special missions to exclude flag =-1, right now they are 0. Then exclude these sites
#Exclude PRIA 2017 sites because we want similar time intervals following bleaching events for all regions
levels(site.data.gen2$MISSIONID)
site.data.gen2<-site.data.gen2[!site.data.gen2$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
site.data.gen2$Year_Island<-paste(site.data.gen2$OBS_YEAR,site.data.gen2$ISLAND,sep="_")
site.data.gen2<-site.data.gen2[!site.data.gen2$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
site.data.gen2<-droplevels(site.data.gen2);levels(site.data.gen2$MISSIONID)
View(site.data.gen2)
#Convert Protected Reef Slope to Forreef and Subset just Forereef sites
site.data.gen2$REEF_ZONE<-ifelse(site.data.gen2$REEF_ZONE=="Protected Slope","Forereef",as.character(site.data.gen2$REEF_ZONE))
site.data.gen2<-subset(site.data.gen2,REEF_ZONE=="Forereef")
#Remove Johnston from analysis- we only have 2015 data
site.data.gen2<-subset(site.data.gen2,ISLAND!="Johnston")
#Change Regions
site.data.gen2$REGION<-ifelse(site.data.gen2$ISLAND %in% c("FDP", "Maug", "Asuncion", "Alamagan", "Pagan", "Agrihan", "Guguan", "Sarigan","Farallon de Pajaros")
,"NMARIAN", as.character(site.data.gen2$REGION))
site.data.gen2$REGION<-ifelse(site.data.gen2$ISLAND %in% c("Saipan", "Tinian", "Aguijan", "Rota", "Guam")
,"SMARIAN", as.character(site.data.gen2$REGION))
site.data.gen2$REGION<-ifelse(site.data.gen2$ISLAND %in% c("Howland","Baker")
,"PHOENIX", as.character(site.data.gen2$REGION))
site.data.gen2$REGION<-ifelse(site.data.gen2$ISLAND =="Wake"
,"WAKE", as.character(site.data.gen2$REGION))
site.data.gen2$REGION<-ifelse(site.data.gen2$ISLAND %in% c("Kingman","Palmyra","Jarvis")
,"LINE", as.character(site.data.gen2$REGION))
# GENERATE DATA FOR TEMPORAL ANALYSIS---------------------------------------------------
site.data.gen2$STRATANAME<- paste(site.data.gen2$SEC_NAME,site.data.gen2$REEF_ZONE,site.data.gen2$DEPTH_BIN,sep="_")
st.list<-ddply(site.data.gen2,.(METHOD,OBS_YEAR,REGION,ISLAND,SEC_NAME,STRATANAME),summarize,n=length(unique(SITE)))
st.list2<-subset(st.list,n>=2);head(st.list)
#Generate list of strata that were surveyed in all years for a given region and had at least 2 sites/stratum
st.list_w<-dcast(st.list2, formula=METHOD+REGION+ISLAND+SEC_NAME+STRATANAME~ OBS_YEAR, value.var="n",fill=0)
dCOLS<-c("2013","2014","2015","2016","2017","2018","2019")
st.list_w$year_n<-rowSums(st.list_w[,dCOLS] > 0, na.rm=T) #count # of years of data
st.list_w2<-subset(st.list_w,REGION %in% c("NMARIAN","SMARIAN","LINE","PHOENIX","WAKE","SAMOA") & year_n>=2) #only include strata that have at least 2 years
st.list_w3<-subset(st.list_w,REGION %in% c("MHI","NWHI") & year_n>=3)#only include strata that have at least 3 years
st.list_w4<-rbind(st.list_w2,st.list_w3)
head(st.list_w4);st.list_w4<-droplevels(st.list_w4) #generate the list
data.gen_temp<-site.data.gen2[site.data.gen2$STRATANAME %in% c(st.list_w4$STRATANAME),] #Subset juv data to only include strata of intersest
View(data.gen_temp) #double check that strata were dropped correctly
write.csv(data.gen_temp,file="T:/Benthic/Projects/Juvenile Project/JuvProject_temporal_SITE.csv")
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juv site using two data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # 15m contour data
fish <- read.csv("FISH_waves_1979_2010.csv") # fish site data
# modify data
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish <- fish[ which(fish$BAD_FLAG == 0),]
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean per coordinate across all years
all_2 <- all %>%
rowwise() %>%
mutate(means=mean(X1979:X2010, na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
setwd("C:/Users/Courtney.S.Couch/Desktop")
write.csv(all_2, "WaveActionHawaii_1997_2010.csv")
# run pairwise gcdist() function to view distance matrix between all of the points
wave_dist <- gcdist(all_2$x, all_2$y)
wave_dist_f <- gcdist(cont$x, cont$y)
dim(wave_dist)
dim(all_2)
# look at the histogram of that -- focus on smallest size to see how close the points are to one another
hist(wave_dist)
min(wave_dist[ which(wave_dist>0)])
plot(table(round(wave_dist[ which(wave_dist>0 & wave_dist<1)],3)))
plot(table(round(wave_dist_f[ which(wave_dist_f>0 & wave_dist_f<10)],3)))
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
head(all_2)
View(all_2)
xy %>% filter_all(any_vars(is.na(.)))
# convert to spatial points data frame
all_2 %>% filter_all(any_vars(is.na(.)))
head(all)
head(fish)
fish <- read.csv("FISH_waves_1979_2010.csv") # fish site data
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juv site using two data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # 15m contour data
fish <- read.csv("FISH_waves_1979_2010.csv") # fish site data
head(fish)
# convert to spatial points data frame
fish %>% filter_all(any_vars(is.na(.)))
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juv site using two data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # 15m contour data
fish <- read.csv("FISH_waves_1979_2010.csv") # fish site data
# modify data
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-subset(fish,Site!="GUA-01310")
head(fish)
fish <- fish[ which(fish$BAD_FLAG == 0),]
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean per coordinate across all years
all_2 <- all %>%
rowwise() %>%
mutate(means=mean(X1979:X2010, na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
setwd("C:/Users/Courtney.S.Couch/Desktop")
write.csv(all_2, "WaveActionHawaii_1997_2010.csv")
# run pairwise gcdist() function to view distance matrix between all of the points
wave_dist <- gcdist(all_2$x, all_2$y)
wave_dist_f <- gcdist(cont$x, cont$y)
dim(wave_dist)
dim(all_2)
# look at the histogram of that -- focus on smallest size to see how close the points are to one another
hist(wave_dist)
min(wave_dist[ which(wave_dist>0)])
plot(table(round(wave_dist[ which(wave_dist>0 & wave_dist<1)],3)))
plot(table(round(wave_dist_f[ which(wave_dist_f>0 & wave_dist_f<10)],3)))
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(all_sp)
plot(all_sp)
extent(all_sp)
table(all_sp$ISL)
cell_size <- 50/1000 # go from meters to km
span_x <- diff(extent(all_sp)[1:2]) # the span of degrees
span_x_km <- span_x*111.111 # converting degrees to km of the span of the points
n_cell_x <- round(span_x_km/cell_size) # the value we want to assign to ncol
span_y <- diff(extent(all_sp)[3:4]) # the span of degrees
span_y_km <- span_y*111.111
n_cell_y <- round(span_y_km/cell_size) # the value we want to assign to nrow
# convert from spdf to raster
rast <- raster()
extent(rast) <- extent(all_sp) # this might be unnecessary
ncol(rast) <- n_cell_x # this is one way of assigning cell size / resolution
nrow(rast) <- n_cell_y
rast2 <- rasterize(all_sp, rast, all_sp$means, fun=mean)
rast2
# writeRaster(rast2, "WavesHawaii.nc", format = "CDF") too big to save
plot(rast2)
setwd("T:/Benthic/Projects/Juvenile Project") # set working directory
juv <- read.csv("JuvProject_temporal_SITE.csv")
setwd("T:/Benthic/Projects/Juvenile Project") # set working directory
juv <- read.csv("JuvProject_temporal_SITE.csv")
setwd("T:/Benthic/Projects/Juvenile Project") # set working directory
juv <- read.csv("JuvProject_temporal_SITE.csv")
head(juv)
juv <- subset(juv,select=c(SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juv)
xy_juv <- juv[,c(2,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juv,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(juv_sp)
juv <- read.csv("JuvProject_temporal_SITE.csv")
juv <- subset(juv,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juv)
# convert juv data to spatial points data
xy_juv <- juv[,c(2,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juv,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(juv_sp)
# plot oahu to check out the data
plot(juv_sp[ which(juv$ISLAND == "Oahu"),], col = "red")
plot(all_sp[ which(all_sp$ISL == "OAH"),], add = TRUE)
plot(all_sp[ which(all_sp$ISL == "OAH"),], add = TRUE)
head(all_sp)
plot(all_sp[ which(all_sp$ISL == "ALA"),], add = TRUE)
