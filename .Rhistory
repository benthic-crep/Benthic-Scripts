mutate(date = as.Date(ISO_TIME),
LON360=lon2lon360(LON),
AGG_WIND=coalesce(WMO_WIND,
TOKYO_WIND,
USA_WIND,
CMA_WIND,
HKO_WIND,
KMA_WIND,
NEWDELHI_WIND,
REUNION_WIND,
BOM_WIND,
NADI_WIND,
WELLINGTON_WIND,
DS824_WIND,
TD9636_WIND,
TD9635_WIND,
NEUMANN_WIND,
MLC_WIND),
AGG_SSHS=as.numeric(as.vector(wind2SSHS(AGG_WIND)))) %>%
select(SID,SEASON,NUMBER,BASIN,SUBBASIN,NAME,date,ISO_TIME,LAT,LON,AGG_WIND,AGG_SSHS,SEASON) %>%
na.omit() %>%
# filter(AGG_SSHS >= 1, SEASON > 1800) %>%
# Guam bounding box
# filter(
#   between(LON, 144.8 - 10, 144.8 + 10),
#   between(LAT, 13.5 - 10, 13.5 + 10)
# ) %>%
distinct() %>%
select(-ISO_TIME)
df <- ibtracs %>%
mutate(date = as.Date(ISO_TIME),
LON360=lon2lon360(LON),
AGG_WIND=coalesce(WMO_WIND,
TOKYO_WIND,
USA_WIND,
CMA_WIND,
HKO_WIND,
KMA_WIND,
NEWDELHI_WIND,
REUNION_WIND,
BOM_WIND,
NADI_WIND,
WELLINGTON_WIND,
DS824_WIND,
TD9636_WIND,
TD9635_WIND,
NEUMANN_WIND,
MLC_WIND),
AGG_SSHS=as.numeric(as.vector(wind2SSHS(AGG_WIND)))) %>%
select(SID,SEASON,NUMBER,BASIN,SUBBASIN,NAME,date,ISO_TIME,LAT,LON,LON360,AGG_WIND,AGG_SSHS,SEASON) %>%
na.omit() %>%
# filter(AGG_SSHS >= 1, SEASON > 1800) %>%
# Guam bounding box
# filter(
#   between(LON, 144.8 - 10, 144.8 + 10),
#   between(LAT, 13.5 - 10, 13.5 + 10)
# ) %>%
distinct() %>%
select(-ISO_TIME)
bounds=df %>% summarize(minLAT=min(LAT),
maxLAT=max(LAT),
minLON360=min(LON360),
maxLON360=max(LON360))
bounds
library(terra)
df <- ibtracs %>%
mutate(date = as.Date(ISO_TIME),
LON360=lon2lon360(LON),
AGG_WIND=coalesce(WMO_WIND,
TOKYO_WIND,
USA_WIND,
CMA_WIND,
HKO_WIND,
KMA_WIND,
NEWDELHI_WIND,
REUNION_WIND,
BOM_WIND,
NADI_WIND,
WELLINGTON_WIND,
DS824_WIND,
TD9636_WIND,
TD9635_WIND,
NEUMANN_WIND,
MLC_WIND),
AGG_SSHS=as.numeric(as.vector(wind2SSHS(AGG_WIND)))) %>%
select(SID,SEASON,NUMBER,BASIN,SUBBASIN,NAME,date,ISO_TIME,LAT,LON,LON360,AGG_WIND,AGG_SSHS,SEASON) %>%
na.omit() %>%
# filter(AGG_SSHS >= 1, SEASON > 1800) %>%
# Guam bounding box
# filter(
#   between(LON, 144.8 - 10, 144.8 + 10),
#   between(LAT, 13.5 - 10, 13.5 + 10)
# ) %>%
distinct() %>%
select(-ISO_TIME)
bounds=df %>% summarize(minLAT=min(LAT),
maxLAT=max(LAT),
minLON360=min(LON360),
maxLON360=max(LON360))
?rast
libary(sf)
library(sf)
?st_as_sf
df_sf=df %>% st_as_sf(coords = c("LON360","LAT"))
df_sf
?rast
Hr=rast(df_sf,type="xyz")
foo_df <- data.frame(st_coordinates(df_sf),z=df_sf$AGG_SSHS)
Hr=rast(foo_df,type="xyz")
plot(Hr)
dim(Hr)
foo_df
bbox(Hr)
extent(Hr)
?terra
df <- ibtracs %>%
mutate(date = as.Date(ISO_TIME),
LON360=lon2lon360(LON),
AGG_WIND=coalesce(WMO_WIND,
TOKYO_WIND,
USA_WIND,
CMA_WIND,
HKO_WIND,
KMA_WIND,
NEWDELHI_WIND,
REUNION_WIND,
BOM_WIND,
NADI_WIND,
WELLINGTON_WIND,
DS824_WIND,
TD9636_WIND,
TD9635_WIND,
NEUMANN_WIND,
MLC_WIND),
AGG_SSHS=as.numeric(as.vector(wind2SSHS(AGG_WIND))),
YEAR=year(ISO_TIME)) %>%
select(SID,SEASON,NUMBER,BASIN,SUBBASIN,NAME,ISO_TIME,date,YEAR,LAT,LON,LON360,AGG_WIND,AGG_SSHS,SEASON) %>%
na.omit() %>%
# filter(AGG_SSHS >= 1, SEASON > 1800) %>%
# Guam bounding box
# filter(
#   between(LON, 144.8 - 10, 144.8 + 10),
#   between(LAT, 13.5 - 10, 13.5 + 10)
# ) %>%
distinct() %>%
select(-ISO_TIME)
bounds=df %>% summarize(minLAT=min(LAT),
maxLAT=max(LAT),
minLON360=min(LON360),
maxLON360=max(LON360))
df_sf=df %>% st_as_sf(coords = c("LON360","LAT"))
df_sf$YEAR
foo_df <- data.frame(st_coordinates(df_sf),z=df_sf$YEAR)
Hr=rast(foo_df,type="xyz")
dim(Hr)
table(df_sf$YEAR)
bounds=df %>% summarize(minLAT=min(LAT),
maxLAT=max(LAT),
minLON360=min(LON360),
maxLON360=max(LON360))
df_sf=df %>% st_as_sf(coords = c("LON360","LAT"))
foo_df <- data.frame(st_coordinates(df_sf),z=df_sf$YEAR)
foo_df
foo_df[foo_df$z>2000,]
Hr=rast(foo_df,type="xyz")
dim(Hr)
?rast
sm=fread("C:/Users/Thomas.Oliver/WORK/Projects/GitHub Projects/fish-paste/data/SURVEY MASTER.csv")
sm
sms=sm[sample(x = 1:nrow(sm),n=100,replace = F),]
sms
sm=fread("C:/Users/Thomas.Oliver/WORK/Projects/GitHub Projects/fish-paste/data/SURVEY MASTER.csv")
sms=sm[sample(x = 1:nrow(sm),n=100,replace = F),]
sms=sm[sample(x = 1:nrow(sm),size = 100,replace = F),]
sms
names(sms)
sms$LONG360_LOV=lon2lon360(sms$LONGITUDE_LOV)
sm=fread("C:/Users/Thomas.Oliver/WORK/Projects/GitHub Projects/fish-paste/data/SURVEY MASTER.csv")
sms=sm[sample(x = 1:nrow(sm),size = 100,replace = F),]
names(sms)
sms$LONG360_LOV=lon2lon360(sms$LONGITUDE_LOV)
sms$LONG360_LOV
sms_sf=st_as_sf(sms,coords=c("LONG360_LOV","LATITUDE_LOV"))
sms_sf
sms$DATE_
sms$DATE_YMD=mdy(sms$DATE_)
sms$DATE_YMD
sms$DATE_
df$date
#Load sector level data
SEC=read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Sector/BenthicREA_sectordata_TAXONCODE.csv")
library(tidyverse)
SEC %>% filter(ISLAND=="Oahu")
table(SEC$PooledSector_Demo_Viztool)
SEC %>% filter(PooledSector_Demo_Viztool=="OAH_NE")
NE=SEC %>% filter(PooledSector_Demo_Viztool=="OAH_NE")
head(NE)
NE=SEC %>% filter(PooledSector_Demo_Viztool=="OAH_NE",Mean_AdColDen>0)
head(NE)
table(NE$ANALYSIS_YEAR)
#OAH_NE
#Load sector level data
SEC=read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Sector/BenthicREA_sectordata_TAXONCODE.csv")
SEC$Sector=SEC$PooledSector_Demo_Viztool
table(SEC$ANALYSIS_YEAR)
NE=SEC %>% filter(Sector=="OAH_NE",Mean_AdColDen>0)
DenSort = NE %>% group_by(TAXONCODE) %>% summarize(mD=mean(Mean_AdColDen))
DenSort
DenSort = NE %>% group_by(TAXONCODE) %>% summarize(mD=mean(Mean_AdColDen)) %>% arrange(mD)
DenSort = NE %>% group_by(TAXONCODE) %>% summarize(mD=mean(Mean_AdColDen)) %>% arrange(desc(mD))
DenSort
NE=SEC %>% filter(Sector=="OAH_NE",Mean_AdColDen>0,TAXONCODE!="SSSS")
DenSort = NE %>% group_by(TAXONCODE) %>% summarize(mD=mean(Mean_AdColDen)) %>% arrange(desc(mD))
DenSort
NE$TAXONCODE=factor(NE$TAXONCODE,levels = DenSort$TAXONCODE)
NE$TAXONCODE
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+geom_point()+geom_errorbar()
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+geom_errorbar()+facet_wrap("ANALYSIS_YEAR")
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+geom_errorbar()+facet_wrap(ANALYSIS_YEAR~.)
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+geom_errorbar()+facet_grid(ANALYSIS_YEAR~.)
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+geom_errorbar()+facet_grid(ANALYSIS_YEAR~.)+scale_y_log10(name="Adult Colony Density")
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+
#geom_errorbar()+
facet_grid(ANALYSIS_YEAR~.)+scale_y_log10(name="Adult Colony Density")
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+
#geom_errorbar()+
facet_grid(ANALYSIS_YEAR~.)+
scale_y_continuous(name="Adult Colony Density")
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+
geom_errorbar()+
facet_grid(ANALYSIS_YEAR~.)+
scale_y_continuous(name="Adult Colony Density")
NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+
geom_errorbar()+
facet_grid(ANALYSIS_YEAR~.)+
scale_y_continuous(name="Adult Colony Density")+
theme_bw()+theme(axis.text.x = element_text(angle=90))
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE)) +
geom_treemap()
library(treemapify)
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE)) +
geom_treemap()
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE)) +
geom_treemap()+
geom_treemap_text()
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic") +
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
?geom_treemap
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap(layout="scol")+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap(layout="scol")+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap(layout="srow")+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap(layout="fixed")+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
ggplot(NE, aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
NE %>% filter(ANALYSIS_YEAR=="2019") %>% ggplot(aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic")
t6=NE %>% filter(ANALYSIS_YEAR=="2019") %>% ggplot(aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic") +scale_fill_discrete(guide="none")
t6
t9=NE %>% filter(ANALYSIS_YEAR=="2019") %>% ggplot(aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic") +scale_fill_discrete(guide="none")
t6=NE %>% filter(ANALYSIS_YEAR=="2016") %>% ggplot(aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic") +scale_fill_discrete(guide="none")
t3=NE %>% filter(ANALYSIS_YEAR=="2013") %>% ggplot(aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic") +scale_fill_discrete(guide="none")
library(patchwork)
t3/t6/t9
t3/t6/t9
MDen=t3/t6/t9
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_TREEMAPS.jpg",height=11,width=8)
MDen=t3/t6/t9
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_TREEMAPS.jpg",height=11,width=8,plot = MDen)
Mdenpts=NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+
geom_errorbar()+
facet_grid(ANALYSIS_YEAR~.)+
scale_y_continuous(name="Adult Colony Density")+
theme_bw()+theme(axis.text.x = element_text(angle=90))
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_TREEMAPS.jpg",height=11,width=8,plot = MDen)
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_Points.jpg",height=11,width=8,plot=Mdenpts)
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_TREEMAPS.jpg",height=11,width=8,plot = MDen)
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_Points.jpg",height=11,width=8,plot=Mdenpts)
write.csv(x = NE,file = "../../zMisc. Projects/OAHU_NE_REA.csv")
NE[,c("TAXONCODE","TAXON_NAME")]
TAXM=read.csv("T:/Benthic/Data/Lookup Tables/2013-23_Taxa_MASTER.csv")
TAXM$TAXON_NAME[match(DenSort$TAXONCODE,TAXM$SPCODE)]
data.frame(TAXONCODE=DenSort$TAXONCODE,Name=TAXM$TAXON_NAME[match(DenSort$TAXONCODE,TAXM$SPCODE)])
NEtax=data.frame(TAXONCODE=DenSort$TAXONCODE,Name=TAXM$TAXON_NAME[match(DenSort$TAXONCODE,TAXM$SPCODE)])
write.csv(x = NEtax,file = "../../zMisc. Projects/OAHU_NE_TAXONLOOKUP.csv")
Mdenpts
t369=NE %>%  ggplot(aes(area = Mean_AdColDen, fill = TAXONCODE,label=TAXONCODE,subgroup=ANALYSIS_YEAR)) +
geom_treemap()+
geom_treemap_text()+
geom_treemap_subgroup_border(colour = "white", size = 5) +
geom_treemap_subgroup_text(place = "centre", grow = TRUE,
alpha = 0.25, colour = "black",
fontface = "italic") +scale_fill_discrete(guide="none")
t369
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_TREEMAPS_together.jpg",height=11,width=8,plot = t369)
Mdenpts=NE %>% ggplot(aes(x=TAXONCODE,y=Mean_AdColDen,color=ANALYSIS_YEAR,
ymin=Mean_AdColDen-SE_AdColDen,ymax=Mean_AdColDen+SE_AdColDen))+
geom_point()+
geom_errorbar()+
facet_grid(ANALYSIS_YEAR~.)+
scale_y_continuous(name="Adult Colony Density (Colonies / m2)")+
theme_bw()+theme(axis.text.x = element_text(angle=90))
ggsave(filename = "../../zMisc. Projects/OAHU_NE_DEN_Points.jpg",height=11,width=8,plot=Mdenpts)
# read in data
cover = read.csv("C:/Users/Thomas.Oliver/Downloads/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
mhi
library(dplyr)
library(tidyr)
library(ggplot2)
library(survey)
options(dplyr.summarise.inform = FALSE)
# read in data
cover = read.csv("C:/Users/Thomas.Oliver/Downloads/BenthicCover_SITE_analysisready.csv")
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
cover$NH
# prepare data for analysis (filtered to Main Hawaiian Islands)
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n()) %>% #add up NHs and n (sites) for sectors that were pooled
filter(REGION == "MHI") %>% #remove strata with only 1 site and just include MHI sites
mutate(sw = NH / n, #Calculate survey weight
STRAT_CONC = paste(ANALYSIS_YEAR, REGION, ISLAND, SECTOR, STRATA, sep = "_"), #create new column with concatenated strata variable
ANALYSIS_YEAR = as.character(ANALYSIS_YEAR), #change to character
SECTOR = as.character(SECTOR), #change to character
STRATA = as.character(STRATA)) %>% #change to character
mutate(across(c(CORAL, CCA, MA, TURF), ~./100)) %>% # convert percent variables to proportions so we can use binomial
# remove islands with incomplete years
group_by(ISLAND) %>% filter(n_distinct(ANALYSIS_YEAR) == 4) %>% # only include islands that have 4 survey years
ungroup() #converts to standard dataframe
library(quantreg)
?rq.wfit
head(cover)
hist(cover$NH)
cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(nn=n(),NH = NH / n())
cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(nn=n(),NH = NH / n()) %>%cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(nn=n(),NH = NH / n()) %>%View()
mhi = cover %>% rename(SECTOR = PooledSector_Viztool) %>% #change name of column to "SECTOR"
distinct(SITEVISITID, SITE, .keep_all = TRUE) %>% #filter duplicates
mutate(NH = ifelse(is.na(NH) & DEPTH_BIN =="Mid", 50, #manually specify a NH value for one of the strata that didn't have NH
ifelse(is.na(NH),25, NH))) %>%
group_by(ANALYSIS_YEAR, SECTOR, SEC_NAME, STRATA) %>% mutate(nn=n(),NH = NH / n()) %>% #calculate NH (total possible sites) by year, sector, sec name and strata
group_by(ANALYSIS_YEAR, SECTOR, STRATA) %>% mutate(NH = sum(NH), n = n())
View(mhi)
head(cover)
50^2
rm(list=ls())
library(tidyverse)
library(ggrepel)
library(scales)
library(patchwork)
mean_rmI=function(x){return(mean(x[is.finite(x)],na.rm=T))}
sd_rmI=function(x){return(sd(x[is.finite(x)],na.rm=T))}
len.fin=function(x){length(x[is.finite(x)])}
se=function(x,na.rm=T){return(sd(x,na.rm=na.rm)/sqrt(len.fin(x)))}
se_rmI=function(x){return(se(x[is.finite(x)],na.rm=T))}
lx=rlnorm(100,meanlog = log(100),sdlog=log(20))
hist(log10(lx),100)
10^(mean(log10(lx)))
exp(sd(log(lx)))
exp(se(log(lx)))
#Load sector level data
SEC=read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Sector/BenthicREA_sectordata_TAXONCODE.csv")
SEC$Sector=SEC$PooledSector_Demo_Viztool
table(SEC$ANALYSIS_YEAR)
length(unique(SEC$PooledSector_Demo_Viztool))
length(unique(substr(SEC$PooledSector_Demo_Viztool,1,3)))
(unique(substr(SEC$PooledSector_Demo_Viztool,1,3)))
